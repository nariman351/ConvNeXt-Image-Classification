{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finetune_ConvNext_on_CIFAR10_using_W&B.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Use this notebook to finetune a ConvNeXt-tiny model on CIFAR 10 dataset. The [official ConvNeXt repository](https://github.com/facebookresearch/ConvNeXt) is instrumented with [Weights and Biases](https://wandb.ai/site). You can now easily log your train/test metrics and version control your model checkpoints to Weigths and Biases"],"metadata":{"id":"LniKjqdogsrH"}},{"cell_type":"markdown","source":["# ⚽️ Installation and Setup\n","\n","The following installation instruction is based on [INSTALL.md](https://github.com/facebookresearch/ConvNeXt/blob/main/INSTALL.md) provided by the official ConvNeXt repository. "],"metadata":{"id":"1JS4ffXFRnRr"}},{"cell_type":"code","source":["!pip install -qq torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install -qq wandb timm==0.3.2 six tensorboardX"],"metadata":{"id":"5YbEGpKrDKC5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658260872295,"user_tz":240,"elapsed":220177,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"1f488278-107a-45d8-a112-e5935c8055d5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |█████████████▌                  | 834.1 MB 1.4 MB/s eta 0:13:38tcmalloc: large alloc 1147494400 bytes == 0x3a2a4000 @  0x7fcc8df31615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████               | 1055.7 MB 1.2 MB/s eta 0:12:22tcmalloc: large alloc 1434370048 bytes == 0x7e8fa000 @  0x7fcc8df31615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████▋          | 1336.2 MB 1.2 MB/s eta 0:08:58tcmalloc: large alloc 1792966656 bytes == 0x372c000 @  0x7fcc8df31615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.3 MB/s eta 0:03:47tcmalloc: large alloc 2241208320 bytes == 0x6e514000 @  0x7fcc8df31615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0xf3e76000 @  0x7fcc8df301e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2477817856 bytes == 0x16a0e2000 @  0x7fcc8df31615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 1982.2 MB 5.3 kB/s \n","\u001b[K     |████████████████████████████████| 17.6 MB 33 kB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.8.0+cu111 which is incompatible.\n","torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n","\u001b[K     |████████████████████████████████| 244 kB 69.7 MB/s \n","\u001b[K     |████████████████████████████████| 125 kB 65.2 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 65.9 MB/s \n","\u001b[K     |████████████████████████████████| 147 kB 71.7 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["Download the official ConvNeXt respository. "],"metadata":{"id":"kDXQ-EpX9fsB"}},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/ConvNeXt"],"metadata":{"id":"zmmHO1Cp4E90","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e625049-f090-4ef5-add4-7b1b3d97ef90","executionInfo":{"status":"ok","timestamp":1658260873282,"user_tz":240,"elapsed":993,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ConvNeXt'...\n","remote: Enumerating objects: 246, done.\u001b[K\n","remote: Counting objects: 100% (84/84), done.\u001b[K\n","remote: Compressing objects: 100% (44/44), done.\u001b[K\n","remote: Total 246 (delta 54), reused 40 (delta 40), pack-reused 162\u001b[K\n","Receiving objects: 100% (246/246), 71.61 KiB | 2.86 MiB/s, done.\n","Resolving deltas: 100% (124/124), done.\n"]}]},{"cell_type":"markdown","source":["# 🏀 Download the Dataset\n","\n","We will be finetuning on CIFAR-10 dataset. To use any custom dataset (CIFAR-10 here) the format of the dataset should be as shown below:\n","\n","```\n","/path/to/dataset/\n","  train/\n","    class1/\n","      img1.jpeg\n","    class2/\n","      img2.jpeg\n","  val/\n","    class1/\n","      img3.jpeg\n","    class2/\n","      img4.jpeg\n","```\n","\n","I have used this [repository](https://github.com/YoongiKim/CIFAR-10-images) that has the CIFAR-10 images in the required format. "],"metadata":{"id":"yoVwkQ0v80KW"}},{"cell_type":"code","source":["!git clone https://github.com/YoongiKim/CIFAR-10-images"],"metadata":{"id":"8xcQ6QV41k8S","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5281c4b0-f064-4ccf-f380-5f7a3f557707","executionInfo":{"status":"ok","timestamp":1658260877566,"user_tz":240,"elapsed":4290,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CIFAR-10-images'...\n","remote: Enumerating objects: 60027, done.\u001b[K\n","remote: Total 60027 (delta 0), reused 0 (delta 0), pack-reused 60027\u001b[K\n","Receiving objects: 100% (60027/60027), 19.94 MiB | 39.04 MiB/s, done.\n","Resolving deltas: 100% (59990/59990), done.\n","Checking out files: 100% (60001/60001), done.\n"]}]},{"cell_type":"markdown","source":["# 🏈 Download Pretrained Weights\n","\n","We will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset."],"metadata":{"id":"J6qUVfL29tH1"}},{"cell_type":"code","source":["%cd ConvNeXt/\n","!wget https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth"],"metadata":{"id":"TYPDl5bT8LZ5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7bb9031e-8b6b-4d1d-ebbd-fd9f8b9e0b9a","executionInfo":{"status":"ok","timestamp":1658260881112,"user_tz":240,"elapsed":3550,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ConvNeXt\n","--2022-07-19 20:01:17--  https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 114414741 (109M) [binary/octet-stream]\n","Saving to: ‘convnext_tiny_1k_224_ema.pth’\n","\n","convnext_tiny_1k_22 100%[===================>] 109.11M  38.3MB/s    in 2.9s    \n","\n","2022-07-19 20:01:20 (38.3 MB/s) - ‘convnext_tiny_1k_224_ema.pth’ saved [114414741/114414741]\n","\n"]}]},{"cell_type":"markdown","source":["# 🎾 Train with Weights and Biases\n","\n","If you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`. \n","\n","You can also save the finetuned checkpoints as version controlled W&B [Artifacts](https://docs.wandb.ai/guides/artifacts) if you pass `--wandb_ckpt true`.\n","\n"],"metadata":{"id":"pSPgPCjp-Lro"}},{"cell_type":"code","source":["!python main.py --epochs 10 \\\n","                --model convnext_tiny \\\n","                --data_set image_folder \\\n","                --data_path ../CIFAR-10-images/train \\\n","                --eval_data_path ../CIFAR-10-images/test \\\n","                --nb_classes 10 \\\n","                --num_workers 8 \\\n","                --warmup_epochs 0 \\\n","                --save_ckpt true \\\n","                --output_dir model_ckpt \\\n","                --finetune convnext_tiny_1k_224_ema.pth \\\n","                --cutmix 0 \\\n","                --mixup 0 --lr 4e-4 \\\n","                --enable_wandb true --wandb_ckpt true"],"metadata":{"id":"_8sNl2Mb6x8_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658270068218,"user_tz":240,"elapsed":9187108,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"9f90ab18-df57-4422-e0ac-2b03b21496ae"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Not using distributed mode\n","Namespace(aa='rand-m9-mstd0.5-inc1', auto_resume=True, batch_size=64, clip_grad=None, color_jitter=0.4, crop_pct=None, cutmix=0.0, cutmix_minmax=None, data_path='../CIFAR-10-images/train', data_set='image_folder', device='cuda', disable_eval=False, dist_eval=True, dist_on_itp=False, dist_url='env://', distributed=False, drop_path=0, enable_wandb=True, epochs=10, eval=False, eval_data_path='../CIFAR-10-images/test', finetune='convnext_tiny_1k_224_ema.pth', head_init_scale=1.0, imagenet_default_mean_and_std=True, input_size=224, layer_decay=1.0, layer_scale_init_value=1e-06, local_rank=-1, log_dir=None, lr=0.0004, min_lr=1e-06, mixup=0.0, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convnext_tiny', model_ema=False, model_ema_decay=0.9999, model_ema_eval=False, model_ema_force_cpu=False, model_key='model|module', model_prefix='', momentum=0.9, nb_classes=10, num_workers=8, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='model_ckpt', pin_mem=True, project='convnext', recount=1, remode='pixel', reprob=0.25, resplit=False, resume='', save_ckpt=True, save_ckpt_freq=1, save_ckpt_num=3, seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', update_freq=1, use_amp=False, wandb_ckpt=True, warmup_epochs=0, warmup_steps=-1, weight_decay=0.05, weight_decay_end=None, world_size=1)\n","Transform = \n","RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BICUBIC)\n","RandomHorizontalFlip(p=0.5)\n","<timm.data.auto_augment.RandAugment object at 0x7f2f1a5b2e10>\n","ToTensor()\n","Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n","<timm.data.random_erasing.RandomErasing object at 0x7f2f1a5b2150>\n","---------------------------\n","Number of the class = 10\n","Transform = \n","Resize(size=256, interpolation=bicubic)\n","CenterCrop(size=(224, 224))\n","ToTensor()\n","Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","---------------------------\n","Number of the class = 10\n","Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f2f1a6134d0>\n","\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n","\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n","\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n","\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ConvNeXt/wandb/run-20220719_201816-1t3nj2l9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mskilled-resonance-2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mist/convnext\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mist/convnext/runs/1t3nj2l9\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Load ckpt from convnext_tiny_1k_224_ema.pth\n","Load state_dict by model_key = model\n","Removing key head.weight from pretrained checkpoint\n","Removing key head.bias from pretrained checkpoint\n","Weights of ConvNeXt not initialized from pretrained model: ['head.weight', 'head.bias']\n","Model = ConvNeXt(\n","  (downsample_layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (1): LayerNorm()\n","    )\n","    (1): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (2): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (3): Sequential(\n","      (0): LayerNorm()\n","      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","  )\n","  (stages): ModuleList(\n","    (0): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (1): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (2): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (3): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (4): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (5): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (6): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (7): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (8): Block(\n","        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","    (3): Sequential(\n","      (0): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (1): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","      (2): Block(\n","        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","        (norm): LayerNorm()\n","        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop_path): Identity()\n","      )\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","  (head): Linear(in_features=768, out_features=10, bias=True)\n",")\n","number of params: 27827818\n","LR = 0.00040000\n","Batch size = 64\n","Update frequent = 1\n","Number of training examples = 50000\n","Number of training training per epoch = 781\n","Param groups = {\n","  \"decay\": {\n","    \"weight_decay\": 0.05,\n","    \"params\": [\n","      \"downsample_layers.0.0.weight\",\n","      \"downsample_layers.1.1.weight\",\n","      \"downsample_layers.2.1.weight\",\n","      \"downsample_layers.3.1.weight\",\n","      \"stages.0.0.dwconv.weight\",\n","      \"stages.0.0.pwconv1.weight\",\n","      \"stages.0.0.pwconv2.weight\",\n","      \"stages.0.1.dwconv.weight\",\n","      \"stages.0.1.pwconv1.weight\",\n","      \"stages.0.1.pwconv2.weight\",\n","      \"stages.0.2.dwconv.weight\",\n","      \"stages.0.2.pwconv1.weight\",\n","      \"stages.0.2.pwconv2.weight\",\n","      \"stages.1.0.dwconv.weight\",\n","      \"stages.1.0.pwconv1.weight\",\n","      \"stages.1.0.pwconv2.weight\",\n","      \"stages.1.1.dwconv.weight\",\n","      \"stages.1.1.pwconv1.weight\",\n","      \"stages.1.1.pwconv2.weight\",\n","      \"stages.1.2.dwconv.weight\",\n","      \"stages.1.2.pwconv1.weight\",\n","      \"stages.1.2.pwconv2.weight\",\n","      \"stages.2.0.dwconv.weight\",\n","      \"stages.2.0.pwconv1.weight\",\n","      \"stages.2.0.pwconv2.weight\",\n","      \"stages.2.1.dwconv.weight\",\n","      \"stages.2.1.pwconv1.weight\",\n","      \"stages.2.1.pwconv2.weight\",\n","      \"stages.2.2.dwconv.weight\",\n","      \"stages.2.2.pwconv1.weight\",\n","      \"stages.2.2.pwconv2.weight\",\n","      \"stages.2.3.dwconv.weight\",\n","      \"stages.2.3.pwconv1.weight\",\n","      \"stages.2.3.pwconv2.weight\",\n","      \"stages.2.4.dwconv.weight\",\n","      \"stages.2.4.pwconv1.weight\",\n","      \"stages.2.4.pwconv2.weight\",\n","      \"stages.2.5.dwconv.weight\",\n","      \"stages.2.5.pwconv1.weight\",\n","      \"stages.2.5.pwconv2.weight\",\n","      \"stages.2.6.dwconv.weight\",\n","      \"stages.2.6.pwconv1.weight\",\n","      \"stages.2.6.pwconv2.weight\",\n","      \"stages.2.7.dwconv.weight\",\n","      \"stages.2.7.pwconv1.weight\",\n","      \"stages.2.7.pwconv2.weight\",\n","      \"stages.2.8.dwconv.weight\",\n","      \"stages.2.8.pwconv1.weight\",\n","      \"stages.2.8.pwconv2.weight\",\n","      \"stages.3.0.dwconv.weight\",\n","      \"stages.3.0.pwconv1.weight\",\n","      \"stages.3.0.pwconv2.weight\",\n","      \"stages.3.1.dwconv.weight\",\n","      \"stages.3.1.pwconv1.weight\",\n","      \"stages.3.1.pwconv2.weight\",\n","      \"stages.3.2.dwconv.weight\",\n","      \"stages.3.2.pwconv1.weight\",\n","      \"stages.3.2.pwconv2.weight\",\n","      \"head.weight\"\n","    ],\n","    \"lr_scale\": 1.0\n","  },\n","  \"no_decay\": {\n","    \"weight_decay\": 0.0,\n","    \"params\": [\n","      \"downsample_layers.0.0.bias\",\n","      \"downsample_layers.0.1.weight\",\n","      \"downsample_layers.0.1.bias\",\n","      \"downsample_layers.1.0.weight\",\n","      \"downsample_layers.1.0.bias\",\n","      \"downsample_layers.1.1.bias\",\n","      \"downsample_layers.2.0.weight\",\n","      \"downsample_layers.2.0.bias\",\n","      \"downsample_layers.2.1.bias\",\n","      \"downsample_layers.3.0.weight\",\n","      \"downsample_layers.3.0.bias\",\n","      \"downsample_layers.3.1.bias\",\n","      \"stages.0.0.gamma\",\n","      \"stages.0.0.dwconv.bias\",\n","      \"stages.0.0.norm.weight\",\n","      \"stages.0.0.norm.bias\",\n","      \"stages.0.0.pwconv1.bias\",\n","      \"stages.0.0.pwconv2.bias\",\n","      \"stages.0.1.gamma\",\n","      \"stages.0.1.dwconv.bias\",\n","      \"stages.0.1.norm.weight\",\n","      \"stages.0.1.norm.bias\",\n","      \"stages.0.1.pwconv1.bias\",\n","      \"stages.0.1.pwconv2.bias\",\n","      \"stages.0.2.gamma\",\n","      \"stages.0.2.dwconv.bias\",\n","      \"stages.0.2.norm.weight\",\n","      \"stages.0.2.norm.bias\",\n","      \"stages.0.2.pwconv1.bias\",\n","      \"stages.0.2.pwconv2.bias\",\n","      \"stages.1.0.gamma\",\n","      \"stages.1.0.dwconv.bias\",\n","      \"stages.1.0.norm.weight\",\n","      \"stages.1.0.norm.bias\",\n","      \"stages.1.0.pwconv1.bias\",\n","      \"stages.1.0.pwconv2.bias\",\n","      \"stages.1.1.gamma\",\n","      \"stages.1.1.dwconv.bias\",\n","      \"stages.1.1.norm.weight\",\n","      \"stages.1.1.norm.bias\",\n","      \"stages.1.1.pwconv1.bias\",\n","      \"stages.1.1.pwconv2.bias\",\n","      \"stages.1.2.gamma\",\n","      \"stages.1.2.dwconv.bias\",\n","      \"stages.1.2.norm.weight\",\n","      \"stages.1.2.norm.bias\",\n","      \"stages.1.2.pwconv1.bias\",\n","      \"stages.1.2.pwconv2.bias\",\n","      \"stages.2.0.gamma\",\n","      \"stages.2.0.dwconv.bias\",\n","      \"stages.2.0.norm.weight\",\n","      \"stages.2.0.norm.bias\",\n","      \"stages.2.0.pwconv1.bias\",\n","      \"stages.2.0.pwconv2.bias\",\n","      \"stages.2.1.gamma\",\n","      \"stages.2.1.dwconv.bias\",\n","      \"stages.2.1.norm.weight\",\n","      \"stages.2.1.norm.bias\",\n","      \"stages.2.1.pwconv1.bias\",\n","      \"stages.2.1.pwconv2.bias\",\n","      \"stages.2.2.gamma\",\n","      \"stages.2.2.dwconv.bias\",\n","      \"stages.2.2.norm.weight\",\n","      \"stages.2.2.norm.bias\",\n","      \"stages.2.2.pwconv1.bias\",\n","      \"stages.2.2.pwconv2.bias\",\n","      \"stages.2.3.gamma\",\n","      \"stages.2.3.dwconv.bias\",\n","      \"stages.2.3.norm.weight\",\n","      \"stages.2.3.norm.bias\",\n","      \"stages.2.3.pwconv1.bias\",\n","      \"stages.2.3.pwconv2.bias\",\n","      \"stages.2.4.gamma\",\n","      \"stages.2.4.dwconv.bias\",\n","      \"stages.2.4.norm.weight\",\n","      \"stages.2.4.norm.bias\",\n","      \"stages.2.4.pwconv1.bias\",\n","      \"stages.2.4.pwconv2.bias\",\n","      \"stages.2.5.gamma\",\n","      \"stages.2.5.dwconv.bias\",\n","      \"stages.2.5.norm.weight\",\n","      \"stages.2.5.norm.bias\",\n","      \"stages.2.5.pwconv1.bias\",\n","      \"stages.2.5.pwconv2.bias\",\n","      \"stages.2.6.gamma\",\n","      \"stages.2.6.dwconv.bias\",\n","      \"stages.2.6.norm.weight\",\n","      \"stages.2.6.norm.bias\",\n","      \"stages.2.6.pwconv1.bias\",\n","      \"stages.2.6.pwconv2.bias\",\n","      \"stages.2.7.gamma\",\n","      \"stages.2.7.dwconv.bias\",\n","      \"stages.2.7.norm.weight\",\n","      \"stages.2.7.norm.bias\",\n","      \"stages.2.7.pwconv1.bias\",\n","      \"stages.2.7.pwconv2.bias\",\n","      \"stages.2.8.gamma\",\n","      \"stages.2.8.dwconv.bias\",\n","      \"stages.2.8.norm.weight\",\n","      \"stages.2.8.norm.bias\",\n","      \"stages.2.8.pwconv1.bias\",\n","      \"stages.2.8.pwconv2.bias\",\n","      \"stages.3.0.gamma\",\n","      \"stages.3.0.dwconv.bias\",\n","      \"stages.3.0.norm.weight\",\n","      \"stages.3.0.norm.bias\",\n","      \"stages.3.0.pwconv1.bias\",\n","      \"stages.3.0.pwconv2.bias\",\n","      \"stages.3.1.gamma\",\n","      \"stages.3.1.dwconv.bias\",\n","      \"stages.3.1.norm.weight\",\n","      \"stages.3.1.norm.bias\",\n","      \"stages.3.1.pwconv1.bias\",\n","      \"stages.3.1.pwconv2.bias\",\n","      \"stages.3.2.gamma\",\n","      \"stages.3.2.dwconv.bias\",\n","      \"stages.3.2.norm.weight\",\n","      \"stages.3.2.norm.bias\",\n","      \"stages.3.2.pwconv1.bias\",\n","      \"stages.3.2.pwconv2.bias\",\n","      \"norm.weight\",\n","      \"norm.bias\",\n","      \"head.bias\"\n","    ],\n","    \"lr_scale\": 1.0\n","  }\n","}\n","Use Cosine LR scheduler\n","Set warmup steps = 0\n","Set warmup steps = 0\n","Max WD = 0.0500000, Min WD = 0.0500000\n","criterion = LabelSmoothingCrossEntropy()\n","Auto resume checkpoint: \n","Start training for 10 epochs\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [0]  [  0/781]  eta: 1:25:37  lr: 0.000400  min_lr: 0.000400  loss: 2.2958 (2.2958)  class_acc: 0.1562 (0.1562)  weight_decay: 0.0500 (0.0500)  time: 6.5782  data: 2.4197  max mem: 8477\n","Epoch: [0]  [ 10/781]  eta: 0:17:26  lr: 0.000400  min_lr: 0.000400  loss: 2.1855 (2.1665)  class_acc: 0.2344 (0.2443)  weight_decay: 0.0500 (0.0500)  time: 1.3568  data: 0.2217  max mem: 8477\n","Epoch: [0]  [ 20/781]  eta: 0:14:06  lr: 0.000400  min_lr: 0.000400  loss: 1.9205 (2.0094)  class_acc: 0.3438 (0.3378)  weight_decay: 0.0500 (0.0500)  time: 0.8397  data: 0.0026  max mem: 8477\n","Epoch: [0]  [ 30/781]  eta: 0:12:53  lr: 0.000400  min_lr: 0.000400  loss: 1.7574 (1.8965)  class_acc: 0.4531 (0.3881)  weight_decay: 0.0500 (0.0500)  time: 0.8500  data: 0.0026  max mem: 8477\n","Epoch: [0]  [ 40/781]  eta: 0:12:13  lr: 0.000400  min_lr: 0.000400  loss: 1.5949 (1.8164)  class_acc: 0.5000 (0.4211)  weight_decay: 0.0500 (0.0500)  time: 0.8612  data: 0.0017  max mem: 8477\n","Epoch: [0]  [ 50/781]  eta: 0:11:47  lr: 0.000400  min_lr: 0.000400  loss: 1.5727 (1.7577)  class_acc: 0.5000 (0.4449)  weight_decay: 0.0500 (0.0500)  time: 0.8717  data: 0.0011  max mem: 8477\n","Epoch: [0]  [ 60/781]  eta: 0:11:28  lr: 0.000400  min_lr: 0.000400  loss: 1.4765 (1.7076)  class_acc: 0.5625 (0.4654)  weight_decay: 0.0500 (0.0500)  time: 0.8843  data: 0.0007  max mem: 8477\n","Epoch: [0]  [ 70/781]  eta: 0:11:14  lr: 0.000400  min_lr: 0.000400  loss: 1.4264 (1.6736)  class_acc: 0.5625 (0.4800)  weight_decay: 0.0500 (0.0500)  time: 0.9019  data: 0.0008  max mem: 8477\n","Epoch: [0]  [ 80/781]  eta: 0:11:03  lr: 0.000400  min_lr: 0.000400  loss: 1.4176 (1.6376)  class_acc: 0.5938 (0.4950)  weight_decay: 0.0500 (0.0500)  time: 0.9187  data: 0.0013  max mem: 8477\n","Epoch: [0]  [ 90/781]  eta: 0:10:53  lr: 0.000400  min_lr: 0.000400  loss: 1.3510 (1.6025)  class_acc: 0.6250 (0.5113)  weight_decay: 0.0500 (0.0500)  time: 0.9326  data: 0.0015  max mem: 8477\n","Epoch: [0]  [100/781]  eta: 0:10:45  lr: 0.000400  min_lr: 0.000400  loss: 1.3125 (1.5761)  class_acc: 0.6250 (0.5234)  weight_decay: 0.0500 (0.0500)  time: 0.9518  data: 0.0013  max mem: 8477\n","Epoch: [0]  [110/781]  eta: 0:10:38  lr: 0.000400  min_lr: 0.000400  loss: 1.3359 (1.5596)  class_acc: 0.6250 (0.5301)  weight_decay: 0.0500 (0.0500)  time: 0.9777  data: 0.0011  max mem: 8477\n","Epoch: [0]  [120/781]  eta: 0:10:32  lr: 0.000400  min_lr: 0.000400  loss: 1.3420 (1.5405)  class_acc: 0.6250 (0.5395)  weight_decay: 0.0500 (0.0500)  time: 1.0036  data: 0.0008  max mem: 8477\n","Epoch: [0]  [130/781]  eta: 0:10:24  lr: 0.000400  min_lr: 0.000400  loss: 1.3332 (1.5259)  class_acc: 0.6406 (0.5470)  weight_decay: 0.0500 (0.0500)  time: 1.0076  data: 0.0009  max mem: 8477\n","Epoch: [0]  [140/781]  eta: 0:10:15  lr: 0.000400  min_lr: 0.000400  loss: 1.3628 (1.5140)  class_acc: 0.6250 (0.5522)  weight_decay: 0.0500 (0.0500)  time: 0.9866  data: 0.0026  max mem: 8477\n","Epoch: [0]  [150/781]  eta: 0:10:06  lr: 0.000400  min_lr: 0.000400  loss: 1.3220 (1.5008)  class_acc: 0.6250 (0.5570)  weight_decay: 0.0500 (0.0500)  time: 0.9654  data: 0.0026  max mem: 8477\n","Epoch: [0]  [160/781]  eta: 0:09:56  lr: 0.000400  min_lr: 0.000400  loss: 1.3272 (1.4903)  class_acc: 0.6250 (0.5622)  weight_decay: 0.0500 (0.0500)  time: 0.9535  data: 0.0009  max mem: 8477\n","Epoch: [0]  [170/781]  eta: 0:09:46  lr: 0.000400  min_lr: 0.000400  loss: 1.3272 (1.4802)  class_acc: 0.6406 (0.5670)  weight_decay: 0.0500 (0.0500)  time: 0.9500  data: 0.0013  max mem: 8477\n","Epoch: [0]  [180/781]  eta: 0:09:36  lr: 0.000399  min_lr: 0.000399  loss: 1.3275 (1.4727)  class_acc: 0.6250 (0.5695)  weight_decay: 0.0500 (0.0500)  time: 0.9522  data: 0.0012  max mem: 8477\n","Epoch: [0]  [190/781]  eta: 0:09:26  lr: 0.000399  min_lr: 0.000399  loss: 1.3607 (1.4681)  class_acc: 0.5938 (0.5708)  weight_decay: 0.0500 (0.0500)  time: 0.9549  data: 0.0014  max mem: 8477\n","Epoch: [0]  [200/781]  eta: 0:09:17  lr: 0.000399  min_lr: 0.000399  loss: 1.3352 (1.4599)  class_acc: 0.6094 (0.5741)  weight_decay: 0.0500 (0.0500)  time: 0.9606  data: 0.0014  max mem: 8477\n","Epoch: [0]  [210/781]  eta: 0:09:08  lr: 0.000399  min_lr: 0.000399  loss: 1.2657 (1.4504)  class_acc: 0.6406 (0.5783)  weight_decay: 0.0500 (0.0500)  time: 0.9706  data: 0.0008  max mem: 8477\n","Epoch: [0]  [220/781]  eta: 0:08:58  lr: 0.000399  min_lr: 0.000399  loss: 1.2998 (1.4453)  class_acc: 0.6406 (0.5809)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0014  max mem: 8477\n","Epoch: [0]  [230/781]  eta: 0:08:49  lr: 0.000399  min_lr: 0.000399  loss: 1.3331 (1.4426)  class_acc: 0.6250 (0.5821)  weight_decay: 0.0500 (0.0500)  time: 0.9716  data: 0.0014  max mem: 8477\n","Epoch: [0]  [240/781]  eta: 0:08:40  lr: 0.000399  min_lr: 0.000399  loss: 1.3086 (1.4375)  class_acc: 0.6250 (0.5843)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0010  max mem: 8477\n","Epoch: [0]  [250/781]  eta: 0:08:30  lr: 0.000399  min_lr: 0.000399  loss: 1.2630 (1.4310)  class_acc: 0.6562 (0.5870)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0012  max mem: 8477\n","Epoch: [0]  [260/781]  eta: 0:08:21  lr: 0.000399  min_lr: 0.000399  loss: 1.2676 (1.4251)  class_acc: 0.6562 (0.5896)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0017  max mem: 8477\n","Epoch: [0]  [270/781]  eta: 0:08:11  lr: 0.000399  min_lr: 0.000399  loss: 1.2869 (1.4216)  class_acc: 0.6250 (0.5909)  weight_decay: 0.0500 (0.0500)  time: 0.9636  data: 0.0014  max mem: 8477\n","Epoch: [0]  [280/781]  eta: 0:08:01  lr: 0.000399  min_lr: 0.000399  loss: 1.3247 (1.4199)  class_acc: 0.6250 (0.5913)  weight_decay: 0.0500 (0.0500)  time: 0.9631  data: 0.0008  max mem: 8477\n","Epoch: [0]  [290/781]  eta: 0:07:52  lr: 0.000399  min_lr: 0.000399  loss: 1.2985 (1.4156)  class_acc: 0.6406 (0.5929)  weight_decay: 0.0500 (0.0500)  time: 0.9628  data: 0.0009  max mem: 8477\n","Epoch: [0]  [300/781]  eta: 0:07:42  lr: 0.000399  min_lr: 0.000399  loss: 1.2457 (1.4091)  class_acc: 0.6562 (0.5960)  weight_decay: 0.0500 (0.0500)  time: 0.9619  data: 0.0012  max mem: 8477\n","Epoch: [0]  [310/781]  eta: 0:07:33  lr: 0.000398  min_lr: 0.000398  loss: 1.2136 (1.4044)  class_acc: 0.6719 (0.5983)  weight_decay: 0.0500 (0.0500)  time: 0.9624  data: 0.0011  max mem: 8477\n","Epoch: [0]  [320/781]  eta: 0:07:23  lr: 0.000398  min_lr: 0.000398  loss: 1.1998 (1.3966)  class_acc: 0.6719 (0.6017)  weight_decay: 0.0500 (0.0500)  time: 0.9622  data: 0.0011  max mem: 8477\n","Epoch: [0]  [330/781]  eta: 0:07:13  lr: 0.000398  min_lr: 0.000398  loss: 1.1998 (1.3918)  class_acc: 0.6562 (0.6036)  weight_decay: 0.0500 (0.0500)  time: 0.9629  data: 0.0012  max mem: 8477\n","Epoch: [0]  [340/781]  eta: 0:07:04  lr: 0.000398  min_lr: 0.000398  loss: 1.2514 (1.3881)  class_acc: 0.6250 (0.6048)  weight_decay: 0.0500 (0.0500)  time: 0.9653  data: 0.0012  max mem: 8477\n","Epoch: [0]  [350/781]  eta: 0:06:54  lr: 0.000398  min_lr: 0.000398  loss: 1.2515 (1.3838)  class_acc: 0.6562 (0.6070)  weight_decay: 0.0500 (0.0500)  time: 0.9642  data: 0.0012  max mem: 8477\n","Epoch: [0]  [360/781]  eta: 0:06:45  lr: 0.000398  min_lr: 0.000398  loss: 1.2515 (1.3808)  class_acc: 0.6719 (0.6084)  weight_decay: 0.0500 (0.0500)  time: 0.9640  data: 0.0020  max mem: 8477\n","Epoch: [0]  [370/781]  eta: 0:06:35  lr: 0.000398  min_lr: 0.000398  loss: 1.2534 (1.3770)  class_acc: 0.6719 (0.6102)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0015  max mem: 8477\n","Epoch: [0]  [380/781]  eta: 0:06:25  lr: 0.000398  min_lr: 0.000398  loss: 1.2257 (1.3725)  class_acc: 0.6875 (0.6125)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0003  max mem: 8477\n","Epoch: [0]  [390/781]  eta: 0:06:16  lr: 0.000398  min_lr: 0.000398  loss: 1.1953 (1.3681)  class_acc: 0.7031 (0.6145)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0007  max mem: 8477\n","Epoch: [0]  [400/781]  eta: 0:06:06  lr: 0.000397  min_lr: 0.000397  loss: 1.2054 (1.3650)  class_acc: 0.6562 (0.6153)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0009  max mem: 8477\n","Epoch: [0]  [410/781]  eta: 0:05:57  lr: 0.000397  min_lr: 0.000397  loss: 1.2657 (1.3629)  class_acc: 0.6406 (0.6162)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0007  max mem: 8477\n","Epoch: [0]  [420/781]  eta: 0:05:47  lr: 0.000397  min_lr: 0.000397  loss: 1.2650 (1.3595)  class_acc: 0.6562 (0.6178)  weight_decay: 0.0500 (0.0500)  time: 0.9726  data: 0.0007  max mem: 8477\n","Epoch: [0]  [430/781]  eta: 0:05:38  lr: 0.000397  min_lr: 0.000397  loss: 1.2228 (1.3562)  class_acc: 0.6875 (0.6193)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0009  max mem: 8477\n","Epoch: [0]  [440/781]  eta: 0:05:28  lr: 0.000397  min_lr: 0.000397  loss: 1.2163 (1.3531)  class_acc: 0.6719 (0.6206)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0011  max mem: 8477\n","Epoch: [0]  [450/781]  eta: 0:05:19  lr: 0.000397  min_lr: 0.000397  loss: 1.2470 (1.3513)  class_acc: 0.6562 (0.6216)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0012  max mem: 8477\n","Epoch: [0]  [460/781]  eta: 0:05:09  lr: 0.000397  min_lr: 0.000397  loss: 1.1977 (1.3480)  class_acc: 0.6875 (0.6233)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0011  max mem: 8477\n","Epoch: [0]  [470/781]  eta: 0:04:59  lr: 0.000396  min_lr: 0.000396  loss: 1.2127 (1.3456)  class_acc: 0.6562 (0.6238)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0010  max mem: 8477\n","Epoch: [0]  [480/781]  eta: 0:04:50  lr: 0.000396  min_lr: 0.000396  loss: 1.2134 (1.3433)  class_acc: 0.6562 (0.6246)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0013  max mem: 8477\n","Epoch: [0]  [490/781]  eta: 0:04:40  lr: 0.000396  min_lr: 0.000396  loss: 1.2086 (1.3409)  class_acc: 0.6562 (0.6251)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0012  max mem: 8477\n","Epoch: [0]  [500/781]  eta: 0:04:31  lr: 0.000396  min_lr: 0.000396  loss: 1.1773 (1.3376)  class_acc: 0.6719 (0.6267)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0012  max mem: 8477\n","Epoch: [0]  [510/781]  eta: 0:04:21  lr: 0.000396  min_lr: 0.000396  loss: 1.1954 (1.3366)  class_acc: 0.6719 (0.6268)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0013  max mem: 8477\n","Epoch: [0]  [520/781]  eta: 0:04:11  lr: 0.000396  min_lr: 0.000396  loss: 1.2098 (1.3333)  class_acc: 0.6875 (0.6284)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0009  max mem: 8477\n","Epoch: [0]  [530/781]  eta: 0:04:02  lr: 0.000395  min_lr: 0.000395  loss: 1.1856 (1.3309)  class_acc: 0.6875 (0.6294)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0008  max mem: 8477\n","Epoch: [0]  [540/781]  eta: 0:03:52  lr: 0.000395  min_lr: 0.000395  loss: 1.1726 (1.3283)  class_acc: 0.6875 (0.6307)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0007  max mem: 8477\n","Epoch: [0]  [550/781]  eta: 0:03:43  lr: 0.000395  min_lr: 0.000395  loss: 1.1966 (1.3258)  class_acc: 0.6719 (0.6316)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0008  max mem: 8477\n","Epoch: [0]  [560/781]  eta: 0:03:33  lr: 0.000395  min_lr: 0.000395  loss: 1.1966 (1.3238)  class_acc: 0.6719 (0.6324)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0013  max mem: 8477\n","Epoch: [0]  [570/781]  eta: 0:03:23  lr: 0.000395  min_lr: 0.000395  loss: 1.2152 (1.3224)  class_acc: 0.6719 (0.6330)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0014  max mem: 8477\n","Epoch: [0]  [580/781]  eta: 0:03:14  lr: 0.000395  min_lr: 0.000395  loss: 1.2573 (1.3210)  class_acc: 0.6719 (0.6334)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0014  max mem: 8477\n","Epoch: [0]  [590/781]  eta: 0:03:04  lr: 0.000394  min_lr: 0.000394  loss: 1.1969 (1.3186)  class_acc: 0.6719 (0.6346)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0018  max mem: 8477\n","Epoch: [0]  [600/781]  eta: 0:02:54  lr: 0.000394  min_lr: 0.000394  loss: 1.1574 (1.3165)  class_acc: 0.7031 (0.6356)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0013  max mem: 8477\n","Epoch: [0]  [610/781]  eta: 0:02:45  lr: 0.000394  min_lr: 0.000394  loss: 1.1891 (1.3145)  class_acc: 0.6875 (0.6364)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0011  max mem: 8477\n","Epoch: [0]  [620/781]  eta: 0:02:35  lr: 0.000394  min_lr: 0.000394  loss: 1.1920 (1.3124)  class_acc: 0.6719 (0.6371)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0014  max mem: 8477\n","Epoch: [0]  [630/781]  eta: 0:02:25  lr: 0.000394  min_lr: 0.000394  loss: 1.2251 (1.3117)  class_acc: 0.6719 (0.6373)  weight_decay: 0.0500 (0.0500)  time: 0.9733  data: 0.0011  max mem: 8477\n","Epoch: [0]  [640/781]  eta: 0:02:16  lr: 0.000393  min_lr: 0.000393  loss: 1.2060 (1.3098)  class_acc: 0.6719 (0.6382)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0008  max mem: 8477\n","Epoch: [0]  [650/781]  eta: 0:02:06  lr: 0.000393  min_lr: 0.000393  loss: 1.1580 (1.3072)  class_acc: 0.6875 (0.6394)  weight_decay: 0.0500 (0.0500)  time: 0.9676  data: 0.0008  max mem: 8477\n","Epoch: [0]  [660/781]  eta: 0:01:56  lr: 0.000393  min_lr: 0.000393  loss: 1.1801 (1.3058)  class_acc: 0.6875 (0.6400)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0010  max mem: 8477\n","Epoch: [0]  [670/781]  eta: 0:01:47  lr: 0.000393  min_lr: 0.000393  loss: 1.2127 (1.3044)  class_acc: 0.6719 (0.6410)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0008  max mem: 8477\n","Epoch: [0]  [680/781]  eta: 0:01:37  lr: 0.000393  min_lr: 0.000393  loss: 1.2489 (1.3038)  class_acc: 0.6719 (0.6413)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0010  max mem: 8477\n","Epoch: [0]  [690/781]  eta: 0:01:27  lr: 0.000392  min_lr: 0.000392  loss: 1.1888 (1.3020)  class_acc: 0.6719 (0.6421)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0011  max mem: 8477\n","Epoch: [0]  [700/781]  eta: 0:01:18  lr: 0.000392  min_lr: 0.000392  loss: 1.1730 (1.2997)  class_acc: 0.6875 (0.6431)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0012  max mem: 8477\n","Epoch: [0]  [710/781]  eta: 0:01:08  lr: 0.000392  min_lr: 0.000392  loss: 1.1550 (1.2975)  class_acc: 0.7031 (0.6442)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0013  max mem: 8477\n","Epoch: [0]  [720/781]  eta: 0:00:58  lr: 0.000392  min_lr: 0.000392  loss: 1.1464 (1.2949)  class_acc: 0.7031 (0.6454)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0011  max mem: 8477\n","Epoch: [0]  [730/781]  eta: 0:00:49  lr: 0.000391  min_lr: 0.000391  loss: 1.1473 (1.2932)  class_acc: 0.7031 (0.6460)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0011  max mem: 8477\n","Epoch: [0]  [740/781]  eta: 0:00:39  lr: 0.000391  min_lr: 0.000391  loss: 1.1675 (1.2917)  class_acc: 0.6875 (0.6468)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0013  max mem: 8477\n","Epoch: [0]  [750/781]  eta: 0:00:29  lr: 0.000391  min_lr: 0.000391  loss: 1.1675 (1.2902)  class_acc: 0.6875 (0.6474)  weight_decay: 0.0500 (0.0500)  time: 0.9710  data: 0.0013  max mem: 8477\n","Epoch: [0]  [760/781]  eta: 0:00:20  lr: 0.000391  min_lr: 0.000391  loss: 1.1696 (1.2886)  class_acc: 0.7031 (0.6481)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0008  max mem: 8477\n","Epoch: [0]  [770/781]  eta: 0:00:10  lr: 0.000391  min_lr: 0.000391  loss: 1.1323 (1.2870)  class_acc: 0.7031 (0.6488)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0006  max mem: 8477\n","Epoch: [0]  [780/781]  eta: 0:00:00  lr: 0.000390  min_lr: 0.000390  loss: 1.1470 (1.2850)  class_acc: 0.7188 (0.6497)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0005  max mem: 8477\n","Epoch: [0] Total time: 0:12:35 (0.9673 s / it)\n","Averaged stats: lr: 0.000390  min_lr: 0.000390  loss: 1.1470 (1.2850)  class_acc: 0.7188 (0.6497)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:06:29  loss: 0.6127 (0.6127)  acc1: 82.2917 (82.2917)  acc5: 97.9167 (97.9167)  time: 3.7055  data: 2.2656  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:14  loss: 0.3611 (0.3729)  acc1: 90.6250 (89.8674)  acc5: 100.0000 (99.4318)  time: 0.7811  data: 0.2077  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:54  loss: 0.2559 (0.2824)  acc1: 94.7917 (93.1052)  acc5: 100.0000 (99.7024)  time: 0.4895  data: 0.0039  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:44  loss: 0.2794 (0.3291)  acc1: 92.7083 (91.7003)  acc5: 100.0000 (99.7984)  time: 0.4892  data: 0.0032  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:36  loss: 0.4585 (0.3628)  acc1: 86.4583 (90.4472)  acc5: 100.0000 (99.8222)  time: 0.4871  data: 0.0006  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:30  loss: 0.4798 (0.3902)  acc1: 85.4167 (89.1748)  acc5: 100.0000 (99.7958)  time: 0.4872  data: 0.0027  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:24  loss: 0.5378 (0.4162)  acc1: 82.2917 (87.8586)  acc5: 100.0000 (99.7780)  time: 0.4872  data: 0.0031  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.4212 (0.4000)  acc1: 86.4583 (88.4390)  acc5: 100.0000 (99.7506)  time: 0.4866  data: 0.0020  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:13  loss: 0.3344 (0.3970)  acc1: 91.6667 (88.7989)  acc5: 100.0000 (99.7171)  time: 0.4871  data: 0.0013  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.3344 (0.3786)  acc1: 92.7083 (89.4803)  acc5: 100.0000 (99.7367)  time: 0.4869  data: 0.0007  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.2176 (0.3744)  acc1: 93.7500 (89.6452)  acc5: 100.0000 (99.7112)  time: 0.4871  data: 0.0007  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.2911 (0.3737)  acc1: 91.6667 (89.6600)  acc5: 100.0000 (99.7200)  time: 0.4694  data: 0.0003  max mem: 8477\n","Test: Total time: 0:00:54 (0.5172 s / it)\n","* Acc@1 89.660 Acc@5 99.720 loss 0.374\n","Accuracy of the model on the 10000 test images: 89.7%\n","Max accuracy: 89.66%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [1]  [  0/781]  eta: 0:44:45  lr: 0.000390  min_lr: 0.000390  loss: 1.2793 (1.2793)  class_acc: 0.6406 (0.6406)  weight_decay: 0.0500 (0.0500)  time: 3.4387  data: 2.4059  max mem: 8477\n","Epoch: [1]  [ 10/781]  eta: 0:15:15  lr: 0.000390  min_lr: 0.000390  loss: 1.2376 (1.2034)  class_acc: 0.6719 (0.6818)  weight_decay: 0.0500 (0.0500)  time: 1.1879  data: 0.2198  max mem: 8477\n","Epoch: [1]  [ 20/781]  eta: 0:13:43  lr: 0.000390  min_lr: 0.000390  loss: 1.1962 (1.1834)  class_acc: 0.6875 (0.6949)  weight_decay: 0.0500 (0.0500)  time: 0.9645  data: 0.0010  max mem: 8477\n","Epoch: [1]  [ 30/781]  eta: 0:13:05  lr: 0.000389  min_lr: 0.000389  loss: 1.1759 (1.1695)  class_acc: 0.7031 (0.6941)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0014  max mem: 8477\n","Epoch: [1]  [ 40/781]  eta: 0:12:42  lr: 0.000389  min_lr: 0.000389  loss: 1.1613 (1.1794)  class_acc: 0.6719 (0.6841)  weight_decay: 0.0500 (0.0500)  time: 0.9728  data: 0.0016  max mem: 8477\n","Epoch: [1]  [ 50/781]  eta: 0:12:24  lr: 0.000389  min_lr: 0.000389  loss: 1.1474 (1.1782)  class_acc: 0.6719 (0.6847)  weight_decay: 0.0500 (0.0500)  time: 0.9746  data: 0.0011  max mem: 8477\n","Epoch: [1]  [ 60/781]  eta: 0:12:08  lr: 0.000389  min_lr: 0.000389  loss: 1.1745 (1.1819)  class_acc: 0.6875 (0.6834)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0014  max mem: 8477\n","Epoch: [1]  [ 70/781]  eta: 0:11:54  lr: 0.000388  min_lr: 0.000388  loss: 1.1838 (1.1832)  class_acc: 0.6875 (0.6855)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0014  max mem: 8477\n","Epoch: [1]  [ 80/781]  eta: 0:11:41  lr: 0.000388  min_lr: 0.000388  loss: 1.1661 (1.1785)  class_acc: 0.7031 (0.6889)  weight_decay: 0.0500 (0.0500)  time: 0.9688  data: 0.0013  max mem: 8477\n","Epoch: [1]  [ 90/781]  eta: 0:11:28  lr: 0.000388  min_lr: 0.000388  loss: 1.0945 (1.1744)  class_acc: 0.7188 (0.6914)  weight_decay: 0.0500 (0.0500)  time: 0.9663  data: 0.0012  max mem: 8477\n","Epoch: [1]  [100/781]  eta: 0:11:16  lr: 0.000388  min_lr: 0.000388  loss: 1.1052 (1.1714)  class_acc: 0.7188 (0.6954)  weight_decay: 0.0500 (0.0500)  time: 0.9664  data: 0.0010  max mem: 8477\n","Epoch: [1]  [110/781]  eta: 0:11:05  lr: 0.000387  min_lr: 0.000387  loss: 1.1097 (1.1689)  class_acc: 0.7031 (0.6958)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0008  max mem: 8477\n","Epoch: [1]  [120/781]  eta: 0:10:53  lr: 0.000387  min_lr: 0.000387  loss: 1.0934 (1.1627)  class_acc: 0.7031 (0.6987)  weight_decay: 0.0500 (0.0500)  time: 0.9665  data: 0.0009  max mem: 8477\n","Epoch: [1]  [130/781]  eta: 0:10:42  lr: 0.000387  min_lr: 0.000387  loss: 1.1489 (1.1686)  class_acc: 0.6875 (0.6960)  weight_decay: 0.0500 (0.0500)  time: 0.9660  data: 0.0009  max mem: 8477\n","Epoch: [1]  [140/781]  eta: 0:10:32  lr: 0.000386  min_lr: 0.000386  loss: 1.1692 (1.1681)  class_acc: 0.6875 (0.6958)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0015  max mem: 8477\n","Epoch: [1]  [150/781]  eta: 0:10:21  lr: 0.000386  min_lr: 0.000386  loss: 1.1348 (1.1660)  class_acc: 0.7031 (0.6970)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0018  max mem: 8477\n","Epoch: [1]  [160/781]  eta: 0:10:11  lr: 0.000386  min_lr: 0.000386  loss: 1.1194 (1.1651)  class_acc: 0.7031 (0.6976)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0009  max mem: 8477\n","Epoch: [1]  [170/781]  eta: 0:10:01  lr: 0.000386  min_lr: 0.000386  loss: 1.1710 (1.1668)  class_acc: 0.6875 (0.6974)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0007  max mem: 8477\n","Epoch: [1]  [180/781]  eta: 0:09:50  lr: 0.000385  min_lr: 0.000385  loss: 1.1783 (1.1688)  class_acc: 0.6875 (0.6973)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0008  max mem: 8477\n","Epoch: [1]  [190/781]  eta: 0:09:40  lr: 0.000385  min_lr: 0.000385  loss: 1.1401 (1.1652)  class_acc: 0.7188 (0.6992)  weight_decay: 0.0500 (0.0500)  time: 0.9726  data: 0.0007  max mem: 8477\n","Epoch: [1]  [200/781]  eta: 0:09:30  lr: 0.000385  min_lr: 0.000385  loss: 1.1123 (1.1646)  class_acc: 0.7188 (0.6999)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0015  max mem: 8477\n","Epoch: [1]  [210/781]  eta: 0:09:20  lr: 0.000384  min_lr: 0.000384  loss: 1.1429 (1.1649)  class_acc: 0.7031 (0.6998)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0019  max mem: 8477\n","Epoch: [1]  [220/781]  eta: 0:09:10  lr: 0.000384  min_lr: 0.000384  loss: 1.1429 (1.1637)  class_acc: 0.7031 (0.7004)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0012  max mem: 8477\n","Epoch: [1]  [230/781]  eta: 0:09:00  lr: 0.000384  min_lr: 0.000384  loss: 1.1918 (1.1663)  class_acc: 0.7031 (0.6994)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0008  max mem: 8477\n","Epoch: [1]  [240/781]  eta: 0:08:50  lr: 0.000383  min_lr: 0.000383  loss: 1.1848 (1.1667)  class_acc: 0.6875 (0.6994)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0010  max mem: 8477\n","Epoch: [1]  [250/781]  eta: 0:08:40  lr: 0.000383  min_lr: 0.000383  loss: 1.1548 (1.1663)  class_acc: 0.6875 (0.6996)  weight_decay: 0.0500 (0.0500)  time: 0.9730  data: 0.0012  max mem: 8477\n","Epoch: [1]  [260/781]  eta: 0:08:30  lr: 0.000383  min_lr: 0.000383  loss: 1.0672 (1.1626)  class_acc: 0.7344 (0.7022)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0011  max mem: 8477\n","Epoch: [1]  [270/781]  eta: 0:08:20  lr: 0.000382  min_lr: 0.000382  loss: 1.0908 (1.1623)  class_acc: 0.7188 (0.7020)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0010  max mem: 8477\n","Epoch: [1]  [280/781]  eta: 0:08:10  lr: 0.000382  min_lr: 0.000382  loss: 1.1157 (1.1615)  class_acc: 0.7031 (0.7028)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0012  max mem: 8477\n","Epoch: [1]  [290/781]  eta: 0:08:00  lr: 0.000382  min_lr: 0.000382  loss: 1.1157 (1.1609)  class_acc: 0.7031 (0.7033)  weight_decay: 0.0500 (0.0500)  time: 0.9646  data: 0.0013  max mem: 8477\n","Epoch: [1]  [300/781]  eta: 0:07:50  lr: 0.000381  min_lr: 0.000381  loss: 1.1614 (1.1614)  class_acc: 0.7031 (0.7035)  weight_decay: 0.0500 (0.0500)  time: 0.9622  data: 0.0009  max mem: 8477\n","Epoch: [1]  [310/781]  eta: 0:07:40  lr: 0.000381  min_lr: 0.000381  loss: 1.1266 (1.1594)  class_acc: 0.7188 (0.7043)  weight_decay: 0.0500 (0.0500)  time: 0.9636  data: 0.0018  max mem: 8477\n","Epoch: [1]  [320/781]  eta: 0:07:30  lr: 0.000381  min_lr: 0.000381  loss: 1.1004 (1.1567)  class_acc: 0.7344 (0.7059)  weight_decay: 0.0500 (0.0500)  time: 0.9651  data: 0.0021  max mem: 8477\n","Epoch: [1]  [330/781]  eta: 0:07:20  lr: 0.000380  min_lr: 0.000380  loss: 1.0708 (1.1557)  class_acc: 0.7500 (0.7065)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0010  max mem: 8477\n","Epoch: [1]  [340/781]  eta: 0:07:10  lr: 0.000380  min_lr: 0.000380  loss: 1.1179 (1.1548)  class_acc: 0.7188 (0.7070)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0010  max mem: 8477\n","Epoch: [1]  [350/781]  eta: 0:07:00  lr: 0.000380  min_lr: 0.000380  loss: 1.1543 (1.1553)  class_acc: 0.6875 (0.7064)  weight_decay: 0.0500 (0.0500)  time: 0.9644  data: 0.0013  max mem: 8477\n","Epoch: [1]  [360/781]  eta: 0:06:50  lr: 0.000379  min_lr: 0.000379  loss: 1.1714 (1.1549)  class_acc: 0.6875 (0.7064)  weight_decay: 0.0500 (0.0500)  time: 0.9646  data: 0.0013  max mem: 8477\n","Epoch: [1]  [370/781]  eta: 0:06:41  lr: 0.000379  min_lr: 0.000379  loss: 1.1477 (1.1550)  class_acc: 0.7031 (0.7063)  weight_decay: 0.0500 (0.0500)  time: 0.9662  data: 0.0010  max mem: 8477\n","Epoch: [1]  [380/781]  eta: 0:06:31  lr: 0.000379  min_lr: 0.000379  loss: 1.1326 (1.1536)  class_acc: 0.7188 (0.7073)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0009  max mem: 8477\n","Epoch: [1]  [390/781]  eta: 0:06:21  lr: 0.000378  min_lr: 0.000378  loss: 1.0856 (1.1525)  class_acc: 0.7500 (0.7080)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0009  max mem: 8477\n","Epoch: [1]  [400/781]  eta: 0:06:11  lr: 0.000378  min_lr: 0.000378  loss: 1.1178 (1.1516)  class_acc: 0.7188 (0.7083)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0008  max mem: 8477\n","Epoch: [1]  [410/781]  eta: 0:06:01  lr: 0.000378  min_lr: 0.000378  loss: 1.1226 (1.1512)  class_acc: 0.7188 (0.7084)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0012  max mem: 8477\n","Epoch: [1]  [420/781]  eta: 0:05:51  lr: 0.000377  min_lr: 0.000377  loss: 1.1252 (1.1510)  class_acc: 0.7031 (0.7081)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0025  max mem: 8477\n","Epoch: [1]  [430/781]  eta: 0:05:42  lr: 0.000377  min_lr: 0.000377  loss: 1.1359 (1.1508)  class_acc: 0.7031 (0.7084)  weight_decay: 0.0500 (0.0500)  time: 0.9681  data: 0.0024  max mem: 8477\n","Epoch: [1]  [440/781]  eta: 0:05:32  lr: 0.000376  min_lr: 0.000376  loss: 1.1333 (1.1508)  class_acc: 0.7188 (0.7084)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0013  max mem: 8477\n","Epoch: [1]  [450/781]  eta: 0:05:22  lr: 0.000376  min_lr: 0.000376  loss: 1.1212 (1.1500)  class_acc: 0.7188 (0.7090)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0012  max mem: 8477\n","Epoch: [1]  [460/781]  eta: 0:05:12  lr: 0.000376  min_lr: 0.000376  loss: 1.0923 (1.1498)  class_acc: 0.7188 (0.7091)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0011  max mem: 8477\n","Epoch: [1]  [470/781]  eta: 0:05:03  lr: 0.000375  min_lr: 0.000375  loss: 1.1425 (1.1488)  class_acc: 0.7031 (0.7094)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0012  max mem: 8477\n","Epoch: [1]  [480/781]  eta: 0:04:53  lr: 0.000375  min_lr: 0.000375  loss: 1.1210 (1.1481)  class_acc: 0.7031 (0.7097)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0013  max mem: 8477\n","Epoch: [1]  [490/781]  eta: 0:04:43  lr: 0.000374  min_lr: 0.000374  loss: 1.1210 (1.1480)  class_acc: 0.7031 (0.7097)  weight_decay: 0.0500 (0.0500)  time: 0.9677  data: 0.0007  max mem: 8477\n","Epoch: [1]  [500/781]  eta: 0:04:33  lr: 0.000374  min_lr: 0.000374  loss: 1.1296 (1.1481)  class_acc: 0.7188 (0.7099)  weight_decay: 0.0500 (0.0500)  time: 0.9675  data: 0.0006  max mem: 8477\n","Epoch: [1]  [510/781]  eta: 0:04:23  lr: 0.000374  min_lr: 0.000374  loss: 1.1192 (1.1477)  class_acc: 0.7188 (0.7102)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0008  max mem: 8477\n","Epoch: [1]  [520/781]  eta: 0:04:14  lr: 0.000373  min_lr: 0.000373  loss: 1.0907 (1.1475)  class_acc: 0.7188 (0.7105)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0008  max mem: 8477\n","Epoch: [1]  [530/781]  eta: 0:04:04  lr: 0.000373  min_lr: 0.000373  loss: 1.1432 (1.1482)  class_acc: 0.7031 (0.7102)  weight_decay: 0.0500 (0.0500)  time: 0.9687  data: 0.0022  max mem: 8477\n","Epoch: [1]  [540/781]  eta: 0:03:54  lr: 0.000372  min_lr: 0.000372  loss: 1.1605 (1.1478)  class_acc: 0.6875 (0.7103)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0023  max mem: 8477\n","Epoch: [1]  [550/781]  eta: 0:03:44  lr: 0.000372  min_lr: 0.000372  loss: 1.0962 (1.1463)  class_acc: 0.7344 (0.7111)  weight_decay: 0.0500 (0.0500)  time: 0.9738  data: 0.0012  max mem: 8477\n","Epoch: [1]  [560/781]  eta: 0:03:35  lr: 0.000372  min_lr: 0.000372  loss: 1.0520 (1.1452)  class_acc: 0.7500 (0.7117)  weight_decay: 0.0500 (0.0500)  time: 0.9704  data: 0.0011  max mem: 8477\n","Epoch: [1]  [570/781]  eta: 0:03:25  lr: 0.000371  min_lr: 0.000371  loss: 1.0935 (1.1454)  class_acc: 0.7188 (0.7115)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0011  max mem: 8477\n","Epoch: [1]  [580/781]  eta: 0:03:15  lr: 0.000371  min_lr: 0.000371  loss: 1.1512 (1.1450)  class_acc: 0.7188 (0.7117)  weight_decay: 0.0500 (0.0500)  time: 0.9661  data: 0.0012  max mem: 8477\n","Epoch: [1]  [590/781]  eta: 0:03:05  lr: 0.000370  min_lr: 0.000370  loss: 1.0675 (1.1437)  class_acc: 0.7344 (0.7120)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0010  max mem: 8477\n","Epoch: [1]  [600/781]  eta: 0:02:56  lr: 0.000370  min_lr: 0.000370  loss: 1.0779 (1.1430)  class_acc: 0.7188 (0.7122)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0011  max mem: 8477\n","Epoch: [1]  [610/781]  eta: 0:02:46  lr: 0.000370  min_lr: 0.000370  loss: 1.1081 (1.1425)  class_acc: 0.7188 (0.7125)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0011  max mem: 8477\n","Epoch: [1]  [620/781]  eta: 0:02:36  lr: 0.000369  min_lr: 0.000369  loss: 1.1191 (1.1422)  class_acc: 0.7188 (0.7126)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0007  max mem: 8477\n","Epoch: [1]  [630/781]  eta: 0:02:26  lr: 0.000369  min_lr: 0.000369  loss: 1.1435 (1.1427)  class_acc: 0.7188 (0.7125)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0009  max mem: 8477\n","Epoch: [1]  [640/781]  eta: 0:02:17  lr: 0.000368  min_lr: 0.000368  loss: 1.1341 (1.1416)  class_acc: 0.7344 (0.7133)  weight_decay: 0.0500 (0.0500)  time: 0.9699  data: 0.0021  max mem: 8477\n","Epoch: [1]  [650/781]  eta: 0:02:07  lr: 0.000368  min_lr: 0.000368  loss: 1.0408 (1.1400)  class_acc: 0.7656 (0.7140)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0021  max mem: 8477\n","Epoch: [1]  [660/781]  eta: 0:01:57  lr: 0.000367  min_lr: 0.000367  loss: 1.0689 (1.1398)  class_acc: 0.7344 (0.7141)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0010  max mem: 8477\n","Epoch: [1]  [670/781]  eta: 0:01:48  lr: 0.000367  min_lr: 0.000367  loss: 1.1281 (1.1390)  class_acc: 0.7344 (0.7147)  weight_decay: 0.0500 (0.0500)  time: 0.9676  data: 0.0012  max mem: 8477\n","Epoch: [1]  [680/781]  eta: 0:01:38  lr: 0.000367  min_lr: 0.000367  loss: 1.1281 (1.1389)  class_acc: 0.7344 (0.7151)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0012  max mem: 8477\n","Epoch: [1]  [690/781]  eta: 0:01:28  lr: 0.000366  min_lr: 0.000366  loss: 1.0984 (1.1380)  class_acc: 0.7344 (0.7152)  weight_decay: 0.0500 (0.0500)  time: 0.9645  data: 0.0007  max mem: 8477\n","Epoch: [1]  [700/781]  eta: 0:01:18  lr: 0.000366  min_lr: 0.000366  loss: 1.0808 (1.1378)  class_acc: 0.7344 (0.7150)  weight_decay: 0.0500 (0.0500)  time: 0.9611  data: 0.0008  max mem: 8477\n","Epoch: [1]  [710/781]  eta: 0:01:09  lr: 0.000365  min_lr: 0.000365  loss: 1.1071 (1.1370)  class_acc: 0.7344 (0.7156)  weight_decay: 0.0500 (0.0500)  time: 0.9628  data: 0.0010  max mem: 8477\n","Epoch: [1]  [720/781]  eta: 0:00:59  lr: 0.000365  min_lr: 0.000365  loss: 1.1007 (1.1366)  class_acc: 0.7344 (0.7155)  weight_decay: 0.0500 (0.0500)  time: 0.9661  data: 0.0008  max mem: 8477\n","Epoch: [1]  [730/781]  eta: 0:00:49  lr: 0.000364  min_lr: 0.000364  loss: 1.1331 (1.1366)  class_acc: 0.7188 (0.7154)  weight_decay: 0.0500 (0.0500)  time: 0.9662  data: 0.0011  max mem: 8477\n","Epoch: [1]  [740/781]  eta: 0:00:39  lr: 0.000364  min_lr: 0.000364  loss: 1.1401 (1.1366)  class_acc: 0.6875 (0.7153)  weight_decay: 0.0500 (0.0500)  time: 0.9653  data: 0.0015  max mem: 8477\n","Epoch: [1]  [750/781]  eta: 0:00:30  lr: 0.000363  min_lr: 0.000363  loss: 1.0831 (1.1359)  class_acc: 0.7031 (0.7157)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0026  max mem: 8477\n","Epoch: [1]  [760/781]  eta: 0:00:20  lr: 0.000363  min_lr: 0.000363  loss: 1.0831 (1.1356)  class_acc: 0.7188 (0.7158)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0024  max mem: 8477\n","Epoch: [1]  [770/781]  eta: 0:00:10  lr: 0.000362  min_lr: 0.000362  loss: 1.0672 (1.1351)  class_acc: 0.7344 (0.7160)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0010  max mem: 8477\n","Epoch: [1]  [780/781]  eta: 0:00:00  lr: 0.000362  min_lr: 0.000362  loss: 1.0409 (1.1343)  class_acc: 0.7500 (0.7165)  weight_decay: 0.0500 (0.0500)  time: 0.9650  data: 0.0006  max mem: 8477\n","Epoch: [1] Total time: 0:12:39 (0.9724 s / it)\n","Averaged stats: lr: 0.000362  min_lr: 0.000362  loss: 1.0409 (1.1343)  class_acc: 0.7500 (0.7165)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:05:19  loss: 0.4039 (0.4039)  acc1: 90.6250 (90.6250)  acc5: 100.0000 (100.0000)  time: 3.0406  data: 2.5256  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:07  loss: 0.3119 (0.3350)  acc1: 91.6667 (90.9091)  acc5: 100.0000 (100.0000)  time: 0.7071  data: 0.2303  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:50  loss: 0.2807 (0.2940)  acc1: 92.7083 (92.5595)  acc5: 100.0000 (99.9504)  time: 0.4754  data: 0.0013  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:42  loss: 0.3495 (0.3428)  acc1: 90.6250 (90.7930)  acc5: 100.0000 (99.9664)  time: 0.4799  data: 0.0010  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:35  loss: 0.5154 (0.4078)  acc1: 84.3750 (88.1860)  acc5: 100.0000 (99.9238)  time: 0.4853  data: 0.0003  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.4840 (0.3779)  acc1: 86.4583 (89.3995)  acc5: 100.0000 (99.9387)  time: 0.4871  data: 0.0003  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2887 (0.3872)  acc1: 90.6250 (89.0027)  acc5: 100.0000 (99.8292)  time: 0.4866  data: 0.0006  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.2618 (0.3594)  acc1: 90.6250 (90.1408)  acc5: 100.0000 (99.8093)  time: 0.4873  data: 0.0006  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.2274 (0.3541)  acc1: 94.7917 (90.4835)  acc5: 100.0000 (99.7814)  time: 0.4878  data: 0.0003  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.2342 (0.3432)  acc1: 93.7500 (90.8883)  acc5: 100.0000 (99.7825)  time: 0.4860  data: 0.0008  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1941 (0.3286)  acc1: 95.8333 (91.4604)  acc5: 100.0000 (99.7937)  time: 0.4857  data: 0.0007  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1829 (0.3222)  acc1: 96.8750 (91.6600)  acc5: 100.0000 (99.8000)  time: 0.4662  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5076 s / it)\n","* Acc@1 91.660 Acc@5 99.800 loss 0.322\n","Accuracy of the model on the 10000 test images: 91.7%\n","Max accuracy: 91.66%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [2]  [  0/781]  eta: 0:40:38  lr: 0.000362  min_lr: 0.000362  loss: 1.2116 (1.2116)  class_acc: 0.7031 (0.7031)  weight_decay: 0.0500 (0.0500)  time: 3.1222  data: 2.0712  max mem: 8477\n","Epoch: [2]  [ 10/781]  eta: 0:14:55  lr: 0.000361  min_lr: 0.000361  loss: 1.0987 (1.1244)  class_acc: 0.7500 (0.7315)  weight_decay: 0.0500 (0.0500)  time: 1.1621  data: 0.1889  max mem: 8477\n","Epoch: [2]  [ 20/781]  eta: 0:13:34  lr: 0.000361  min_lr: 0.000361  loss: 1.0743 (1.1003)  class_acc: 0.7500 (0.7403)  weight_decay: 0.0500 (0.0500)  time: 0.9675  data: 0.0015  max mem: 8477\n","Epoch: [2]  [ 30/781]  eta: 0:13:00  lr: 0.000360  min_lr: 0.000360  loss: 1.0670 (1.0940)  class_acc: 0.7344 (0.7354)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0015  max mem: 8477\n","Epoch: [2]  [ 40/781]  eta: 0:12:38  lr: 0.000360  min_lr: 0.000360  loss: 1.1136 (1.1145)  class_acc: 0.7188 (0.7290)  weight_decay: 0.0500 (0.0500)  time: 0.9737  data: 0.0008  max mem: 8477\n","Epoch: [2]  [ 50/781]  eta: 0:12:20  lr: 0.000360  min_lr: 0.000360  loss: 1.1167 (1.1212)  class_acc: 0.7188 (0.7243)  weight_decay: 0.0500 (0.0500)  time: 0.9747  data: 0.0009  max mem: 8477\n","Epoch: [2]  [ 60/781]  eta: 0:12:05  lr: 0.000359  min_lr: 0.000359  loss: 1.0961 (1.1183)  class_acc: 0.7344 (0.7267)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0011  max mem: 8477\n","Epoch: [2]  [ 70/781]  eta: 0:11:51  lr: 0.000359  min_lr: 0.000359  loss: 1.0906 (1.1143)  class_acc: 0.7344 (0.7276)  weight_decay: 0.0500 (0.0500)  time: 0.9686  data: 0.0011  max mem: 8477\n","Epoch: [2]  [ 80/781]  eta: 0:11:38  lr: 0.000358  min_lr: 0.000358  loss: 1.0881 (1.1110)  class_acc: 0.7188 (0.7294)  weight_decay: 0.0500 (0.0500)  time: 0.9651  data: 0.0010  max mem: 8477\n","Epoch: [2]  [ 90/781]  eta: 0:11:25  lr: 0.000358  min_lr: 0.000358  loss: 1.0887 (1.1115)  class_acc: 0.7188 (0.7272)  weight_decay: 0.0500 (0.0500)  time: 0.9623  data: 0.0010  max mem: 8477\n","Epoch: [2]  [100/781]  eta: 0:11:13  lr: 0.000357  min_lr: 0.000357  loss: 1.0701 (1.1054)  class_acc: 0.7344 (0.7311)  weight_decay: 0.0500 (0.0500)  time: 0.9614  data: 0.0012  max mem: 8477\n","Epoch: [2]  [110/781]  eta: 0:11:01  lr: 0.000357  min_lr: 0.000357  loss: 1.0780 (1.1050)  class_acc: 0.7500 (0.7304)  weight_decay: 0.0500 (0.0500)  time: 0.9598  data: 0.0011  max mem: 8477\n","Epoch: [2]  [120/781]  eta: 0:10:50  lr: 0.000356  min_lr: 0.000356  loss: 1.0967 (1.1018)  class_acc: 0.7500 (0.7324)  weight_decay: 0.0500 (0.0500)  time: 0.9600  data: 0.0008  max mem: 8477\n","Epoch: [2]  [130/781]  eta: 0:10:39  lr: 0.000356  min_lr: 0.000356  loss: 1.0449 (1.1024)  class_acc: 0.7500 (0.7329)  weight_decay: 0.0500 (0.0500)  time: 0.9592  data: 0.0013  max mem: 8477\n","Epoch: [2]  [140/781]  eta: 0:10:28  lr: 0.000355  min_lr: 0.000355  loss: 1.0337 (1.0990)  class_acc: 0.7500 (0.7345)  weight_decay: 0.0500 (0.0500)  time: 0.9579  data: 0.0014  max mem: 8477\n","Epoch: [2]  [150/781]  eta: 0:10:18  lr: 0.000355  min_lr: 0.000355  loss: 1.0329 (1.0983)  class_acc: 0.7500 (0.7344)  weight_decay: 0.0500 (0.0500)  time: 0.9619  data: 0.0012  max mem: 8477\n","Epoch: [2]  [160/781]  eta: 0:10:08  lr: 0.000354  min_lr: 0.000354  loss: 1.0114 (1.0938)  class_acc: 0.7656 (0.7368)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0011  max mem: 8477\n","Epoch: [2]  [170/781]  eta: 0:09:58  lr: 0.000354  min_lr: 0.000354  loss: 1.0642 (1.0947)  class_acc: 0.7500 (0.7364)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0006  max mem: 8477\n","Epoch: [2]  [180/781]  eta: 0:09:48  lr: 0.000353  min_lr: 0.000353  loss: 1.1053 (1.0968)  class_acc: 0.7188 (0.7358)  weight_decay: 0.0500 (0.0500)  time: 0.9746  data: 0.0007  max mem: 8477\n","Epoch: [2]  [190/781]  eta: 0:09:38  lr: 0.000352  min_lr: 0.000352  loss: 1.0754 (1.0936)  class_acc: 0.7500 (0.7375)  weight_decay: 0.0500 (0.0500)  time: 0.9743  data: 0.0012  max mem: 8477\n","Epoch: [2]  [200/781]  eta: 0:09:28  lr: 0.000352  min_lr: 0.000352  loss: 1.0291 (1.0901)  class_acc: 0.7656 (0.7397)  weight_decay: 0.0500 (0.0500)  time: 0.9741  data: 0.0011  max mem: 8477\n","Epoch: [2]  [210/781]  eta: 0:09:18  lr: 0.000351  min_lr: 0.000351  loss: 1.0433 (1.0884)  class_acc: 0.7656 (0.7410)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0008  max mem: 8477\n","Epoch: [2]  [220/781]  eta: 0:09:08  lr: 0.000351  min_lr: 0.000351  loss: 1.0551 (1.0864)  class_acc: 0.7500 (0.7410)  weight_decay: 0.0500 (0.0500)  time: 0.9659  data: 0.0011  max mem: 8477\n","Epoch: [2]  [230/781]  eta: 0:08:58  lr: 0.000350  min_lr: 0.000350  loss: 1.0608 (1.0864)  class_acc: 0.7344 (0.7407)  weight_decay: 0.0500 (0.0500)  time: 0.9650  data: 0.0008  max mem: 8477\n","Epoch: [2]  [240/781]  eta: 0:08:47  lr: 0.000350  min_lr: 0.000350  loss: 1.0693 (1.0863)  class_acc: 0.7500 (0.7409)  weight_decay: 0.0500 (0.0500)  time: 0.9634  data: 0.0020  max mem: 8477\n","Epoch: [2]  [250/781]  eta: 0:08:37  lr: 0.000349  min_lr: 0.000349  loss: 1.0828 (1.0867)  class_acc: 0.7344 (0.7404)  weight_decay: 0.0500 (0.0500)  time: 0.9627  data: 0.0021  max mem: 8477\n","Epoch: [2]  [260/781]  eta: 0:08:27  lr: 0.000349  min_lr: 0.000349  loss: 1.0935 (1.0881)  class_acc: 0.7344 (0.7401)  weight_decay: 0.0500 (0.0500)  time: 0.9613  data: 0.0010  max mem: 8477\n","Epoch: [2]  [270/781]  eta: 0:08:17  lr: 0.000348  min_lr: 0.000348  loss: 1.1010 (1.0885)  class_acc: 0.7344 (0.7404)  weight_decay: 0.0500 (0.0500)  time: 0.9590  data: 0.0012  max mem: 8477\n","Epoch: [2]  [280/781]  eta: 0:08:07  lr: 0.000348  min_lr: 0.000348  loss: 1.1010 (1.0907)  class_acc: 0.7344 (0.7394)  weight_decay: 0.0500 (0.0500)  time: 0.9586  data: 0.0008  max mem: 8477\n","Epoch: [2]  [290/781]  eta: 0:07:57  lr: 0.000347  min_lr: 0.000347  loss: 1.0660 (1.0891)  class_acc: 0.7500 (0.7405)  weight_decay: 0.0500 (0.0500)  time: 0.9589  data: 0.0004  max mem: 8477\n","Epoch: [2]  [300/781]  eta: 0:07:47  lr: 0.000347  min_lr: 0.000347  loss: 1.0541 (1.0892)  class_acc: 0.7500 (0.7403)  weight_decay: 0.0500 (0.0500)  time: 0.9612  data: 0.0006  max mem: 8477\n","Epoch: [2]  [310/781]  eta: 0:07:38  lr: 0.000346  min_lr: 0.000346  loss: 1.0541 (1.0877)  class_acc: 0.7500 (0.7411)  weight_decay: 0.0500 (0.0500)  time: 0.9629  data: 0.0014  max mem: 8477\n","Epoch: [2]  [320/781]  eta: 0:07:28  lr: 0.000346  min_lr: 0.000346  loss: 1.0497 (1.0855)  class_acc: 0.7500 (0.7420)  weight_decay: 0.0500 (0.0500)  time: 0.9629  data: 0.0014  max mem: 8477\n","Epoch: [2]  [330/781]  eta: 0:07:18  lr: 0.000345  min_lr: 0.000345  loss: 1.0602 (1.0849)  class_acc: 0.7344 (0.7419)  weight_decay: 0.0500 (0.0500)  time: 0.9643  data: 0.0010  max mem: 8477\n","Epoch: [2]  [340/781]  eta: 0:07:08  lr: 0.000344  min_lr: 0.000344  loss: 1.0841 (1.0841)  class_acc: 0.7188 (0.7422)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0012  max mem: 8477\n","Epoch: [2]  [350/781]  eta: 0:06:58  lr: 0.000344  min_lr: 0.000344  loss: 1.0332 (1.0832)  class_acc: 0.7656 (0.7427)  weight_decay: 0.0500 (0.0500)  time: 0.9678  data: 0.0027  max mem: 8477\n","Epoch: [2]  [360/781]  eta: 0:06:49  lr: 0.000343  min_lr: 0.000343  loss: 1.0492 (1.0836)  class_acc: 0.7500 (0.7426)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0027  max mem: 8477\n","Epoch: [2]  [370/781]  eta: 0:06:39  lr: 0.000343  min_lr: 0.000343  loss: 1.0697 (1.0835)  class_acc: 0.7344 (0.7422)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0009  max mem: 8477\n","Epoch: [2]  [380/781]  eta: 0:06:29  lr: 0.000342  min_lr: 0.000342  loss: 1.0811 (1.0838)  class_acc: 0.7344 (0.7420)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0008  max mem: 8477\n","Epoch: [2]  [390/781]  eta: 0:06:19  lr: 0.000342  min_lr: 0.000342  loss: 1.0235 (1.0816)  class_acc: 0.7500 (0.7429)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0012  max mem: 8477\n","Epoch: [2]  [400/781]  eta: 0:06:10  lr: 0.000341  min_lr: 0.000341  loss: 0.9951 (1.0795)  class_acc: 0.7500 (0.7436)  weight_decay: 0.0500 (0.0500)  time: 0.9738  data: 0.0011  max mem: 8477\n","Epoch: [2]  [410/781]  eta: 0:06:00  lr: 0.000340  min_lr: 0.000340  loss: 1.0169 (1.0797)  class_acc: 0.7500 (0.7436)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0009  max mem: 8477\n","Epoch: [2]  [420/781]  eta: 0:05:50  lr: 0.000340  min_lr: 0.000340  loss: 1.0358 (1.0793)  class_acc: 0.7344 (0.7438)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0008  max mem: 8477\n","Epoch: [2]  [430/781]  eta: 0:05:41  lr: 0.000339  min_lr: 0.000339  loss: 1.0225 (1.0780)  class_acc: 0.7344 (0.7441)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0007  max mem: 8477\n","Epoch: [2]  [440/781]  eta: 0:05:31  lr: 0.000339  min_lr: 0.000339  loss: 1.0541 (1.0773)  class_acc: 0.7344 (0.7441)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0007  max mem: 8477\n","Epoch: [2]  [450/781]  eta: 0:05:21  lr: 0.000338  min_lr: 0.000338  loss: 1.0585 (1.0768)  class_acc: 0.7500 (0.7440)  weight_decay: 0.0500 (0.0500)  time: 0.9739  data: 0.0007  max mem: 8477\n","Epoch: [2]  [460/781]  eta: 0:05:11  lr: 0.000338  min_lr: 0.000338  loss: 1.0263 (1.0762)  class_acc: 0.7500 (0.7443)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0019  max mem: 8477\n","Epoch: [2]  [470/781]  eta: 0:05:02  lr: 0.000337  min_lr: 0.000337  loss: 1.0448 (1.0771)  class_acc: 0.7500 (0.7438)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0019  max mem: 8477\n","Epoch: [2]  [480/781]  eta: 0:04:52  lr: 0.000336  min_lr: 0.000336  loss: 1.0644 (1.0770)  class_acc: 0.7188 (0.7437)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0009  max mem: 8477\n","Epoch: [2]  [490/781]  eta: 0:04:42  lr: 0.000336  min_lr: 0.000336  loss: 1.0687 (1.0774)  class_acc: 0.7344 (0.7437)  weight_decay: 0.0500 (0.0500)  time: 0.9718  data: 0.0013  max mem: 8477\n","Epoch: [2]  [500/781]  eta: 0:04:33  lr: 0.000335  min_lr: 0.000335  loss: 1.0879 (1.0773)  class_acc: 0.7344 (0.7435)  weight_decay: 0.0500 (0.0500)  time: 0.9706  data: 0.0019  max mem: 8477\n","Epoch: [2]  [510/781]  eta: 0:04:23  lr: 0.000335  min_lr: 0.000335  loss: 1.0929 (1.0776)  class_acc: 0.7188 (0.7429)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0019  max mem: 8477\n","Epoch: [2]  [520/781]  eta: 0:04:13  lr: 0.000334  min_lr: 0.000334  loss: 1.0707 (1.0778)  class_acc: 0.7188 (0.7426)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0016  max mem: 8477\n","Epoch: [2]  [530/781]  eta: 0:04:03  lr: 0.000333  min_lr: 0.000333  loss: 1.0597 (1.0772)  class_acc: 0.7344 (0.7426)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0017  max mem: 8477\n","Epoch: [2]  [540/781]  eta: 0:03:54  lr: 0.000333  min_lr: 0.000333  loss: 1.0348 (1.0759)  class_acc: 0.7344 (0.7432)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0018  max mem: 8477\n","Epoch: [2]  [550/781]  eta: 0:03:44  lr: 0.000332  min_lr: 0.000332  loss: 1.0338 (1.0760)  class_acc: 0.7500 (0.7429)  weight_decay: 0.0500 (0.0500)  time: 0.9746  data: 0.0019  max mem: 8477\n","Epoch: [2]  [560/781]  eta: 0:03:34  lr: 0.000332  min_lr: 0.000332  loss: 1.0682 (1.0759)  class_acc: 0.7344 (0.7426)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0022  max mem: 8477\n","Epoch: [2]  [570/781]  eta: 0:03:25  lr: 0.000331  min_lr: 0.000331  loss: 1.0682 (1.0758)  class_acc: 0.7344 (0.7428)  weight_decay: 0.0500 (0.0500)  time: 0.9684  data: 0.0018  max mem: 8477\n","Epoch: [2]  [580/781]  eta: 0:03:15  lr: 0.000330  min_lr: 0.000330  loss: 1.0522 (1.0751)  class_acc: 0.7500 (0.7432)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0012  max mem: 8477\n","Epoch: [2]  [590/781]  eta: 0:03:05  lr: 0.000330  min_lr: 0.000330  loss: 1.0498 (1.0743)  class_acc: 0.7812 (0.7439)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0011  max mem: 8477\n","Epoch: [2]  [600/781]  eta: 0:02:55  lr: 0.000329  min_lr: 0.000329  loss: 1.0576 (1.0745)  class_acc: 0.7500 (0.7437)  weight_decay: 0.0500 (0.0500)  time: 0.9726  data: 0.0011  max mem: 8477\n","Epoch: [2]  [610/781]  eta: 0:02:46  lr: 0.000329  min_lr: 0.000329  loss: 1.0643 (1.0746)  class_acc: 0.7344 (0.7436)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0009  max mem: 8477\n","Epoch: [2]  [620/781]  eta: 0:02:36  lr: 0.000328  min_lr: 0.000328  loss: 1.0694 (1.0749)  class_acc: 0.7188 (0.7434)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0009  max mem: 8477\n","Epoch: [2]  [630/781]  eta: 0:02:26  lr: 0.000327  min_lr: 0.000327  loss: 1.0617 (1.0748)  class_acc: 0.7188 (0.7433)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0009  max mem: 8477\n","Epoch: [2]  [640/781]  eta: 0:02:16  lr: 0.000327  min_lr: 0.000327  loss: 1.0563 (1.0749)  class_acc: 0.7188 (0.7432)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0010  max mem: 8477\n","Epoch: [2]  [650/781]  eta: 0:02:07  lr: 0.000326  min_lr: 0.000326  loss: 1.0544 (1.0745)  class_acc: 0.7500 (0.7433)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0014  max mem: 8477\n","Epoch: [2]  [660/781]  eta: 0:01:57  lr: 0.000325  min_lr: 0.000325  loss: 1.0307 (1.0742)  class_acc: 0.7656 (0.7435)  weight_decay: 0.0500 (0.0500)  time: 0.9736  data: 0.0013  max mem: 8477\n","Epoch: [2]  [670/781]  eta: 0:01:47  lr: 0.000325  min_lr: 0.000325  loss: 1.0244 (1.0734)  class_acc: 0.7812 (0.7439)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0020  max mem: 8477\n","Epoch: [2]  [680/781]  eta: 0:01:38  lr: 0.000324  min_lr: 0.000324  loss: 1.0359 (1.0741)  class_acc: 0.7500 (0.7436)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0022  max mem: 8477\n","Epoch: [2]  [690/781]  eta: 0:01:28  lr: 0.000324  min_lr: 0.000324  loss: 1.1187 (1.0741)  class_acc: 0.7500 (0.7438)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0010  max mem: 8477\n","Epoch: [2]  [700/781]  eta: 0:01:18  lr: 0.000323  min_lr: 0.000323  loss: 1.1094 (1.0743)  class_acc: 0.7344 (0.7435)  weight_decay: 0.0500 (0.0500)  time: 0.9733  data: 0.0005  max mem: 8477\n","Epoch: [2]  [710/781]  eta: 0:01:08  lr: 0.000322  min_lr: 0.000322  loss: 1.0845 (1.0741)  class_acc: 0.7344 (0.7439)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0008  max mem: 8477\n","Epoch: [2]  [720/781]  eta: 0:00:59  lr: 0.000322  min_lr: 0.000322  loss: 1.0290 (1.0737)  class_acc: 0.7344 (0.7440)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0013  max mem: 8477\n","Epoch: [2]  [730/781]  eta: 0:00:49  lr: 0.000321  min_lr: 0.000321  loss: 1.0139 (1.0733)  class_acc: 0.7344 (0.7442)  weight_decay: 0.0500 (0.0500)  time: 0.9710  data: 0.0012  max mem: 8477\n","Epoch: [2]  [740/781]  eta: 0:00:39  lr: 0.000320  min_lr: 0.000320  loss: 1.0418 (1.0735)  class_acc: 0.7500 (0.7442)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0009  max mem: 8477\n","Epoch: [2]  [750/781]  eta: 0:00:30  lr: 0.000320  min_lr: 0.000320  loss: 1.0699 (1.0735)  class_acc: 0.7500 (0.7442)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0010  max mem: 8477\n","Epoch: [2]  [760/781]  eta: 0:00:20  lr: 0.000319  min_lr: 0.000319  loss: 1.0689 (1.0734)  class_acc: 0.7500 (0.7441)  weight_decay: 0.0500 (0.0500)  time: 0.9740  data: 0.0010  max mem: 8477\n","Epoch: [2]  [770/781]  eta: 0:00:10  lr: 0.000318  min_lr: 0.000318  loss: 1.0481 (1.0734)  class_acc: 0.7188 (0.7440)  weight_decay: 0.0500 (0.0500)  time: 0.9706  data: 0.0008  max mem: 8477\n","Epoch: [2]  [780/781]  eta: 0:00:00  lr: 0.000318  min_lr: 0.000318  loss: 1.0527 (1.0733)  class_acc: 0.7188 (0.7439)  weight_decay: 0.0500 (0.0500)  time: 0.9688  data: 0.0007  max mem: 8477\n","Epoch: [2] Total time: 0:12:39 (0.9722 s / it)\n","Averaged stats: lr: 0.000318  min_lr: 0.000318  loss: 1.0527 (1.0733)  class_acc: 0.7188 (0.7439)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:04:38  loss: 0.3100 (0.3100)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 2.6481  data: 2.1170  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:06  loss: 0.2648 (0.2634)  acc1: 93.7500 (93.9394)  acc5: 100.0000 (99.7159)  time: 0.7051  data: 0.2255  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:50  loss: 0.2078 (0.2261)  acc1: 94.7917 (94.9405)  acc5: 100.0000 (99.8512)  time: 0.4944  data: 0.0186  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:42  loss: 0.3264 (0.2917)  acc1: 90.6250 (92.5403)  acc5: 100.0000 (99.7312)  time: 0.4812  data: 0.0015  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:35  loss: 0.4373 (0.3301)  acc1: 87.5000 (91.3872)  acc5: 100.0000 (99.7713)  time: 0.4857  data: 0.0014  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.3533 (0.3077)  acc1: 91.6667 (92.1160)  acc5: 100.0000 (99.7958)  time: 0.4867  data: 0.0009  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2912 (0.3322)  acc1: 89.5833 (91.1373)  acc5: 100.0000 (99.7097)  time: 0.4869  data: 0.0014  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.3147 (0.3172)  acc1: 89.5833 (91.5933)  acc5: 100.0000 (99.7506)  time: 0.4872  data: 0.0014  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.2222 (0.3079)  acc1: 94.7917 (91.9110)  acc5: 100.0000 (99.7428)  time: 0.4871  data: 0.0011  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.2020 (0.2954)  acc1: 94.7917 (92.3649)  acc5: 100.0000 (99.7482)  time: 0.4869  data: 0.0008  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1939 (0.2873)  acc1: 95.8333 (92.6774)  acc5: 100.0000 (99.7731)  time: 0.4871  data: 0.0002  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1982 (0.2846)  acc1: 95.8333 (92.7600)  acc5: 100.0000 (99.7800)  time: 0.4668  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5074 s / it)\n","* Acc@1 92.760 Acc@5 99.780 loss 0.285\n","Accuracy of the model on the 10000 test images: 92.8%\n","Max accuracy: 92.76%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [3]  [  0/781]  eta: 0:48:52  lr: 0.000318  min_lr: 0.000318  loss: 1.2351 (1.2351)  class_acc: 0.6719 (0.6719)  weight_decay: 0.0500 (0.0500)  time: 3.7551  data: 2.7063  max mem: 8477\n","Epoch: [3]  [ 10/781]  eta: 0:15:36  lr: 0.000317  min_lr: 0.000317  loss: 1.0932 (1.0506)  class_acc: 0.7188 (0.7557)  weight_decay: 0.0500 (0.0500)  time: 1.2141  data: 0.2478  max mem: 8477\n","Epoch: [3]  [ 20/781]  eta: 0:13:55  lr: 0.000316  min_lr: 0.000316  loss: 1.0471 (1.0255)  class_acc: 0.7812 (0.7716)  weight_decay: 0.0500 (0.0500)  time: 0.9650  data: 0.0014  max mem: 8477\n","Epoch: [3]  [ 30/781]  eta: 0:13:14  lr: 0.000316  min_lr: 0.000316  loss: 1.0100 (1.0259)  class_acc: 0.7812 (0.7712)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0005  max mem: 8477\n","Epoch: [3]  [ 40/781]  eta: 0:12:49  lr: 0.000315  min_lr: 0.000315  loss: 0.9881 (1.0252)  class_acc: 0.7969 (0.7740)  weight_decay: 0.0500 (0.0500)  time: 0.9750  data: 0.0005  max mem: 8477\n","Epoch: [3]  [ 50/781]  eta: 0:12:29  lr: 0.000314  min_lr: 0.000314  loss: 1.0053 (1.0288)  class_acc: 0.7500 (0.7684)  weight_decay: 0.0500 (0.0500)  time: 0.9745  data: 0.0008  max mem: 8477\n","Epoch: [3]  [ 60/781]  eta: 0:12:12  lr: 0.000314  min_lr: 0.000314  loss: 1.0432 (1.0330)  class_acc: 0.7344 (0.7654)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0009  max mem: 8477\n","Epoch: [3]  [ 70/781]  eta: 0:11:57  lr: 0.000313  min_lr: 0.000313  loss: 1.0597 (1.0368)  class_acc: 0.7500 (0.7636)  weight_decay: 0.0500 (0.0500)  time: 0.9681  data: 0.0011  max mem: 8477\n","Epoch: [3]  [ 80/781]  eta: 0:11:43  lr: 0.000313  min_lr: 0.000313  loss: 1.0214 (1.0307)  class_acc: 0.7656 (0.7668)  weight_decay: 0.0500 (0.0500)  time: 0.9621  data: 0.0014  max mem: 8477\n","Epoch: [3]  [ 90/781]  eta: 0:11:29  lr: 0.000312  min_lr: 0.000312  loss: 0.9704 (1.0289)  class_acc: 0.7812 (0.7665)  weight_decay: 0.0500 (0.0500)  time: 0.9599  data: 0.0010  max mem: 8477\n","Epoch: [3]  [100/781]  eta: 0:11:17  lr: 0.000311  min_lr: 0.000311  loss: 1.0588 (1.0293)  class_acc: 0.7500 (0.7675)  weight_decay: 0.0500 (0.0500)  time: 0.9591  data: 0.0006  max mem: 8477\n","Epoch: [3]  [110/781]  eta: 0:11:05  lr: 0.000311  min_lr: 0.000311  loss: 1.0952 (1.0351)  class_acc: 0.7344 (0.7644)  weight_decay: 0.0500 (0.0500)  time: 0.9598  data: 0.0011  max mem: 8477\n","Epoch: [3]  [120/781]  eta: 0:10:54  lr: 0.000310  min_lr: 0.000310  loss: 1.0830 (1.0344)  class_acc: 0.7656 (0.7659)  weight_decay: 0.0500 (0.0500)  time: 0.9648  data: 0.0010  max mem: 8477\n","Epoch: [3]  [130/781]  eta: 0:10:43  lr: 0.000309  min_lr: 0.000309  loss: 1.0250 (1.0331)  class_acc: 0.7969 (0.7675)  weight_decay: 0.0500 (0.0500)  time: 0.9688  data: 0.0008  max mem: 8477\n","Epoch: [3]  [140/781]  eta: 0:10:32  lr: 0.000308  min_lr: 0.000308  loss: 1.0019 (1.0300)  class_acc: 0.7969 (0.7697)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0010  max mem: 8477\n","Epoch: [3]  [150/781]  eta: 0:10:21  lr: 0.000308  min_lr: 0.000308  loss: 1.0019 (1.0311)  class_acc: 0.7812 (0.7692)  weight_decay: 0.0500 (0.0500)  time: 0.9686  data: 0.0010  max mem: 8477\n","Epoch: [3]  [160/781]  eta: 0:10:11  lr: 0.000307  min_lr: 0.000307  loss: 1.0141 (1.0301)  class_acc: 0.7656 (0.7691)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0015  max mem: 8477\n","Epoch: [3]  [170/781]  eta: 0:10:01  lr: 0.000306  min_lr: 0.000306  loss: 1.0141 (1.0319)  class_acc: 0.7500 (0.7671)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0013  max mem: 8477\n","Epoch: [3]  [180/781]  eta: 0:09:50  lr: 0.000306  min_lr: 0.000306  loss: 1.0326 (1.0319)  class_acc: 0.7500 (0.7675)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0010  max mem: 8477\n","Epoch: [3]  [190/781]  eta: 0:09:40  lr: 0.000305  min_lr: 0.000305  loss: 1.0460 (1.0314)  class_acc: 0.7656 (0.7676)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0014  max mem: 8477\n","Epoch: [3]  [200/781]  eta: 0:09:30  lr: 0.000304  min_lr: 0.000304  loss: 1.0165 (1.0322)  class_acc: 0.7656 (0.7673)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0010  max mem: 8477\n","Epoch: [3]  [210/781]  eta: 0:09:20  lr: 0.000304  min_lr: 0.000304  loss: 1.0438 (1.0333)  class_acc: 0.7656 (0.7665)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0009  max mem: 8477\n","Epoch: [3]  [220/781]  eta: 0:09:10  lr: 0.000303  min_lr: 0.000303  loss: 1.0438 (1.0335)  class_acc: 0.7500 (0.7661)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0014  max mem: 8477\n","Epoch: [3]  [230/781]  eta: 0:09:00  lr: 0.000302  min_lr: 0.000302  loss: 1.0119 (1.0336)  class_acc: 0.7656 (0.7658)  weight_decay: 0.0500 (0.0500)  time: 0.9671  data: 0.0015  max mem: 8477\n","Epoch: [3]  [240/781]  eta: 0:08:49  lr: 0.000302  min_lr: 0.000302  loss: 1.0062 (1.0341)  class_acc: 0.7656 (0.7650)  weight_decay: 0.0500 (0.0500)  time: 0.9662  data: 0.0015  max mem: 8477\n","Epoch: [3]  [250/781]  eta: 0:08:39  lr: 0.000301  min_lr: 0.000301  loss: 1.0459 (1.0348)  class_acc: 0.7500 (0.7649)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0014  max mem: 8477\n","Epoch: [3]  [260/781]  eta: 0:08:29  lr: 0.000300  min_lr: 0.000300  loss: 1.0398 (1.0336)  class_acc: 0.7812 (0.7658)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0024  max mem: 8477\n","Epoch: [3]  [270/781]  eta: 0:08:19  lr: 0.000300  min_lr: 0.000300  loss: 1.0255 (1.0346)  class_acc: 0.7656 (0.7653)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0023  max mem: 8477\n","Epoch: [3]  [280/781]  eta: 0:08:09  lr: 0.000299  min_lr: 0.000299  loss: 1.0255 (1.0349)  class_acc: 0.7500 (0.7649)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0007  max mem: 8477\n","Epoch: [3]  [290/781]  eta: 0:08:00  lr: 0.000298  min_lr: 0.000298  loss: 1.0318 (1.0353)  class_acc: 0.7500 (0.7644)  weight_decay: 0.0500 (0.0500)  time: 0.9676  data: 0.0011  max mem: 8477\n","Epoch: [3]  [300/781]  eta: 0:07:50  lr: 0.000297  min_lr: 0.000297  loss: 1.0238 (1.0352)  class_acc: 0.7500 (0.7644)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0015  max mem: 8477\n","Epoch: [3]  [310/781]  eta: 0:07:40  lr: 0.000297  min_lr: 0.000297  loss: 1.0238 (1.0342)  class_acc: 0.7656 (0.7648)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0014  max mem: 8477\n","Epoch: [3]  [320/781]  eta: 0:07:30  lr: 0.000296  min_lr: 0.000296  loss: 1.0262 (1.0336)  class_acc: 0.7656 (0.7649)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0009  max mem: 8477\n","Epoch: [3]  [330/781]  eta: 0:07:20  lr: 0.000295  min_lr: 0.000295  loss: 1.0572 (1.0350)  class_acc: 0.7656 (0.7644)  weight_decay: 0.0500 (0.0500)  time: 0.9743  data: 0.0005  max mem: 8477\n","Epoch: [3]  [340/781]  eta: 0:07:10  lr: 0.000295  min_lr: 0.000295  loss: 1.0770 (1.0351)  class_acc: 0.7500 (0.7640)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0007  max mem: 8477\n","Epoch: [3]  [350/781]  eta: 0:07:00  lr: 0.000294  min_lr: 0.000294  loss: 1.0442 (1.0347)  class_acc: 0.7500 (0.7635)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0009  max mem: 8477\n","Epoch: [3]  [360/781]  eta: 0:06:51  lr: 0.000293  min_lr: 0.000293  loss: 1.0059 (1.0344)  class_acc: 0.7500 (0.7635)  weight_decay: 0.0500 (0.0500)  time: 0.9686  data: 0.0008  max mem: 8477\n","Epoch: [3]  [370/781]  eta: 0:06:41  lr: 0.000293  min_lr: 0.000293  loss: 1.0059 (1.0341)  class_acc: 0.7656 (0.7636)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0019  max mem: 8477\n","Epoch: [3]  [380/781]  eta: 0:06:31  lr: 0.000292  min_lr: 0.000292  loss: 1.0147 (1.0338)  class_acc: 0.7656 (0.7636)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0019  max mem: 8477\n","Epoch: [3]  [390/781]  eta: 0:06:21  lr: 0.000291  min_lr: 0.000291  loss: 0.9574 (1.0321)  class_acc: 0.7812 (0.7643)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0009  max mem: 8477\n","Epoch: [3]  [400/781]  eta: 0:06:11  lr: 0.000290  min_lr: 0.000290  loss: 0.9464 (1.0311)  class_acc: 0.7969 (0.7648)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0012  max mem: 8477\n","Epoch: [3]  [410/781]  eta: 0:06:02  lr: 0.000290  min_lr: 0.000290  loss: 0.9905 (1.0306)  class_acc: 0.7969 (0.7654)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0012  max mem: 8477\n","Epoch: [3]  [420/781]  eta: 0:05:52  lr: 0.000289  min_lr: 0.000289  loss: 1.0239 (1.0314)  class_acc: 0.7812 (0.7651)  weight_decay: 0.0500 (0.0500)  time: 0.9684  data: 0.0009  max mem: 8477\n","Epoch: [3]  [430/781]  eta: 0:05:42  lr: 0.000288  min_lr: 0.000288  loss: 1.0188 (1.0317)  class_acc: 0.7656 (0.7649)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0006  max mem: 8477\n","Epoch: [3]  [440/781]  eta: 0:05:32  lr: 0.000288  min_lr: 0.000288  loss: 1.0267 (1.0315)  class_acc: 0.7656 (0.7652)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0005  max mem: 8477\n","Epoch: [3]  [450/781]  eta: 0:05:22  lr: 0.000287  min_lr: 0.000287  loss: 1.0266 (1.0305)  class_acc: 0.7656 (0.7657)  weight_decay: 0.0500 (0.0500)  time: 0.9659  data: 0.0006  max mem: 8477\n","Epoch: [3]  [460/781]  eta: 0:05:12  lr: 0.000286  min_lr: 0.000286  loss: 1.0002 (1.0299)  class_acc: 0.7812 (0.7662)  weight_decay: 0.0500 (0.0500)  time: 0.9653  data: 0.0009  max mem: 8477\n","Epoch: [3]  [470/781]  eta: 0:05:03  lr: 0.000285  min_lr: 0.000285  loss: 0.9979 (1.0304)  class_acc: 0.7656 (0.7658)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0018  max mem: 8477\n","Epoch: [3]  [480/781]  eta: 0:04:53  lr: 0.000285  min_lr: 0.000285  loss: 1.0072 (1.0302)  class_acc: 0.7500 (0.7657)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0018  max mem: 8477\n","Epoch: [3]  [490/781]  eta: 0:04:43  lr: 0.000284  min_lr: 0.000284  loss: 1.0481 (1.0310)  class_acc: 0.7500 (0.7653)  weight_decay: 0.0500 (0.0500)  time: 0.9637  data: 0.0009  max mem: 8477\n","Epoch: [3]  [500/781]  eta: 0:04:33  lr: 0.000283  min_lr: 0.000283  loss: 1.0415 (1.0307)  class_acc: 0.7500 (0.7652)  weight_decay: 0.0500 (0.0500)  time: 0.9609  data: 0.0011  max mem: 8477\n","Epoch: [3]  [510/781]  eta: 0:04:23  lr: 0.000282  min_lr: 0.000282  loss: 1.0159 (1.0305)  class_acc: 0.7812 (0.7652)  weight_decay: 0.0500 (0.0500)  time: 0.9619  data: 0.0013  max mem: 8477\n","Epoch: [3]  [520/781]  eta: 0:04:14  lr: 0.000282  min_lr: 0.000282  loss: 1.0194 (1.0301)  class_acc: 0.7812 (0.7654)  weight_decay: 0.0500 (0.0500)  time: 0.9635  data: 0.0013  max mem: 8477\n","Epoch: [3]  [530/781]  eta: 0:04:04  lr: 0.000281  min_lr: 0.000281  loss: 1.0311 (1.0305)  class_acc: 0.7812 (0.7652)  weight_decay: 0.0500 (0.0500)  time: 0.9643  data: 0.0010  max mem: 8477\n","Epoch: [3]  [540/781]  eta: 0:03:54  lr: 0.000280  min_lr: 0.000280  loss: 1.0068 (1.0299)  class_acc: 0.7500 (0.7653)  weight_decay: 0.0500 (0.0500)  time: 0.9658  data: 0.0010  max mem: 8477\n","Epoch: [3]  [550/781]  eta: 0:03:44  lr: 0.000279  min_lr: 0.000279  loss: 1.0219 (1.0301)  class_acc: 0.7500 (0.7652)  weight_decay: 0.0500 (0.0500)  time: 0.9650  data: 0.0013  max mem: 8477\n","Epoch: [3]  [560/781]  eta: 0:03:35  lr: 0.000279  min_lr: 0.000279  loss: 1.0219 (1.0299)  class_acc: 0.7812 (0.7654)  weight_decay: 0.0500 (0.0500)  time: 0.9663  data: 0.0013  max mem: 8477\n","Epoch: [3]  [570/781]  eta: 0:03:25  lr: 0.000278  min_lr: 0.000278  loss: 1.0138 (1.0301)  class_acc: 0.7656 (0.7653)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0009  max mem: 8477\n","Epoch: [3]  [580/781]  eta: 0:03:15  lr: 0.000277  min_lr: 0.000277  loss: 1.0312 (1.0305)  class_acc: 0.7656 (0.7651)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0014  max mem: 8477\n","Epoch: [3]  [590/781]  eta: 0:03:05  lr: 0.000277  min_lr: 0.000277  loss: 1.0332 (1.0302)  class_acc: 0.7500 (0.7649)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0013  max mem: 8477\n","Epoch: [3]  [600/781]  eta: 0:02:56  lr: 0.000276  min_lr: 0.000276  loss: 0.9950 (1.0293)  class_acc: 0.7500 (0.7650)  weight_decay: 0.0500 (0.0500)  time: 0.9710  data: 0.0010  max mem: 8477\n","Epoch: [3]  [610/781]  eta: 0:02:46  lr: 0.000275  min_lr: 0.000275  loss: 0.9777 (1.0287)  class_acc: 0.7812 (0.7654)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0011  max mem: 8477\n","Epoch: [3]  [620/781]  eta: 0:02:36  lr: 0.000274  min_lr: 0.000274  loss: 0.9870 (1.0283)  class_acc: 0.7812 (0.7657)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0013  max mem: 8477\n","Epoch: [3]  [630/781]  eta: 0:02:26  lr: 0.000274  min_lr: 0.000274  loss: 1.0229 (1.0281)  class_acc: 0.7656 (0.7657)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0013  max mem: 8477\n","Epoch: [3]  [640/781]  eta: 0:02:17  lr: 0.000273  min_lr: 0.000273  loss: 1.0151 (1.0280)  class_acc: 0.7500 (0.7657)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0007  max mem: 8477\n","Epoch: [3]  [650/781]  eta: 0:02:07  lr: 0.000272  min_lr: 0.000272  loss: 0.9935 (1.0271)  class_acc: 0.7812 (0.7662)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0006  max mem: 8477\n","Epoch: [3]  [660/781]  eta: 0:01:57  lr: 0.000271  min_lr: 0.000271  loss: 1.0281 (1.0273)  class_acc: 0.7812 (0.7661)  weight_decay: 0.0500 (0.0500)  time: 0.9728  data: 0.0012  max mem: 8477\n","Epoch: [3]  [670/781]  eta: 0:01:47  lr: 0.000271  min_lr: 0.000271  loss: 1.0086 (1.0266)  class_acc: 0.7812 (0.7666)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0013  max mem: 8477\n","Epoch: [3]  [680/781]  eta: 0:01:38  lr: 0.000270  min_lr: 0.000270  loss: 1.0001 (1.0272)  class_acc: 0.7812 (0.7664)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0019  max mem: 8477\n","Epoch: [3]  [690/781]  eta: 0:01:28  lr: 0.000269  min_lr: 0.000269  loss: 1.0561 (1.0276)  class_acc: 0.7500 (0.7661)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0019  max mem: 8477\n","Epoch: [3]  [700/781]  eta: 0:01:18  lr: 0.000268  min_lr: 0.000268  loss: 1.0158 (1.0270)  class_acc: 0.7656 (0.7664)  weight_decay: 0.0500 (0.0500)  time: 0.9639  data: 0.0011  max mem: 8477\n","Epoch: [3]  [710/781]  eta: 0:01:09  lr: 0.000268  min_lr: 0.000268  loss: 0.9627 (1.0258)  class_acc: 0.7969 (0.7667)  weight_decay: 0.0500 (0.0500)  time: 0.9626  data: 0.0013  max mem: 8477\n","Epoch: [3]  [720/781]  eta: 0:00:59  lr: 0.000267  min_lr: 0.000267  loss: 0.9614 (1.0252)  class_acc: 0.7969 (0.7669)  weight_decay: 0.0500 (0.0500)  time: 0.9645  data: 0.0013  max mem: 8477\n","Epoch: [3]  [730/781]  eta: 0:00:49  lr: 0.000266  min_lr: 0.000266  loss: 0.9977 (1.0253)  class_acc: 0.7656 (0.7670)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0012  max mem: 8477\n","Epoch: [3]  [740/781]  eta: 0:00:39  lr: 0.000265  min_lr: 0.000265  loss: 1.0346 (1.0260)  class_acc: 0.7344 (0.7664)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0007  max mem: 8477\n","Epoch: [3]  [750/781]  eta: 0:00:30  lr: 0.000265  min_lr: 0.000265  loss: 1.0030 (1.0257)  class_acc: 0.7344 (0.7665)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0004  max mem: 8477\n","Epoch: [3]  [760/781]  eta: 0:00:20  lr: 0.000264  min_lr: 0.000264  loss: 0.9931 (1.0249)  class_acc: 0.7969 (0.7669)  weight_decay: 0.0500 (0.0500)  time: 0.9719  data: 0.0007  max mem: 8477\n","Epoch: [3]  [770/781]  eta: 0:00:10  lr: 0.000263  min_lr: 0.000263  loss: 0.9661 (1.0246)  class_acc: 0.7656 (0.7670)  weight_decay: 0.0500 (0.0500)  time: 0.9687  data: 0.0009  max mem: 8477\n","Epoch: [3]  [780/781]  eta: 0:00:00  lr: 0.000262  min_lr: 0.000262  loss: 1.0344 (1.0246)  class_acc: 0.7656 (0.7669)  weight_decay: 0.0500 (0.0500)  time: 0.9659  data: 0.0007  max mem: 8477\n","Epoch: [3] Total time: 0:12:39 (0.9723 s / it)\n","Averaged stats: lr: 0.000262  min_lr: 0.000262  loss: 1.0344 (1.0246)  class_acc: 0.7656 (0.7669)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:06:00  loss: 0.3284 (0.3284)  acc1: 92.7083 (92.7083)  acc5: 100.0000 (100.0000)  time: 3.4372  data: 2.8723  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:11  loss: 0.2261 (0.2399)  acc1: 94.7917 (94.9811)  acc5: 100.0000 (99.9053)  time: 0.7560  data: 0.2743  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:53  loss: 0.2058 (0.2060)  acc1: 96.8750 (96.0814)  acc5: 100.0000 (99.9504)  time: 0.4838  data: 0.0077  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:43  loss: 0.2675 (0.2446)  acc1: 94.7917 (94.9933)  acc5: 100.0000 (99.9328)  time: 0.4813  data: 0.0014  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:36  loss: 0.3297 (0.2722)  acc1: 90.6250 (93.6230)  acc5: 100.0000 (99.9238)  time: 0.4852  data: 0.0015  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.3297 (0.2766)  acc1: 90.6250 (93.5049)  acc5: 100.0000 (99.9183)  time: 0.4872  data: 0.0012  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:24  loss: 0.3226 (0.2913)  acc1: 90.6250 (92.7766)  acc5: 100.0000 (99.9146)  time: 0.4870  data: 0.0008  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.2993 (0.2907)  acc1: 92.7083 (93.0164)  acc5: 100.0000 (99.8680)  time: 0.4875  data: 0.0018  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:13  loss: 0.2663 (0.2861)  acc1: 94.7917 (93.2485)  acc5: 100.0000 (99.8200)  time: 0.4875  data: 0.0022  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.2031 (0.2756)  acc1: 95.8333 (93.6012)  acc5: 100.0000 (99.8283)  time: 0.4870  data: 0.0007  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.2011 (0.2693)  acc1: 95.8333 (93.7913)  acc5: 100.0000 (99.8350)  time: 0.4874  data: 0.0002  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1940 (0.2666)  acc1: 95.8333 (93.8500)  acc5: 100.0000 (99.8400)  time: 0.4678  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5132 s / it)\n","* Acc@1 93.850 Acc@5 99.840 loss 0.267\n","Accuracy of the model on the 10000 test images: 93.9%\n","Max accuracy: 93.85%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [4]  [  0/781]  eta: 0:41:10  lr: 0.000262  min_lr: 0.000262  loss: 1.0119 (1.0119)  class_acc: 0.7656 (0.7656)  weight_decay: 0.0500 (0.0500)  time: 3.1637  data: 2.1095  max mem: 8477\n","Epoch: [4]  [ 10/781]  eta: 0:14:55  lr: 0.000261  min_lr: 0.000261  loss: 1.0119 (1.0243)  class_acc: 0.7812 (0.7656)  weight_decay: 0.0500 (0.0500)  time: 1.1615  data: 0.1929  max mem: 8477\n","Epoch: [4]  [ 20/781]  eta: 0:13:35  lr: 0.000261  min_lr: 0.000261  loss: 0.9605 (0.9832)  class_acc: 0.7812 (0.7790)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0012  max mem: 8477\n","Epoch: [4]  [ 30/781]  eta: 0:13:01  lr: 0.000260  min_lr: 0.000260  loss: 0.9759 (0.9888)  class_acc: 0.7812 (0.7752)  weight_decay: 0.0500 (0.0500)  time: 0.9737  data: 0.0011  max mem: 8477\n","Epoch: [4]  [ 40/781]  eta: 0:12:39  lr: 0.000259  min_lr: 0.000259  loss: 1.0033 (0.9997)  class_acc: 0.7500 (0.7713)  weight_decay: 0.0500 (0.0500)  time: 0.9748  data: 0.0015  max mem: 8477\n","Epoch: [4]  [ 50/781]  eta: 0:12:21  lr: 0.000258  min_lr: 0.000258  loss: 1.0283 (1.0069)  class_acc: 0.7500 (0.7687)  weight_decay: 0.0500 (0.0500)  time: 0.9743  data: 0.0029  max mem: 8477\n","Epoch: [4]  [ 60/781]  eta: 0:12:06  lr: 0.000258  min_lr: 0.000258  loss: 1.0209 (1.0042)  class_acc: 0.7812 (0.7713)  weight_decay: 0.0500 (0.0500)  time: 0.9736  data: 0.0028  max mem: 8477\n","Epoch: [4]  [ 70/781]  eta: 0:11:52  lr: 0.000257  min_lr: 0.000257  loss: 0.9825 (1.0019)  class_acc: 0.7812 (0.7700)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0013  max mem: 8477\n","Epoch: [4]  [ 80/781]  eta: 0:11:38  lr: 0.000256  min_lr: 0.000256  loss: 0.9614 (0.9982)  class_acc: 0.7812 (0.7737)  weight_decay: 0.0500 (0.0500)  time: 0.9620  data: 0.0009  max mem: 8477\n","Epoch: [4]  [ 90/781]  eta: 0:11:25  lr: 0.000255  min_lr: 0.000255  loss: 0.9439 (0.9930)  class_acc: 0.7969 (0.7764)  weight_decay: 0.0500 (0.0500)  time: 0.9593  data: 0.0008  max mem: 8477\n","Epoch: [4]  [100/781]  eta: 0:11:13  lr: 0.000254  min_lr: 0.000254  loss: 0.9830 (0.9940)  class_acc: 0.7969 (0.7774)  weight_decay: 0.0500 (0.0500)  time: 0.9602  data: 0.0011  max mem: 8477\n","Epoch: [4]  [110/781]  eta: 0:11:01  lr: 0.000254  min_lr: 0.000254  loss: 0.9878 (0.9917)  class_acc: 0.7812 (0.7791)  weight_decay: 0.0500 (0.0500)  time: 0.9588  data: 0.0014  max mem: 8477\n","Epoch: [4]  [120/781]  eta: 0:10:50  lr: 0.000253  min_lr: 0.000253  loss: 0.9696 (0.9910)  class_acc: 0.7656 (0.7785)  weight_decay: 0.0500 (0.0500)  time: 0.9600  data: 0.0011  max mem: 8477\n","Epoch: [4]  [130/781]  eta: 0:10:39  lr: 0.000252  min_lr: 0.000252  loss: 0.9664 (0.9883)  class_acc: 0.7812 (0.7807)  weight_decay: 0.0500 (0.0500)  time: 0.9623  data: 0.0008  max mem: 8477\n","Epoch: [4]  [140/781]  eta: 0:10:28  lr: 0.000251  min_lr: 0.000251  loss: 0.9534 (0.9876)  class_acc: 0.7969 (0.7814)  weight_decay: 0.0500 (0.0500)  time: 0.9610  data: 0.0011  max mem: 8477\n","Epoch: [4]  [150/781]  eta: 0:10:18  lr: 0.000251  min_lr: 0.000251  loss: 0.9864 (0.9887)  class_acc: 0.7812 (0.7810)  weight_decay: 0.0500 (0.0500)  time: 0.9625  data: 0.0013  max mem: 8477\n","Epoch: [4]  [160/781]  eta: 0:10:08  lr: 0.000250  min_lr: 0.000250  loss: 1.0003 (0.9899)  class_acc: 0.7656 (0.7800)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0013  max mem: 8477\n","Epoch: [4]  [170/781]  eta: 0:09:58  lr: 0.000249  min_lr: 0.000249  loss: 1.0086 (0.9918)  class_acc: 0.7656 (0.7793)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0014  max mem: 8477\n","Epoch: [4]  [180/781]  eta: 0:09:48  lr: 0.000248  min_lr: 0.000248  loss: 1.0245 (0.9945)  class_acc: 0.7500 (0.7778)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0012  max mem: 8477\n","Epoch: [4]  [190/781]  eta: 0:09:38  lr: 0.000247  min_lr: 0.000247  loss: 0.9932 (0.9927)  class_acc: 0.7812 (0.7795)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0007  max mem: 8477\n","Epoch: [4]  [200/781]  eta: 0:09:28  lr: 0.000247  min_lr: 0.000247  loss: 0.9469 (0.9906)  class_acc: 0.8125 (0.7806)  weight_decay: 0.0500 (0.0500)  time: 0.9717  data: 0.0010  max mem: 8477\n","Epoch: [4]  [210/781]  eta: 0:09:18  lr: 0.000246  min_lr: 0.000246  loss: 0.9547 (0.9925)  class_acc: 0.7812 (0.7794)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0012  max mem: 8477\n","Epoch: [4]  [220/781]  eta: 0:09:08  lr: 0.000245  min_lr: 0.000245  loss: 0.9547 (0.9913)  class_acc: 0.7812 (0.7803)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0008  max mem: 8477\n","Epoch: [4]  [230/781]  eta: 0:08:58  lr: 0.000244  min_lr: 0.000244  loss: 0.9944 (0.9937)  class_acc: 0.7656 (0.7787)  weight_decay: 0.0500 (0.0500)  time: 0.9704  data: 0.0007  max mem: 8477\n","Epoch: [4]  [240/781]  eta: 0:08:48  lr: 0.000244  min_lr: 0.000244  loss: 0.9730 (0.9926)  class_acc: 0.7500 (0.7790)  weight_decay: 0.0500 (0.0500)  time: 0.9730  data: 0.0008  max mem: 8477\n","Epoch: [4]  [250/781]  eta: 0:08:38  lr: 0.000243  min_lr: 0.000243  loss: 0.9730 (0.9933)  class_acc: 0.7656 (0.7783)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0009  max mem: 8477\n","Epoch: [4]  [260/781]  eta: 0:08:28  lr: 0.000242  min_lr: 0.000242  loss: 1.0088 (0.9941)  class_acc: 0.7656 (0.7783)  weight_decay: 0.0500 (0.0500)  time: 0.9707  data: 0.0018  max mem: 8477\n","Epoch: [4]  [270/781]  eta: 0:08:18  lr: 0.000241  min_lr: 0.000241  loss: 0.9809 (0.9939)  class_acc: 0.7812 (0.7783)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0016  max mem: 8477\n","Epoch: [4]  [280/781]  eta: 0:08:08  lr: 0.000240  min_lr: 0.000240  loss: 0.9791 (0.9957)  class_acc: 0.7656 (0.7779)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0008  max mem: 8477\n","Epoch: [4]  [290/781]  eta: 0:07:59  lr: 0.000240  min_lr: 0.000240  loss: 0.9825 (0.9946)  class_acc: 0.7656 (0.7780)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0010  max mem: 8477\n","Epoch: [4]  [300/781]  eta: 0:07:49  lr: 0.000239  min_lr: 0.000239  loss: 1.0048 (0.9958)  class_acc: 0.7656 (0.7777)  weight_decay: 0.0500 (0.0500)  time: 0.9743  data: 0.0013  max mem: 8477\n","Epoch: [4]  [310/781]  eta: 0:07:39  lr: 0.000238  min_lr: 0.000238  loss: 1.0174 (0.9961)  class_acc: 0.7500 (0.7772)  weight_decay: 0.0500 (0.0500)  time: 0.9730  data: 0.0013  max mem: 8477\n","Epoch: [4]  [320/781]  eta: 0:07:29  lr: 0.000237  min_lr: 0.000237  loss: 0.9543 (0.9955)  class_acc: 0.7656 (0.7778)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0008  max mem: 8477\n","Epoch: [4]  [330/781]  eta: 0:07:19  lr: 0.000236  min_lr: 0.000236  loss: 0.9612 (0.9950)  class_acc: 0.7969 (0.7777)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0009  max mem: 8477\n","Epoch: [4]  [340/781]  eta: 0:07:10  lr: 0.000236  min_lr: 0.000236  loss: 1.0011 (0.9961)  class_acc: 0.7656 (0.7774)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0010  max mem: 8477\n","Epoch: [4]  [350/781]  eta: 0:07:00  lr: 0.000235  min_lr: 0.000235  loss: 0.9599 (0.9949)  class_acc: 0.7656 (0.7780)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0009  max mem: 8477\n","Epoch: [4]  [360/781]  eta: 0:06:50  lr: 0.000234  min_lr: 0.000234  loss: 0.9226 (0.9940)  class_acc: 0.7812 (0.7785)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0017  max mem: 8477\n","Epoch: [4]  [370/781]  eta: 0:06:40  lr: 0.000233  min_lr: 0.000233  loss: 0.9799 (0.9933)  class_acc: 0.7812 (0.7791)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0016  max mem: 8477\n","Epoch: [4]  [380/781]  eta: 0:06:31  lr: 0.000233  min_lr: 0.000233  loss: 0.9774 (0.9922)  class_acc: 0.7969 (0.7797)  weight_decay: 0.0500 (0.0500)  time: 0.9737  data: 0.0007  max mem: 8477\n","Epoch: [4]  [390/781]  eta: 0:06:21  lr: 0.000232  min_lr: 0.000232  loss: 0.9565 (0.9912)  class_acc: 0.8125 (0.7800)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0009  max mem: 8477\n","Epoch: [4]  [400/781]  eta: 0:06:11  lr: 0.000231  min_lr: 0.000231  loss: 0.9236 (0.9904)  class_acc: 0.7969 (0.7802)  weight_decay: 0.0500 (0.0500)  time: 0.9658  data: 0.0013  max mem: 8477\n","Epoch: [4]  [410/781]  eta: 0:06:01  lr: 0.000230  min_lr: 0.000230  loss: 0.9710 (0.9912)  class_acc: 0.7969 (0.7799)  weight_decay: 0.0500 (0.0500)  time: 0.9628  data: 0.0014  max mem: 8477\n","Epoch: [4]  [420/781]  eta: 0:05:51  lr: 0.000229  min_lr: 0.000229  loss: 0.9884 (0.9906)  class_acc: 0.7656 (0.7800)  weight_decay: 0.0500 (0.0500)  time: 0.9601  data: 0.0013  max mem: 8477\n","Epoch: [4]  [430/781]  eta: 0:05:41  lr: 0.000229  min_lr: 0.000229  loss: 0.9367 (0.9893)  class_acc: 0.7969 (0.7805)  weight_decay: 0.0500 (0.0500)  time: 0.9610  data: 0.0011  max mem: 8477\n","Epoch: [4]  [440/781]  eta: 0:05:31  lr: 0.000228  min_lr: 0.000228  loss: 0.9765 (0.9895)  class_acc: 0.7812 (0.7801)  weight_decay: 0.0500 (0.0500)  time: 0.9626  data: 0.0006  max mem: 8477\n","Epoch: [4]  [450/781]  eta: 0:05:22  lr: 0.000227  min_lr: 0.000227  loss: 0.9529 (0.9884)  class_acc: 0.7969 (0.7806)  weight_decay: 0.0500 (0.0500)  time: 0.9648  data: 0.0010  max mem: 8477\n","Epoch: [4]  [460/781]  eta: 0:05:12  lr: 0.000226  min_lr: 0.000226  loss: 0.9157 (0.9879)  class_acc: 0.8125 (0.7808)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0015  max mem: 8477\n","Epoch: [4]  [470/781]  eta: 0:05:02  lr: 0.000225  min_lr: 0.000225  loss: 0.9529 (0.9874)  class_acc: 0.7812 (0.7811)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0018  max mem: 8477\n","Epoch: [4]  [480/781]  eta: 0:04:52  lr: 0.000225  min_lr: 0.000225  loss: 0.9311 (0.9863)  class_acc: 0.7969 (0.7817)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0016  max mem: 8477\n","Epoch: [4]  [490/781]  eta: 0:04:43  lr: 0.000224  min_lr: 0.000224  loss: 0.9311 (0.9864)  class_acc: 0.7969 (0.7819)  weight_decay: 0.0500 (0.0500)  time: 0.9660  data: 0.0012  max mem: 8477\n","Epoch: [4]  [500/781]  eta: 0:04:33  lr: 0.000223  min_lr: 0.000223  loss: 0.9268 (0.9854)  class_acc: 0.7812 (0.7825)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0012  max mem: 8477\n","Epoch: [4]  [510/781]  eta: 0:04:23  lr: 0.000222  min_lr: 0.000222  loss: 0.9204 (0.9854)  class_acc: 0.8125 (0.7828)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0010  max mem: 8477\n","Epoch: [4]  [520/781]  eta: 0:04:13  lr: 0.000221  min_lr: 0.000221  loss: 0.9346 (0.9851)  class_acc: 0.8125 (0.7831)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0011  max mem: 8477\n","Epoch: [4]  [530/781]  eta: 0:04:04  lr: 0.000221  min_lr: 0.000221  loss: 0.8902 (0.9839)  class_acc: 0.8125 (0.7835)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0009  max mem: 8477\n","Epoch: [4]  [540/781]  eta: 0:03:54  lr: 0.000220  min_lr: 0.000220  loss: 0.8981 (0.9836)  class_acc: 0.7969 (0.7835)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0007  max mem: 8477\n","Epoch: [4]  [550/781]  eta: 0:03:44  lr: 0.000219  min_lr: 0.000219  loss: 0.9947 (0.9836)  class_acc: 0.7812 (0.7835)  weight_decay: 0.0500 (0.0500)  time: 0.9749  data: 0.0009  max mem: 8477\n","Epoch: [4]  [560/781]  eta: 0:03:34  lr: 0.000218  min_lr: 0.000218  loss: 0.9657 (0.9831)  class_acc: 0.7812 (0.7837)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0010  max mem: 8477\n","Epoch: [4]  [570/781]  eta: 0:03:25  lr: 0.000217  min_lr: 0.000217  loss: 0.9657 (0.9836)  class_acc: 0.7969 (0.7835)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0018  max mem: 8477\n","Epoch: [4]  [580/781]  eta: 0:03:15  lr: 0.000217  min_lr: 0.000217  loss: 1.0363 (0.9846)  class_acc: 0.7656 (0.7831)  weight_decay: 0.0500 (0.0500)  time: 0.9707  data: 0.0015  max mem: 8477\n","Epoch: [4]  [590/781]  eta: 0:03:05  lr: 0.000216  min_lr: 0.000216  loss: 0.9871 (0.9842)  class_acc: 0.7812 (0.7833)  weight_decay: 0.0500 (0.0500)  time: 0.9746  data: 0.0006  max mem: 8477\n","Epoch: [4]  [600/781]  eta: 0:02:56  lr: 0.000215  min_lr: 0.000215  loss: 0.9544 (0.9832)  class_acc: 0.7969 (0.7837)  weight_decay: 0.0500 (0.0500)  time: 0.9736  data: 0.0008  max mem: 8477\n","Epoch: [4]  [610/781]  eta: 0:02:46  lr: 0.000214  min_lr: 0.000214  loss: 0.9595 (0.9829)  class_acc: 0.8125 (0.7841)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0010  max mem: 8477\n","Epoch: [4]  [620/781]  eta: 0:02:36  lr: 0.000213  min_lr: 0.000213  loss: 0.9635 (0.9827)  class_acc: 0.8125 (0.7840)  weight_decay: 0.0500 (0.0500)  time: 0.9747  data: 0.0009  max mem: 8477\n","Epoch: [4]  [630/781]  eta: 0:02:26  lr: 0.000213  min_lr: 0.000213  loss: 0.9677 (0.9823)  class_acc: 0.7812 (0.7842)  weight_decay: 0.0500 (0.0500)  time: 0.9746  data: 0.0007  max mem: 8477\n","Epoch: [4]  [640/781]  eta: 0:02:17  lr: 0.000212  min_lr: 0.000212  loss: 0.9694 (0.9816)  class_acc: 0.7812 (0.7846)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0005  max mem: 8477\n","Epoch: [4]  [650/781]  eta: 0:02:07  lr: 0.000211  min_lr: 0.000211  loss: 0.9183 (0.9807)  class_acc: 0.7969 (0.7848)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0004  max mem: 8477\n","Epoch: [4]  [660/781]  eta: 0:01:57  lr: 0.000210  min_lr: 0.000210  loss: 0.9197 (0.9800)  class_acc: 0.8125 (0.7853)  weight_decay: 0.0500 (0.0500)  time: 0.9747  data: 0.0005  max mem: 8477\n","Epoch: [4]  [670/781]  eta: 0:01:47  lr: 0.000209  min_lr: 0.000209  loss: 0.9310 (0.9795)  class_acc: 0.8125 (0.7855)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0012  max mem: 8477\n","Epoch: [4]  [680/781]  eta: 0:01:38  lr: 0.000209  min_lr: 0.000209  loss: 0.9617 (0.9795)  class_acc: 0.8125 (0.7855)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0010  max mem: 8477\n","Epoch: [4]  [690/781]  eta: 0:01:28  lr: 0.000208  min_lr: 0.000208  loss: 0.9610 (0.9788)  class_acc: 0.7969 (0.7858)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0004  max mem: 8477\n","Epoch: [4]  [700/781]  eta: 0:01:18  lr: 0.000207  min_lr: 0.000207  loss: 0.9000 (0.9780)  class_acc: 0.8125 (0.7862)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0006  max mem: 8477\n","Epoch: [4]  [710/781]  eta: 0:01:09  lr: 0.000206  min_lr: 0.000206  loss: 0.9147 (0.9780)  class_acc: 0.8125 (0.7861)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0009  max mem: 8477\n","Epoch: [4]  [720/781]  eta: 0:00:59  lr: 0.000205  min_lr: 0.000205  loss: 0.9422 (0.9771)  class_acc: 0.7812 (0.7863)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0009  max mem: 8477\n","Epoch: [4]  [730/781]  eta: 0:00:49  lr: 0.000205  min_lr: 0.000205  loss: 0.9592 (0.9776)  class_acc: 0.7812 (0.7863)  weight_decay: 0.0500 (0.0500)  time: 0.9746  data: 0.0010  max mem: 8477\n","Epoch: [4]  [740/781]  eta: 0:00:39  lr: 0.000204  min_lr: 0.000204  loss: 0.9742 (0.9777)  class_acc: 0.7812 (0.7862)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0011  max mem: 8477\n","Epoch: [4]  [750/781]  eta: 0:00:30  lr: 0.000203  min_lr: 0.000203  loss: 0.9664 (0.9777)  class_acc: 0.7812 (0.7861)  weight_decay: 0.0500 (0.0500)  time: 0.9677  data: 0.0009  max mem: 8477\n","Epoch: [4]  [760/781]  eta: 0:00:20  lr: 0.000202  min_lr: 0.000202  loss: 0.9576 (0.9776)  class_acc: 0.8125 (0.7863)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0008  max mem: 8477\n","Epoch: [4]  [770/781]  eta: 0:00:10  lr: 0.000201  min_lr: 0.000201  loss: 0.9651 (0.9770)  class_acc: 0.8125 (0.7865)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0008  max mem: 8477\n","Epoch: [4]  [780/781]  eta: 0:00:00  lr: 0.000201  min_lr: 0.000201  loss: 0.9685 (0.9769)  class_acc: 0.7969 (0.7866)  weight_decay: 0.0500 (0.0500)  time: 0.9637  data: 0.0006  max mem: 8477\n","Epoch: [4] Total time: 0:12:39 (0.9727 s / it)\n","Averaged stats: lr: 0.000201  min_lr: 0.000201  loss: 0.9685 (0.9769)  class_acc: 0.7969 (0.7866)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:04:55  loss: 0.2579 (0.2579)  acc1: 92.7083 (92.7083)  acc5: 100.0000 (100.0000)  time: 2.8123  data: 2.3013  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:05  loss: 0.1998 (0.2005)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (99.9053)  time: 0.6872  data: 0.2114  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:49  loss: 0.1951 (0.1952)  acc1: 95.8333 (96.2798)  acc5: 100.0000 (99.9008)  time: 0.4765  data: 0.0013  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:41  loss: 0.2437 (0.2351)  acc1: 94.7917 (94.9933)  acc5: 100.0000 (99.7648)  time: 0.4815  data: 0.0012  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:34  loss: 0.3577 (0.2716)  acc1: 90.6250 (93.3689)  acc5: 100.0000 (99.7967)  time: 0.4849  data: 0.0018  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.3306 (0.2726)  acc1: 90.6250 (93.3415)  acc5: 100.0000 (99.8366)  time: 0.4863  data: 0.0017  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.3014 (0.2852)  acc1: 91.6667 (92.7254)  acc5: 100.0000 (99.8634)  time: 0.4874  data: 0.0027  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.2797 (0.2790)  acc1: 91.6667 (92.9724)  acc5: 100.0000 (99.8680)  time: 0.4874  data: 0.0027  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.1988 (0.2670)  acc1: 96.8750 (93.4799)  acc5: 100.0000 (99.8714)  time: 0.4874  data: 0.0011  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.1777 (0.2577)  acc1: 96.8750 (93.8645)  acc5: 100.0000 (99.8741)  time: 0.4869  data: 0.0003  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1885 (0.2504)  acc1: 96.8750 (94.1935)  acc5: 100.0000 (99.8866)  time: 0.4867  data: 0.0002  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1885 (0.2471)  acc1: 96.8750 (94.2800)  acc5: 100.0000 (99.8900)  time: 0.4676  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5057 s / it)\n","* Acc@1 94.280 Acc@5 99.890 loss 0.247\n","Accuracy of the model on the 10000 test images: 94.3%\n","Max accuracy: 94.28%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [5]  [  0/781]  eta: 0:41:48  lr: 0.000200  min_lr: 0.000200  loss: 1.0318 (1.0318)  class_acc: 0.7500 (0.7500)  weight_decay: 0.0500 (0.0500)  time: 3.2118  data: 2.1899  max mem: 8477\n","Epoch: [5]  [ 10/781]  eta: 0:14:57  lr: 0.000200  min_lr: 0.000200  loss: 0.9510 (0.9468)  class_acc: 0.8125 (0.8011)  weight_decay: 0.0500 (0.0500)  time: 1.1639  data: 0.2005  max mem: 8477\n","Epoch: [5]  [ 20/781]  eta: 0:13:34  lr: 0.000199  min_lr: 0.000199  loss: 0.9314 (0.9476)  class_acc: 0.8125 (0.8013)  weight_decay: 0.0500 (0.0500)  time: 0.9628  data: 0.0011  max mem: 8477\n","Epoch: [5]  [ 30/781]  eta: 0:13:00  lr: 0.000198  min_lr: 0.000198  loss: 0.9403 (0.9437)  class_acc: 0.7969 (0.8039)  weight_decay: 0.0500 (0.0500)  time: 0.9706  data: 0.0011  max mem: 8477\n","Epoch: [5]  [ 40/781]  eta: 0:12:38  lr: 0.000197  min_lr: 0.000197  loss: 0.9556 (0.9563)  class_acc: 0.7969 (0.7954)  weight_decay: 0.0500 (0.0500)  time: 0.9747  data: 0.0012  max mem: 8477\n","Epoch: [5]  [ 50/781]  eta: 0:12:21  lr: 0.000196  min_lr: 0.000196  loss: 0.9705 (0.9590)  class_acc: 0.7812 (0.7929)  weight_decay: 0.0500 (0.0500)  time: 0.9743  data: 0.0008  max mem: 8477\n","Epoch: [5]  [ 60/781]  eta: 0:12:06  lr: 0.000196  min_lr: 0.000196  loss: 0.9393 (0.9587)  class_acc: 0.7969 (0.7923)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0007  max mem: 8477\n","Epoch: [5]  [ 70/781]  eta: 0:11:52  lr: 0.000195  min_lr: 0.000195  loss: 0.9327 (0.9535)  class_acc: 0.7969 (0.7960)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0010  max mem: 8477\n","Epoch: [5]  [ 80/781]  eta: 0:11:38  lr: 0.000194  min_lr: 0.000194  loss: 0.9407 (0.9532)  class_acc: 0.8125 (0.7963)  weight_decay: 0.0500 (0.0500)  time: 0.9630  data: 0.0014  max mem: 8477\n","Epoch: [5]  [ 90/781]  eta: 0:11:26  lr: 0.000193  min_lr: 0.000193  loss: 0.9436 (0.9505)  class_acc: 0.7969 (0.7965)  weight_decay: 0.0500 (0.0500)  time: 0.9631  data: 0.0011  max mem: 8477\n","Epoch: [5]  [100/781]  eta: 0:11:14  lr: 0.000192  min_lr: 0.000192  loss: 0.9151 (0.9455)  class_acc: 0.8125 (0.8009)  weight_decay: 0.0500 (0.0500)  time: 0.9638  data: 0.0007  max mem: 8477\n","Epoch: [5]  [110/781]  eta: 0:11:02  lr: 0.000192  min_lr: 0.000192  loss: 0.9115 (0.9444)  class_acc: 0.8125 (0.8015)  weight_decay: 0.0500 (0.0500)  time: 0.9622  data: 0.0006  max mem: 8477\n","Epoch: [5]  [120/781]  eta: 0:10:51  lr: 0.000191  min_lr: 0.000191  loss: 0.9255 (0.9454)  class_acc: 0.7812 (0.8006)  weight_decay: 0.0500 (0.0500)  time: 0.9646  data: 0.0006  max mem: 8477\n","Epoch: [5]  [130/781]  eta: 0:10:40  lr: 0.000190  min_lr: 0.000190  loss: 0.9486 (0.9479)  class_acc: 0.7969 (0.8006)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0008  max mem: 8477\n","Epoch: [5]  [140/781]  eta: 0:10:29  lr: 0.000189  min_lr: 0.000189  loss: 0.9693 (0.9494)  class_acc: 0.7969 (0.7991)  weight_decay: 0.0500 (0.0500)  time: 0.9631  data: 0.0012  max mem: 8477\n","Epoch: [5]  [150/781]  eta: 0:10:19  lr: 0.000188  min_lr: 0.000188  loss: 0.9637 (0.9509)  class_acc: 0.7969 (0.7990)  weight_decay: 0.0500 (0.0500)  time: 0.9629  data: 0.0013  max mem: 8477\n","Epoch: [5]  [160/781]  eta: 0:10:08  lr: 0.000188  min_lr: 0.000188  loss: 0.9572 (0.9525)  class_acc: 0.7969 (0.7980)  weight_decay: 0.0500 (0.0500)  time: 0.9655  data: 0.0012  max mem: 8477\n","Epoch: [5]  [170/781]  eta: 0:09:58  lr: 0.000187  min_lr: 0.000187  loss: 1.0110 (0.9565)  class_acc: 0.7656 (0.7962)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0010  max mem: 8477\n","Epoch: [5]  [180/781]  eta: 0:09:48  lr: 0.000186  min_lr: 0.000186  loss: 0.9895 (0.9591)  class_acc: 0.7656 (0.7951)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0007  max mem: 8477\n","Epoch: [5]  [190/781]  eta: 0:09:38  lr: 0.000185  min_lr: 0.000185  loss: 0.9359 (0.9557)  class_acc: 0.7969 (0.7961)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0014  max mem: 8477\n","Epoch: [5]  [200/781]  eta: 0:09:28  lr: 0.000184  min_lr: 0.000184  loss: 0.8875 (0.9533)  class_acc: 0.8281 (0.7974)  weight_decay: 0.0500 (0.0500)  time: 0.9699  data: 0.0018  max mem: 8477\n","Epoch: [5]  [210/781]  eta: 0:09:18  lr: 0.000184  min_lr: 0.000184  loss: 0.8906 (0.9506)  class_acc: 0.8438 (0.7983)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0012  max mem: 8477\n","Epoch: [5]  [220/781]  eta: 0:09:08  lr: 0.000183  min_lr: 0.000183  loss: 0.8860 (0.9499)  class_acc: 0.8281 (0.7991)  weight_decay: 0.0500 (0.0500)  time: 0.9647  data: 0.0008  max mem: 8477\n","Epoch: [5]  [230/781]  eta: 0:08:58  lr: 0.000182  min_lr: 0.000182  loss: 0.9010 (0.9490)  class_acc: 0.8281 (0.8001)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0009  max mem: 8477\n","Epoch: [5]  [240/781]  eta: 0:08:48  lr: 0.000181  min_lr: 0.000181  loss: 0.9436 (0.9488)  class_acc: 0.7969 (0.7999)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0014  max mem: 8477\n","Epoch: [5]  [250/781]  eta: 0:08:38  lr: 0.000180  min_lr: 0.000180  loss: 0.9436 (0.9487)  class_acc: 0.7969 (0.7995)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0016  max mem: 8477\n","Epoch: [5]  [260/781]  eta: 0:08:28  lr: 0.000180  min_lr: 0.000180  loss: 0.9339 (0.9494)  class_acc: 0.7969 (0.7994)  weight_decay: 0.0500 (0.0500)  time: 0.9675  data: 0.0012  max mem: 8477\n","Epoch: [5]  [270/781]  eta: 0:08:18  lr: 0.000179  min_lr: 0.000179  loss: 0.9432 (0.9491)  class_acc: 0.7969 (0.7996)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0009  max mem: 8477\n","Epoch: [5]  [280/781]  eta: 0:08:08  lr: 0.000178  min_lr: 0.000178  loss: 0.9631 (0.9495)  class_acc: 0.7969 (0.7998)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0012  max mem: 8477\n","Epoch: [5]  [290/781]  eta: 0:07:58  lr: 0.000177  min_lr: 0.000177  loss: 0.9670 (0.9501)  class_acc: 0.7969 (0.7996)  weight_decay: 0.0500 (0.0500)  time: 0.9684  data: 0.0012  max mem: 8477\n","Epoch: [5]  [300/781]  eta: 0:07:49  lr: 0.000176  min_lr: 0.000176  loss: 0.9271 (0.9495)  class_acc: 0.7969 (0.7999)  weight_decay: 0.0500 (0.0500)  time: 0.9716  data: 0.0011  max mem: 8477\n","Epoch: [5]  [310/781]  eta: 0:07:39  lr: 0.000176  min_lr: 0.000176  loss: 0.8902 (0.9473)  class_acc: 0.8281 (0.8013)  weight_decay: 0.0500 (0.0500)  time: 0.9736  data: 0.0014  max mem: 8477\n","Epoch: [5]  [320/781]  eta: 0:07:29  lr: 0.000175  min_lr: 0.000175  loss: 0.9050 (0.9464)  class_acc: 0.8125 (0.8013)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0012  max mem: 8477\n","Epoch: [5]  [330/781]  eta: 0:07:19  lr: 0.000174  min_lr: 0.000174  loss: 0.9351 (0.9468)  class_acc: 0.7969 (0.8012)  weight_decay: 0.0500 (0.0500)  time: 0.9718  data: 0.0008  max mem: 8477\n","Epoch: [5]  [340/781]  eta: 0:07:09  lr: 0.000173  min_lr: 0.000173  loss: 0.9019 (0.9458)  class_acc: 0.8281 (0.8016)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0009  max mem: 8477\n","Epoch: [5]  [350/781]  eta: 0:07:00  lr: 0.000173  min_lr: 0.000173  loss: 0.8967 (0.9459)  class_acc: 0.8281 (0.8016)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0010  max mem: 8477\n","Epoch: [5]  [360/781]  eta: 0:06:50  lr: 0.000172  min_lr: 0.000172  loss: 0.9164 (0.9458)  class_acc: 0.7969 (0.8015)  weight_decay: 0.0500 (0.0500)  time: 0.9671  data: 0.0010  max mem: 8477\n","Epoch: [5]  [370/781]  eta: 0:06:40  lr: 0.000171  min_lr: 0.000171  loss: 0.9798 (0.9462)  class_acc: 0.7812 (0.8016)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0009  max mem: 8477\n","Epoch: [5]  [380/781]  eta: 0:06:30  lr: 0.000170  min_lr: 0.000170  loss: 0.9798 (0.9471)  class_acc: 0.7812 (0.8014)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0010  max mem: 8477\n","Epoch: [5]  [390/781]  eta: 0:06:20  lr: 0.000169  min_lr: 0.000169  loss: 0.9393 (0.9475)  class_acc: 0.7812 (0.8009)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0013  max mem: 8477\n","Epoch: [5]  [400/781]  eta: 0:06:11  lr: 0.000169  min_lr: 0.000169  loss: 0.9410 (0.9478)  class_acc: 0.7812 (0.8008)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0012  max mem: 8477\n","Epoch: [5]  [410/781]  eta: 0:06:01  lr: 0.000168  min_lr: 0.000168  loss: 0.9591 (0.9475)  class_acc: 0.7969 (0.8012)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0010  max mem: 8477\n","Epoch: [5]  [420/781]  eta: 0:05:51  lr: 0.000167  min_lr: 0.000167  loss: 0.9324 (0.9471)  class_acc: 0.8125 (0.8011)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0011  max mem: 8477\n","Epoch: [5]  [430/781]  eta: 0:05:41  lr: 0.000166  min_lr: 0.000166  loss: 0.9532 (0.9475)  class_acc: 0.7969 (0.8009)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0016  max mem: 8477\n","Epoch: [5]  [440/781]  eta: 0:05:32  lr: 0.000165  min_lr: 0.000165  loss: 0.9152 (0.9467)  class_acc: 0.8125 (0.8010)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0019  max mem: 8477\n","Epoch: [5]  [450/781]  eta: 0:05:22  lr: 0.000165  min_lr: 0.000165  loss: 0.8672 (0.9455)  class_acc: 0.8281 (0.8014)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0015  max mem: 8477\n","Epoch: [5]  [460/781]  eta: 0:05:12  lr: 0.000164  min_lr: 0.000164  loss: 0.8925 (0.9451)  class_acc: 0.8281 (0.8020)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0010  max mem: 8477\n","Epoch: [5]  [470/781]  eta: 0:05:02  lr: 0.000163  min_lr: 0.000163  loss: 0.9181 (0.9461)  class_acc: 0.8281 (0.8015)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0012  max mem: 8477\n","Epoch: [5]  [480/781]  eta: 0:04:53  lr: 0.000162  min_lr: 0.000162  loss: 0.9537 (0.9458)  class_acc: 0.7812 (0.8017)  weight_decay: 0.0500 (0.0500)  time: 0.9727  data: 0.0014  max mem: 8477\n","Epoch: [5]  [490/781]  eta: 0:04:43  lr: 0.000161  min_lr: 0.000161  loss: 0.9314 (0.9457)  class_acc: 0.8125 (0.8017)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0010  max mem: 8477\n","Epoch: [5]  [500/781]  eta: 0:04:33  lr: 0.000161  min_lr: 0.000161  loss: 0.9180 (0.9446)  class_acc: 0.8281 (0.8022)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0009  max mem: 8477\n","Epoch: [5]  [510/781]  eta: 0:04:23  lr: 0.000160  min_lr: 0.000160  loss: 0.8845 (0.9439)  class_acc: 0.8281 (0.8023)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0007  max mem: 8477\n","Epoch: [5]  [520/781]  eta: 0:04:13  lr: 0.000159  min_lr: 0.000159  loss: 0.9098 (0.9436)  class_acc: 0.8125 (0.8021)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0007  max mem: 8477\n","Epoch: [5]  [530/781]  eta: 0:04:04  lr: 0.000158  min_lr: 0.000158  loss: 0.9456 (0.9440)  class_acc: 0.7812 (0.8015)  weight_decay: 0.0500 (0.0500)  time: 0.9717  data: 0.0013  max mem: 8477\n","Epoch: [5]  [540/781]  eta: 0:03:54  lr: 0.000158  min_lr: 0.000158  loss: 0.9165 (0.9430)  class_acc: 0.7812 (0.8018)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0019  max mem: 8477\n","Epoch: [5]  [550/781]  eta: 0:03:44  lr: 0.000157  min_lr: 0.000157  loss: 0.9307 (0.9438)  class_acc: 0.7969 (0.8018)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0013  max mem: 8477\n","Epoch: [5]  [560/781]  eta: 0:03:35  lr: 0.000156  min_lr: 0.000156  loss: 0.9139 (0.9428)  class_acc: 0.8125 (0.8022)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0007  max mem: 8477\n","Epoch: [5]  [570/781]  eta: 0:03:25  lr: 0.000155  min_lr: 0.000155  loss: 0.8791 (0.9425)  class_acc: 0.8125 (0.8024)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0009  max mem: 8477\n","Epoch: [5]  [580/781]  eta: 0:03:15  lr: 0.000154  min_lr: 0.000154  loss: 0.8744 (0.9415)  class_acc: 0.8125 (0.8028)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0006  max mem: 8477\n","Epoch: [5]  [590/781]  eta: 0:03:05  lr: 0.000154  min_lr: 0.000154  loss: 0.8659 (0.9408)  class_acc: 0.8281 (0.8032)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0012  max mem: 8477\n","Epoch: [5]  [600/781]  eta: 0:02:56  lr: 0.000153  min_lr: 0.000153  loss: 0.8457 (0.9401)  class_acc: 0.8281 (0.8035)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0015  max mem: 8477\n","Epoch: [5]  [610/781]  eta: 0:02:46  lr: 0.000152  min_lr: 0.000152  loss: 0.9042 (0.9410)  class_acc: 0.8125 (0.8031)  weight_decay: 0.0500 (0.0500)  time: 0.9641  data: 0.0008  max mem: 8477\n","Epoch: [5]  [620/781]  eta: 0:02:36  lr: 0.000151  min_lr: 0.000151  loss: 0.9979 (0.9413)  class_acc: 0.7812 (0.8028)  weight_decay: 0.0500 (0.0500)  time: 0.9620  data: 0.0009  max mem: 8477\n","Epoch: [5]  [630/781]  eta: 0:02:26  lr: 0.000150  min_lr: 0.000150  loss: 0.9897 (0.9419)  class_acc: 0.7969 (0.8026)  weight_decay: 0.0500 (0.0500)  time: 0.9628  data: 0.0017  max mem: 8477\n","Epoch: [5]  [640/781]  eta: 0:02:17  lr: 0.000150  min_lr: 0.000150  loss: 0.9236 (0.9421)  class_acc: 0.7969 (0.8023)  weight_decay: 0.0500 (0.0500)  time: 0.9622  data: 0.0024  max mem: 8477\n","Epoch: [5]  [650/781]  eta: 0:02:07  lr: 0.000149  min_lr: 0.000149  loss: 0.9032 (0.9416)  class_acc: 0.7969 (0.8025)  weight_decay: 0.0500 (0.0500)  time: 0.9638  data: 0.0016  max mem: 8477\n","Epoch: [5]  [660/781]  eta: 0:01:57  lr: 0.000148  min_lr: 0.000148  loss: 0.8921 (0.9413)  class_acc: 0.8281 (0.8027)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0005  max mem: 8477\n","Epoch: [5]  [670/781]  eta: 0:01:47  lr: 0.000147  min_lr: 0.000147  loss: 0.8907 (0.9405)  class_acc: 0.8281 (0.8029)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0008  max mem: 8477\n","Epoch: [5]  [680/781]  eta: 0:01:38  lr: 0.000147  min_lr: 0.000147  loss: 0.9121 (0.9406)  class_acc: 0.8125 (0.8028)  weight_decay: 0.0500 (0.0500)  time: 0.9660  data: 0.0011  max mem: 8477\n","Epoch: [5]  [690/781]  eta: 0:01:28  lr: 0.000146  min_lr: 0.000146  loss: 0.9121 (0.9396)  class_acc: 0.7969 (0.8032)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0013  max mem: 8477\n","Epoch: [5]  [700/781]  eta: 0:01:18  lr: 0.000145  min_lr: 0.000145  loss: 0.8375 (0.9385)  class_acc: 0.8438 (0.8038)  weight_decay: 0.0500 (0.0500)  time: 0.9660  data: 0.0019  max mem: 8477\n","Epoch: [5]  [710/781]  eta: 0:01:08  lr: 0.000144  min_lr: 0.000144  loss: 0.8783 (0.9381)  class_acc: 0.8438 (0.8041)  weight_decay: 0.0500 (0.0500)  time: 0.9664  data: 0.0016  max mem: 8477\n","Epoch: [5]  [720/781]  eta: 0:00:59  lr: 0.000144  min_lr: 0.000144  loss: 0.8802 (0.9370)  class_acc: 0.8281 (0.8045)  weight_decay: 0.0500 (0.0500)  time: 0.9677  data: 0.0011  max mem: 8477\n","Epoch: [5]  [730/781]  eta: 0:00:49  lr: 0.000143  min_lr: 0.000143  loss: 0.8802 (0.9365)  class_acc: 0.8281 (0.8047)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0020  max mem: 8477\n","Epoch: [5]  [740/781]  eta: 0:00:39  lr: 0.000142  min_lr: 0.000142  loss: 0.9318 (0.9368)  class_acc: 0.8281 (0.8049)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0020  max mem: 8477\n","Epoch: [5]  [750/781]  eta: 0:00:30  lr: 0.000141  min_lr: 0.000141  loss: 0.9269 (0.9367)  class_acc: 0.8125 (0.8048)  weight_decay: 0.0500 (0.0500)  time: 0.9699  data: 0.0013  max mem: 8477\n","Epoch: [5]  [760/781]  eta: 0:00:20  lr: 0.000140  min_lr: 0.000140  loss: 0.9174 (0.9363)  class_acc: 0.7969 (0.8047)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0011  max mem: 8477\n","Epoch: [5]  [770/781]  eta: 0:00:10  lr: 0.000140  min_lr: 0.000140  loss: 0.9334 (0.9364)  class_acc: 0.7969 (0.8047)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0007  max mem: 8477\n","Epoch: [5]  [780/781]  eta: 0:00:00  lr: 0.000139  min_lr: 0.000139  loss: 0.9517 (0.9368)  class_acc: 0.7969 (0.8045)  weight_decay: 0.0500 (0.0500)  time: 0.9679  data: 0.0005  max mem: 8477\n","Epoch: [5] Total time: 0:12:38 (0.9717 s / it)\n","Averaged stats: lr: 0.000139  min_lr: 0.000139  loss: 0.9517 (0.9368)  class_acc: 0.7969 (0.8045)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:04:29  loss: 0.1997 (0.1997)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  time: 2.5657  data: 2.0655  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:03  loss: 0.1831 (0.1802)  acc1: 96.8750 (97.3485)  acc5: 100.0000 (99.9053)  time: 0.6663  data: 0.1885  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:49  loss: 0.1713 (0.1770)  acc1: 96.8750 (97.1230)  acc5: 100.0000 (99.9504)  time: 0.4787  data: 0.0012  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:41  loss: 0.2172 (0.2106)  acc1: 94.7917 (95.7661)  acc5: 100.0000 (99.8992)  time: 0.4834  data: 0.0015  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:34  loss: 0.3582 (0.2770)  acc1: 87.5000 (93.1911)  acc5: 100.0000 (99.8476)  time: 0.4856  data: 0.0016  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:28  loss: 0.3639 (0.2710)  acc1: 87.5000 (93.3824)  acc5: 100.0000 (99.8775)  time: 0.4861  data: 0.0017  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2382 (0.2763)  acc1: 93.7500 (93.0840)  acc5: 100.0000 (99.8805)  time: 0.4871  data: 0.0010  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:17  loss: 0.2299 (0.2660)  acc1: 93.7500 (93.5739)  acc5: 100.0000 (99.8826)  time: 0.4874  data: 0.0003  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.1814 (0.2584)  acc1: 96.8750 (93.9172)  acc5: 100.0000 (99.8457)  time: 0.4874  data: 0.0010  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.1873 (0.2506)  acc1: 96.8750 (94.1850)  acc5: 100.0000 (99.8626)  time: 0.4868  data: 0.0017  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1819 (0.2448)  acc1: 96.8750 (94.3998)  acc5: 100.0000 (99.8659)  time: 0.4871  data: 0.0009  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1808 (0.2417)  acc1: 96.8750 (94.4700)  acc5: 100.0000 (99.8700)  time: 0.4677  data: 0.0009  max mem: 8477\n","Test: Total time: 0:00:52 (0.5038 s / it)\n","* Acc@1 94.470 Acc@5 99.870 loss 0.242\n","Accuracy of the model on the 10000 test images: 94.5%\n","Max accuracy: 94.47%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [6]  [  0/781]  eta: 0:40:37  lr: 0.000139  min_lr: 0.000139  loss: 0.8500 (0.8500)  class_acc: 0.8594 (0.8594)  weight_decay: 0.0500 (0.0500)  time: 3.1209  data: 2.0615  max mem: 8477\n","Epoch: [6]  [ 10/781]  eta: 0:14:55  lr: 0.000138  min_lr: 0.000138  loss: 0.9744 (0.9832)  class_acc: 0.7812 (0.7869)  weight_decay: 0.0500 (0.0500)  time: 1.1610  data: 0.1906  max mem: 8477\n","Epoch: [6]  [ 20/781]  eta: 0:13:35  lr: 0.000137  min_lr: 0.000137  loss: 0.8817 (0.9423)  class_acc: 0.8125 (0.8088)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0023  max mem: 8477\n","Epoch: [6]  [ 30/781]  eta: 0:13:01  lr: 0.000137  min_lr: 0.000137  loss: 0.8537 (0.9080)  class_acc: 0.8438 (0.8271)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0012  max mem: 8477\n","Epoch: [6]  [ 40/781]  eta: 0:12:38  lr: 0.000136  min_lr: 0.000136  loss: 0.8853 (0.9193)  class_acc: 0.8281 (0.8201)  weight_decay: 0.0500 (0.0500)  time: 0.9737  data: 0.0010  max mem: 8477\n","Epoch: [6]  [ 50/781]  eta: 0:12:21  lr: 0.000135  min_lr: 0.000135  loss: 0.9197 (0.9122)  class_acc: 0.7969 (0.8195)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0011  max mem: 8477\n","Epoch: [6]  [ 60/781]  eta: 0:12:06  lr: 0.000134  min_lr: 0.000134  loss: 0.9013 (0.9139)  class_acc: 0.7969 (0.8174)  weight_decay: 0.0500 (0.0500)  time: 0.9745  data: 0.0012  max mem: 8477\n","Epoch: [6]  [ 70/781]  eta: 0:11:52  lr: 0.000134  min_lr: 0.000134  loss: 0.9013 (0.9122)  class_acc: 0.7969 (0.8176)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0013  max mem: 8477\n","Epoch: [6]  [ 80/781]  eta: 0:11:39  lr: 0.000133  min_lr: 0.000133  loss: 0.9006 (0.9146)  class_acc: 0.7969 (0.8160)  weight_decay: 0.0500 (0.0500)  time: 0.9671  data: 0.0014  max mem: 8477\n","Epoch: [6]  [ 90/781]  eta: 0:11:27  lr: 0.000132  min_lr: 0.000132  loss: 0.8809 (0.9105)  class_acc: 0.8125 (0.8178)  weight_decay: 0.0500 (0.0500)  time: 0.9665  data: 0.0015  max mem: 8477\n","Epoch: [6]  [100/781]  eta: 0:11:15  lr: 0.000131  min_lr: 0.000131  loss: 0.8799 (0.9073)  class_acc: 0.8281 (0.8209)  weight_decay: 0.0500 (0.0500)  time: 0.9658  data: 0.0014  max mem: 8477\n","Epoch: [6]  [110/781]  eta: 0:11:03  lr: 0.000131  min_lr: 0.000131  loss: 0.8835 (0.9101)  class_acc: 0.8281 (0.8190)  weight_decay: 0.0500 (0.0500)  time: 0.9640  data: 0.0012  max mem: 8477\n","Epoch: [6]  [120/781]  eta: 0:10:52  lr: 0.000130  min_lr: 0.000130  loss: 0.9322 (0.9120)  class_acc: 0.8125 (0.8182)  weight_decay: 0.0500 (0.0500)  time: 0.9642  data: 0.0011  max mem: 8477\n","Epoch: [6]  [130/781]  eta: 0:10:41  lr: 0.000129  min_lr: 0.000129  loss: 0.9224 (0.9128)  class_acc: 0.8125 (0.8177)  weight_decay: 0.0500 (0.0500)  time: 0.9631  data: 0.0007  max mem: 8477\n","Epoch: [6]  [140/781]  eta: 0:10:30  lr: 0.000128  min_lr: 0.000128  loss: 0.8840 (0.9107)  class_acc: 0.8125 (0.8187)  weight_decay: 0.0500 (0.0500)  time: 0.9634  data: 0.0004  max mem: 8477\n","Epoch: [6]  [150/781]  eta: 0:10:19  lr: 0.000128  min_lr: 0.000128  loss: 0.8802 (0.9100)  class_acc: 0.8125 (0.8184)  weight_decay: 0.0500 (0.0500)  time: 0.9654  data: 0.0005  max mem: 8477\n","Epoch: [6]  [160/781]  eta: 0:10:09  lr: 0.000127  min_lr: 0.000127  loss: 0.8802 (0.9093)  class_acc: 0.8125 (0.8180)  weight_decay: 0.0500 (0.0500)  time: 0.9655  data: 0.0007  max mem: 8477\n","Epoch: [6]  [170/781]  eta: 0:09:59  lr: 0.000126  min_lr: 0.000126  loss: 0.8928 (0.9105)  class_acc: 0.7969 (0.8178)  weight_decay: 0.0500 (0.0500)  time: 0.9687  data: 0.0008  max mem: 8477\n","Epoch: [6]  [180/781]  eta: 0:09:48  lr: 0.000125  min_lr: 0.000125  loss: 0.8822 (0.9085)  class_acc: 0.8125 (0.8182)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0011  max mem: 8477\n","Epoch: [6]  [190/781]  eta: 0:09:38  lr: 0.000125  min_lr: 0.000125  loss: 0.8928 (0.9091)  class_acc: 0.8125 (0.8181)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0017  max mem: 8477\n","Epoch: [6]  [200/781]  eta: 0:09:28  lr: 0.000124  min_lr: 0.000124  loss: 0.8977 (0.9090)  class_acc: 0.8125 (0.8179)  weight_decay: 0.0500 (0.0500)  time: 0.9676  data: 0.0019  max mem: 8477\n","Epoch: [6]  [210/781]  eta: 0:09:18  lr: 0.000123  min_lr: 0.000123  loss: 0.8950 (0.9084)  class_acc: 0.8125 (0.8181)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0011  max mem: 8477\n","Epoch: [6]  [220/781]  eta: 0:09:08  lr: 0.000122  min_lr: 0.000122  loss: 0.8876 (0.9070)  class_acc: 0.8438 (0.8192)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0009  max mem: 8477\n","Epoch: [6]  [230/781]  eta: 0:08:58  lr: 0.000122  min_lr: 0.000122  loss: 0.8957 (0.9075)  class_acc: 0.8281 (0.8187)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0010  max mem: 8477\n","Epoch: [6]  [240/781]  eta: 0:08:48  lr: 0.000121  min_lr: 0.000121  loss: 0.9190 (0.9081)  class_acc: 0.7969 (0.8180)  weight_decay: 0.0500 (0.0500)  time: 0.9719  data: 0.0010  max mem: 8477\n","Epoch: [6]  [250/781]  eta: 0:08:38  lr: 0.000120  min_lr: 0.000120  loss: 0.9190 (0.9085)  class_acc: 0.7969 (0.8175)  weight_decay: 0.0500 (0.0500)  time: 0.9684  data: 0.0008  max mem: 8477\n","Epoch: [6]  [260/781]  eta: 0:08:28  lr: 0.000119  min_lr: 0.000119  loss: 0.9394 (0.9102)  class_acc: 0.7969 (0.8166)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0008  max mem: 8477\n","Epoch: [6]  [270/781]  eta: 0:08:18  lr: 0.000119  min_lr: 0.000119  loss: 0.8620 (0.9089)  class_acc: 0.8125 (0.8168)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0010  max mem: 8477\n","Epoch: [6]  [280/781]  eta: 0:08:09  lr: 0.000118  min_lr: 0.000118  loss: 0.8877 (0.9101)  class_acc: 0.8125 (0.8161)  weight_decay: 0.0500 (0.0500)  time: 0.9726  data: 0.0012  max mem: 8477\n","Epoch: [6]  [290/781]  eta: 0:07:59  lr: 0.000117  min_lr: 0.000117  loss: 0.9119 (0.9091)  class_acc: 0.8125 (0.8160)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0017  max mem: 8477\n","Epoch: [6]  [300/781]  eta: 0:07:49  lr: 0.000116  min_lr: 0.000116  loss: 0.8908 (0.9093)  class_acc: 0.8281 (0.8164)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0016  max mem: 8477\n","Epoch: [6]  [310/781]  eta: 0:07:39  lr: 0.000116  min_lr: 0.000116  loss: 0.8898 (0.9085)  class_acc: 0.8281 (0.8169)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0012  max mem: 8477\n","Epoch: [6]  [320/781]  eta: 0:07:29  lr: 0.000115  min_lr: 0.000115  loss: 0.8902 (0.9089)  class_acc: 0.8125 (0.8168)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0009  max mem: 8477\n","Epoch: [6]  [330/781]  eta: 0:07:20  lr: 0.000114  min_lr: 0.000114  loss: 0.8992 (0.9088)  class_acc: 0.8125 (0.8170)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0014  max mem: 8477\n","Epoch: [6]  [340/781]  eta: 0:07:10  lr: 0.000114  min_lr: 0.000114  loss: 0.8992 (0.9087)  class_acc: 0.8125 (0.8169)  weight_decay: 0.0500 (0.0500)  time: 0.9726  data: 0.0013  max mem: 8477\n","Epoch: [6]  [350/781]  eta: 0:07:00  lr: 0.000113  min_lr: 0.000113  loss: 0.8610 (0.9074)  class_acc: 0.8125 (0.8178)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0009  max mem: 8477\n","Epoch: [6]  [360/781]  eta: 0:06:50  lr: 0.000112  min_lr: 0.000112  loss: 0.8477 (0.9070)  class_acc: 0.8438 (0.8179)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0014  max mem: 8477\n","Epoch: [6]  [370/781]  eta: 0:06:40  lr: 0.000111  min_lr: 0.000111  loss: 0.8700 (0.9067)  class_acc: 0.8125 (0.8178)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0014  max mem: 8477\n","Epoch: [6]  [380/781]  eta: 0:06:31  lr: 0.000111  min_lr: 0.000111  loss: 0.8611 (0.9056)  class_acc: 0.8125 (0.8183)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0008  max mem: 8477\n","Epoch: [6]  [390/781]  eta: 0:06:21  lr: 0.000110  min_lr: 0.000110  loss: 0.8295 (0.9045)  class_acc: 0.8438 (0.8187)  weight_decay: 0.0500 (0.0500)  time: 0.9733  data: 0.0010  max mem: 8477\n","Epoch: [6]  [400/781]  eta: 0:06:11  lr: 0.000109  min_lr: 0.000109  loss: 0.8627 (0.9044)  class_acc: 0.8125 (0.8186)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0019  max mem: 8477\n","Epoch: [6]  [410/781]  eta: 0:06:01  lr: 0.000109  min_lr: 0.000109  loss: 0.8657 (0.9036)  class_acc: 0.8125 (0.8188)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0015  max mem: 8477\n","Epoch: [6]  [420/781]  eta: 0:05:51  lr: 0.000108  min_lr: 0.000108  loss: 0.8823 (0.9034)  class_acc: 0.8125 (0.8189)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0009  max mem: 8477\n","Epoch: [6]  [430/781]  eta: 0:05:42  lr: 0.000107  min_lr: 0.000107  loss: 0.9026 (0.9034)  class_acc: 0.8125 (0.8188)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0010  max mem: 8477\n","Epoch: [6]  [440/781]  eta: 0:05:32  lr: 0.000106  min_lr: 0.000106  loss: 0.8678 (0.9034)  class_acc: 0.7969 (0.8187)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0012  max mem: 8477\n","Epoch: [6]  [450/781]  eta: 0:05:22  lr: 0.000106  min_lr: 0.000106  loss: 0.8813 (0.9031)  class_acc: 0.8125 (0.8191)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0013  max mem: 8477\n","Epoch: [6]  [460/781]  eta: 0:05:12  lr: 0.000105  min_lr: 0.000105  loss: 0.8878 (0.9040)  class_acc: 0.8125 (0.8186)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0007  max mem: 8477\n","Epoch: [6]  [470/781]  eta: 0:05:03  lr: 0.000104  min_lr: 0.000104  loss: 0.9173 (0.9038)  class_acc: 0.7812 (0.8184)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0007  max mem: 8477\n","Epoch: [6]  [480/781]  eta: 0:04:53  lr: 0.000104  min_lr: 0.000104  loss: 0.8369 (0.9020)  class_acc: 0.8281 (0.8193)  weight_decay: 0.0500 (0.0500)  time: 0.9736  data: 0.0016  max mem: 8477\n","Epoch: [6]  [490/781]  eta: 0:04:43  lr: 0.000103  min_lr: 0.000103  loss: 0.8380 (0.9019)  class_acc: 0.8281 (0.8196)  weight_decay: 0.0500 (0.0500)  time: 0.9718  data: 0.0019  max mem: 8477\n","Epoch: [6]  [500/781]  eta: 0:04:33  lr: 0.000102  min_lr: 0.000102  loss: 0.9080 (0.9020)  class_acc: 0.8125 (0.8194)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0011  max mem: 8477\n","Epoch: [6]  [510/781]  eta: 0:04:24  lr: 0.000101  min_lr: 0.000101  loss: 0.8674 (0.9019)  class_acc: 0.8125 (0.8195)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0010  max mem: 8477\n","Epoch: [6]  [520/781]  eta: 0:04:14  lr: 0.000101  min_lr: 0.000101  loss: 0.8626 (0.9018)  class_acc: 0.8281 (0.8196)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0015  max mem: 8477\n","Epoch: [6]  [530/781]  eta: 0:04:04  lr: 0.000100  min_lr: 0.000100  loss: 0.8931 (0.9015)  class_acc: 0.8125 (0.8198)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0014  max mem: 8477\n","Epoch: [6]  [540/781]  eta: 0:03:54  lr: 0.000099  min_lr: 0.000099  loss: 0.8694 (0.9006)  class_acc: 0.8281 (0.8203)  weight_decay: 0.0500 (0.0500)  time: 0.9741  data: 0.0009  max mem: 8477\n","Epoch: [6]  [550/781]  eta: 0:03:45  lr: 0.000099  min_lr: 0.000099  loss: 0.8412 (0.9001)  class_acc: 0.8281 (0.8205)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0011  max mem: 8477\n","Epoch: [6]  [560/781]  eta: 0:03:35  lr: 0.000098  min_lr: 0.000098  loss: 0.8703 (0.8995)  class_acc: 0.8281 (0.8208)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0011  max mem: 8477\n","Epoch: [6]  [570/781]  eta: 0:03:25  lr: 0.000097  min_lr: 0.000097  loss: 0.8703 (0.8992)  class_acc: 0.8281 (0.8210)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0012  max mem: 8477\n","Epoch: [6]  [580/781]  eta: 0:03:15  lr: 0.000097  min_lr: 0.000097  loss: 0.8817 (0.8988)  class_acc: 0.8438 (0.8215)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0019  max mem: 8477\n","Epoch: [6]  [590/781]  eta: 0:03:06  lr: 0.000096  min_lr: 0.000096  loss: 0.8972 (0.8993)  class_acc: 0.8125 (0.8212)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0017  max mem: 8477\n","Epoch: [6]  [600/781]  eta: 0:02:56  lr: 0.000095  min_lr: 0.000095  loss: 0.9134 (0.9000)  class_acc: 0.7969 (0.8207)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0012  max mem: 8477\n","Epoch: [6]  [610/781]  eta: 0:02:46  lr: 0.000095  min_lr: 0.000095  loss: 0.8972 (0.8996)  class_acc: 0.7969 (0.8209)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0009  max mem: 8477\n","Epoch: [6]  [620/781]  eta: 0:02:36  lr: 0.000094  min_lr: 0.000094  loss: 0.8492 (0.8992)  class_acc: 0.8125 (0.8209)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0007  max mem: 8477\n","Epoch: [6]  [630/781]  eta: 0:02:27  lr: 0.000093  min_lr: 0.000093  loss: 0.9052 (0.8996)  class_acc: 0.8125 (0.8206)  weight_decay: 0.0500 (0.0500)  time: 0.9717  data: 0.0007  max mem: 8477\n","Epoch: [6]  [640/781]  eta: 0:02:17  lr: 0.000093  min_lr: 0.000093  loss: 0.9008 (0.8991)  class_acc: 0.8125 (0.8208)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0009  max mem: 8477\n","Epoch: [6]  [650/781]  eta: 0:02:07  lr: 0.000092  min_lr: 0.000092  loss: 0.8402 (0.8986)  class_acc: 0.8594 (0.8211)  weight_decay: 0.0500 (0.0500)  time: 0.9733  data: 0.0008  max mem: 8477\n","Epoch: [6]  [660/781]  eta: 0:01:57  lr: 0.000091  min_lr: 0.000091  loss: 0.8402 (0.8978)  class_acc: 0.8594 (0.8216)  weight_decay: 0.0500 (0.0500)  time: 0.9738  data: 0.0007  max mem: 8477\n","Epoch: [6]  [670/781]  eta: 0:01:48  lr: 0.000091  min_lr: 0.000091  loss: 0.8282 (0.8978)  class_acc: 0.8438 (0.8218)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0006  max mem: 8477\n","Epoch: [6]  [680/781]  eta: 0:01:38  lr: 0.000090  min_lr: 0.000090  loss: 0.8708 (0.8979)  class_acc: 0.8281 (0.8218)  weight_decay: 0.0500 (0.0500)  time: 0.9674  data: 0.0011  max mem: 8477\n","Epoch: [6]  [690/781]  eta: 0:01:28  lr: 0.000089  min_lr: 0.000089  loss: 0.8750 (0.8976)  class_acc: 0.8125 (0.8220)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0015  max mem: 8477\n","Epoch: [6]  [700/781]  eta: 0:01:18  lr: 0.000089  min_lr: 0.000089  loss: 0.8508 (0.8965)  class_acc: 0.8281 (0.8224)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0013  max mem: 8477\n","Epoch: [6]  [710/781]  eta: 0:01:09  lr: 0.000088  min_lr: 0.000088  loss: 0.8380 (0.8963)  class_acc: 0.8438 (0.8227)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0015  max mem: 8477\n","Epoch: [6]  [720/781]  eta: 0:00:59  lr: 0.000087  min_lr: 0.000087  loss: 0.8380 (0.8957)  class_acc: 0.8438 (0.8230)  weight_decay: 0.0500 (0.0500)  time: 0.9707  data: 0.0020  max mem: 8477\n","Epoch: [6]  [730/781]  eta: 0:00:49  lr: 0.000087  min_lr: 0.000087  loss: 0.8290 (0.8955)  class_acc: 0.8438 (0.8231)  weight_decay: 0.0500 (0.0500)  time: 0.9733  data: 0.0015  max mem: 8477\n","Epoch: [6]  [740/781]  eta: 0:00:39  lr: 0.000086  min_lr: 0.000086  loss: 0.8646 (0.8952)  class_acc: 0.8281 (0.8233)  weight_decay: 0.0500 (0.0500)  time: 0.9741  data: 0.0009  max mem: 8477\n","Epoch: [6]  [750/781]  eta: 0:00:30  lr: 0.000085  min_lr: 0.000085  loss: 0.8878 (0.8959)  class_acc: 0.8125 (0.8231)  weight_decay: 0.0500 (0.0500)  time: 0.9717  data: 0.0008  max mem: 8477\n","Epoch: [6]  [760/781]  eta: 0:00:20  lr: 0.000085  min_lr: 0.000085  loss: 0.9187 (0.8958)  class_acc: 0.8125 (0.8231)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0008  max mem: 8477\n","Epoch: [6]  [770/781]  eta: 0:00:10  lr: 0.000084  min_lr: 0.000084  loss: 0.8817 (0.8960)  class_acc: 0.8125 (0.8228)  weight_decay: 0.0500 (0.0500)  time: 0.9681  data: 0.0005  max mem: 8477\n","Epoch: [6]  [780/781]  eta: 0:00:00  lr: 0.000083  min_lr: 0.000083  loss: 0.8817 (0.8960)  class_acc: 0.8125 (0.8229)  weight_decay: 0.0500 (0.0500)  time: 0.9677  data: 0.0004  max mem: 8477\n","Epoch: [6] Total time: 0:12:40 (0.9738 s / it)\n","Averaged stats: lr: 0.000083  min_lr: 0.000083  loss: 0.8817 (0.8960)  class_acc: 0.8125 (0.8229)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:04:20  loss: 0.1675 (0.1675)  acc1: 97.9167 (97.9167)  acc5: 100.0000 (100.0000)  time: 2.4781  data: 1.9051  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:02  loss: 0.1767 (0.1798)  acc1: 96.8750 (96.9697)  acc5: 100.0000 (99.9053)  time: 0.6582  data: 0.1751  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:48  loss: 0.1674 (0.1739)  acc1: 96.8750 (97.3214)  acc5: 100.0000 (99.9504)  time: 0.4779  data: 0.0019  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:40  loss: 0.2004 (0.2001)  acc1: 96.8750 (96.3038)  acc5: 100.0000 (99.8656)  time: 0.4833  data: 0.0018  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:34  loss: 0.3125 (0.2365)  acc1: 91.6667 (94.9949)  acc5: 100.0000 (99.8730)  time: 0.4872  data: 0.0015  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:28  loss: 0.3029 (0.2324)  acc1: 92.7083 (95.1593)  acc5: 100.0000 (99.8979)  time: 0.4876  data: 0.0010  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2384 (0.2520)  acc1: 93.7500 (94.3648)  acc5: 100.0000 (99.9146)  time: 0.4868  data: 0.0013  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:17  loss: 0.2422 (0.2461)  acc1: 93.7500 (94.6009)  acc5: 100.0000 (99.8973)  time: 0.4865  data: 0.0016  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.1906 (0.2440)  acc1: 96.8750 (94.7402)  acc5: 100.0000 (99.8714)  time: 0.4873  data: 0.0010  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.1925 (0.2376)  acc1: 95.8333 (94.9176)  acc5: 100.0000 (99.8855)  time: 0.4873  data: 0.0015  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1898 (0.2334)  acc1: 95.8333 (95.0392)  acc5: 100.0000 (99.8969)  time: 0.4874  data: 0.0015  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1785 (0.2309)  acc1: 95.8333 (95.0800)  acc5: 100.0000 (99.9000)  time: 0.4678  data: 0.0006  max mem: 8477\n","Test: Total time: 0:00:52 (0.5031 s / it)\n","* Acc@1 95.080 Acc@5 99.900 loss 0.231\n","Accuracy of the model on the 10000 test images: 95.1%\n","Max accuracy: 95.08%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [7]  [  0/781]  eta: 0:39:36  lr: 0.000083  min_lr: 0.000083  loss: 0.8933 (0.8933)  class_acc: 0.8438 (0.8438)  weight_decay: 0.0500 (0.0500)  time: 3.0429  data: 2.0169  max mem: 8477\n","Epoch: [7]  [ 10/781]  eta: 0:14:46  lr: 0.000083  min_lr: 0.000083  loss: 0.9209 (0.9481)  class_acc: 0.8125 (0.8139)  weight_decay: 0.0500 (0.0500)  time: 1.1499  data: 0.1851  max mem: 8477\n","Epoch: [7]  [ 20/781]  eta: 0:13:28  lr: 0.000082  min_lr: 0.000082  loss: 0.8771 (0.8888)  class_acc: 0.8281 (0.8393)  weight_decay: 0.0500 (0.0500)  time: 0.9627  data: 0.0017  max mem: 8477\n","Epoch: [7]  [ 30/781]  eta: 0:12:55  lr: 0.000081  min_lr: 0.000081  loss: 0.8279 (0.8815)  class_acc: 0.8594 (0.8372)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0023  max mem: 8477\n","Epoch: [7]  [ 40/781]  eta: 0:12:35  lr: 0.000081  min_lr: 0.000081  loss: 0.8401 (0.8790)  class_acc: 0.8594 (0.8403)  weight_decay: 0.0500 (0.0500)  time: 0.9740  data: 0.0019  max mem: 8477\n","Epoch: [7]  [ 50/781]  eta: 0:12:18  lr: 0.000080  min_lr: 0.000080  loss: 0.8792 (0.8803)  class_acc: 0.8281 (0.8373)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0007  max mem: 8477\n","Epoch: [7]  [ 60/781]  eta: 0:12:03  lr: 0.000079  min_lr: 0.000079  loss: 0.8558 (0.8751)  class_acc: 0.8438 (0.8381)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0005  max mem: 8477\n","Epoch: [7]  [ 70/781]  eta: 0:11:50  lr: 0.000079  min_lr: 0.000079  loss: 0.8413 (0.8733)  class_acc: 0.8438 (0.8387)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0006  max mem: 8477\n","Epoch: [7]  [ 80/781]  eta: 0:11:37  lr: 0.000078  min_lr: 0.000078  loss: 0.8848 (0.8786)  class_acc: 0.8281 (0.8366)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0011  max mem: 8477\n","Epoch: [7]  [ 90/781]  eta: 0:11:25  lr: 0.000077  min_lr: 0.000077  loss: 0.8802 (0.8770)  class_acc: 0.8281 (0.8367)  weight_decay: 0.0500 (0.0500)  time: 0.9674  data: 0.0014  max mem: 8477\n","Epoch: [7]  [100/781]  eta: 0:11:13  lr: 0.000077  min_lr: 0.000077  loss: 0.8541 (0.8771)  class_acc: 0.8438 (0.8354)  weight_decay: 0.0500 (0.0500)  time: 0.9649  data: 0.0015  max mem: 8477\n","Epoch: [7]  [110/781]  eta: 0:11:01  lr: 0.000076  min_lr: 0.000076  loss: 0.8766 (0.8783)  class_acc: 0.8125 (0.8333)  weight_decay: 0.0500 (0.0500)  time: 0.9608  data: 0.0013  max mem: 8477\n","Epoch: [7]  [120/781]  eta: 0:10:50  lr: 0.000076  min_lr: 0.000076  loss: 0.8809 (0.8790)  class_acc: 0.8281 (0.8325)  weight_decay: 0.0500 (0.0500)  time: 0.9593  data: 0.0011  max mem: 8477\n","Epoch: [7]  [130/781]  eta: 0:10:39  lr: 0.000075  min_lr: 0.000075  loss: 0.8825 (0.8777)  class_acc: 0.8281 (0.8333)  weight_decay: 0.0500 (0.0500)  time: 0.9617  data: 0.0018  max mem: 8477\n","Epoch: [7]  [140/781]  eta: 0:10:28  lr: 0.000074  min_lr: 0.000074  loss: 0.8551 (0.8747)  class_acc: 0.8438 (0.8343)  weight_decay: 0.0500 (0.0500)  time: 0.9624  data: 0.0018  max mem: 8477\n","Epoch: [7]  [150/781]  eta: 0:10:18  lr: 0.000074  min_lr: 0.000074  loss: 0.8820 (0.8766)  class_acc: 0.8438 (0.8335)  weight_decay: 0.0500 (0.0500)  time: 0.9637  data: 0.0009  max mem: 8477\n","Epoch: [7]  [160/781]  eta: 0:10:08  lr: 0.000073  min_lr: 0.000073  loss: 0.8958 (0.8781)  class_acc: 0.7969 (0.8322)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0010  max mem: 8477\n","Epoch: [7]  [170/781]  eta: 0:09:58  lr: 0.000072  min_lr: 0.000072  loss: 0.8802 (0.8789)  class_acc: 0.8281 (0.8323)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0012  max mem: 8477\n","Epoch: [7]  [180/781]  eta: 0:09:47  lr: 0.000072  min_lr: 0.000072  loss: 0.8772 (0.8806)  class_acc: 0.8281 (0.8322)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0013  max mem: 8477\n","Epoch: [7]  [190/781]  eta: 0:09:37  lr: 0.000071  min_lr: 0.000071  loss: 0.8878 (0.8806)  class_acc: 0.8281 (0.8321)  weight_decay: 0.0500 (0.0500)  time: 0.9651  data: 0.0012  max mem: 8477\n","Epoch: [7]  [200/781]  eta: 0:09:27  lr: 0.000071  min_lr: 0.000071  loss: 0.8814 (0.8821)  class_acc: 0.8281 (0.8311)  weight_decay: 0.0500 (0.0500)  time: 0.9658  data: 0.0008  max mem: 8477\n","Epoch: [7]  [210/781]  eta: 0:09:17  lr: 0.000070  min_lr: 0.000070  loss: 0.8618 (0.8806)  class_acc: 0.8281 (0.8315)  weight_decay: 0.0500 (0.0500)  time: 0.9655  data: 0.0010  max mem: 8477\n","Epoch: [7]  [220/781]  eta: 0:09:07  lr: 0.000069  min_lr: 0.000069  loss: 0.8271 (0.8794)  class_acc: 0.8438 (0.8317)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0010  max mem: 8477\n","Epoch: [7]  [230/781]  eta: 0:08:57  lr: 0.000069  min_lr: 0.000069  loss: 0.8605 (0.8796)  class_acc: 0.8281 (0.8314)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0014  max mem: 8477\n","Epoch: [7]  [240/781]  eta: 0:08:47  lr: 0.000068  min_lr: 0.000068  loss: 0.8703 (0.8790)  class_acc: 0.8281 (0.8316)  weight_decay: 0.0500 (0.0500)  time: 0.9687  data: 0.0015  max mem: 8477\n","Epoch: [7]  [250/781]  eta: 0:08:37  lr: 0.000068  min_lr: 0.000068  loss: 0.8602 (0.8798)  class_acc: 0.8281 (0.8310)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0006  max mem: 8477\n","Epoch: [7]  [260/781]  eta: 0:08:27  lr: 0.000067  min_lr: 0.000067  loss: 0.8656 (0.8792)  class_acc: 0.8125 (0.8314)  weight_decay: 0.0500 (0.0500)  time: 0.9653  data: 0.0004  max mem: 8477\n","Epoch: [7]  [270/781]  eta: 0:08:17  lr: 0.000066  min_lr: 0.000066  loss: 0.8697 (0.8801)  class_acc: 0.8125 (0.8309)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0007  max mem: 8477\n","Epoch: [7]  [280/781]  eta: 0:08:08  lr: 0.000066  min_lr: 0.000066  loss: 0.9165 (0.8821)  class_acc: 0.7969 (0.8304)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0012  max mem: 8477\n","Epoch: [7]  [290/781]  eta: 0:07:58  lr: 0.000065  min_lr: 0.000065  loss: 0.8690 (0.8805)  class_acc: 0.8281 (0.8312)  weight_decay: 0.0500 (0.0500)  time: 0.9675  data: 0.0013  max mem: 8477\n","Epoch: [7]  [300/781]  eta: 0:07:48  lr: 0.000065  min_lr: 0.000065  loss: 0.8690 (0.8811)  class_acc: 0.8438 (0.8310)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0012  max mem: 8477\n","Epoch: [7]  [310/781]  eta: 0:07:38  lr: 0.000064  min_lr: 0.000064  loss: 0.8908 (0.8822)  class_acc: 0.8438 (0.8306)  weight_decay: 0.0500 (0.0500)  time: 0.9704  data: 0.0010  max mem: 8477\n","Epoch: [7]  [320/781]  eta: 0:07:28  lr: 0.000063  min_lr: 0.000063  loss: 0.8883 (0.8824)  class_acc: 0.8281 (0.8303)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0020  max mem: 8477\n","Epoch: [7]  [330/781]  eta: 0:07:18  lr: 0.000063  min_lr: 0.000063  loss: 0.8883 (0.8823)  class_acc: 0.8281 (0.8304)  weight_decay: 0.0500 (0.0500)  time: 0.9681  data: 0.0019  max mem: 8477\n","Epoch: [7]  [340/781]  eta: 0:07:09  lr: 0.000062  min_lr: 0.000062  loss: 0.8801 (0.8822)  class_acc: 0.8438 (0.8306)  weight_decay: 0.0500 (0.0500)  time: 0.9649  data: 0.0008  max mem: 8477\n","Epoch: [7]  [350/781]  eta: 0:06:59  lr: 0.000062  min_lr: 0.000062  loss: 0.8779 (0.8822)  class_acc: 0.8281 (0.8311)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0010  max mem: 8477\n","Epoch: [7]  [360/781]  eta: 0:06:49  lr: 0.000061  min_lr: 0.000061  loss: 0.9071 (0.8825)  class_acc: 0.8281 (0.8308)  weight_decay: 0.0500 (0.0500)  time: 0.9678  data: 0.0012  max mem: 8477\n","Epoch: [7]  [370/781]  eta: 0:06:39  lr: 0.000061  min_lr: 0.000061  loss: 0.8934 (0.8818)  class_acc: 0.8125 (0.8309)  weight_decay: 0.0500 (0.0500)  time: 0.9698  data: 0.0014  max mem: 8477\n","Epoch: [7]  [380/781]  eta: 0:06:30  lr: 0.000060  min_lr: 0.000060  loss: 0.8667 (0.8809)  class_acc: 0.8281 (0.8312)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0015  max mem: 8477\n","Epoch: [7]  [390/781]  eta: 0:06:20  lr: 0.000059  min_lr: 0.000059  loss: 0.8694 (0.8808)  class_acc: 0.8281 (0.8311)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0012  max mem: 8477\n","Epoch: [7]  [400/781]  eta: 0:06:10  lr: 0.000059  min_lr: 0.000059  loss: 0.8531 (0.8800)  class_acc: 0.8438 (0.8318)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0012  max mem: 8477\n","Epoch: [7]  [410/781]  eta: 0:06:00  lr: 0.000058  min_lr: 0.000058  loss: 0.8640 (0.8811)  class_acc: 0.8438 (0.8315)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0011  max mem: 8477\n","Epoch: [7]  [420/781]  eta: 0:05:51  lr: 0.000058  min_lr: 0.000058  loss: 0.8579 (0.8803)  class_acc: 0.8281 (0.8316)  weight_decay: 0.0500 (0.0500)  time: 0.9674  data: 0.0015  max mem: 8477\n","Epoch: [7]  [430/781]  eta: 0:05:41  lr: 0.000057  min_lr: 0.000057  loss: 0.8291 (0.8796)  class_acc: 0.8281 (0.8318)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0016  max mem: 8477\n","Epoch: [7]  [440/781]  eta: 0:05:31  lr: 0.000057  min_lr: 0.000057  loss: 0.8209 (0.8785)  class_acc: 0.8438 (0.8323)  weight_decay: 0.0500 (0.0500)  time: 0.9707  data: 0.0010  max mem: 8477\n","Epoch: [7]  [450/781]  eta: 0:05:21  lr: 0.000056  min_lr: 0.000056  loss: 0.8209 (0.8772)  class_acc: 0.8594 (0.8328)  weight_decay: 0.0500 (0.0500)  time: 0.9737  data: 0.0013  max mem: 8477\n","Epoch: [7]  [460/781]  eta: 0:05:12  lr: 0.000056  min_lr: 0.000056  loss: 0.8277 (0.8763)  class_acc: 0.8594 (0.8331)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0015  max mem: 8477\n","Epoch: [7]  [470/781]  eta: 0:05:02  lr: 0.000055  min_lr: 0.000055  loss: 0.8416 (0.8760)  class_acc: 0.8438 (0.8333)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0012  max mem: 8477\n","Epoch: [7]  [480/781]  eta: 0:04:52  lr: 0.000054  min_lr: 0.000054  loss: 0.8521 (0.8766)  class_acc: 0.8125 (0.8330)  weight_decay: 0.0500 (0.0500)  time: 0.9738  data: 0.0009  max mem: 8477\n","Epoch: [7]  [490/781]  eta: 0:04:42  lr: 0.000054  min_lr: 0.000054  loss: 0.8649 (0.8767)  class_acc: 0.8281 (0.8330)  weight_decay: 0.0500 (0.0500)  time: 0.9719  data: 0.0009  max mem: 8477\n","Epoch: [7]  [500/781]  eta: 0:04:33  lr: 0.000053  min_lr: 0.000053  loss: 0.8579 (0.8764)  class_acc: 0.8438 (0.8332)  weight_decay: 0.0500 (0.0500)  time: 0.9696  data: 0.0010  max mem: 8477\n","Epoch: [7]  [510/781]  eta: 0:04:23  lr: 0.000053  min_lr: 0.000053  loss: 0.8410 (0.8764)  class_acc: 0.8438 (0.8333)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0010  max mem: 8477\n","Epoch: [7]  [520/781]  eta: 0:04:13  lr: 0.000052  min_lr: 0.000052  loss: 0.8813 (0.8760)  class_acc: 0.8438 (0.8334)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0021  max mem: 8477\n","Epoch: [7]  [530/781]  eta: 0:04:04  lr: 0.000052  min_lr: 0.000052  loss: 0.9026 (0.8761)  class_acc: 0.8281 (0.8335)  weight_decay: 0.0500 (0.0500)  time: 0.9719  data: 0.0021  max mem: 8477\n","Epoch: [7]  [540/781]  eta: 0:03:54  lr: 0.000051  min_lr: 0.000051  loss: 0.8675 (0.8757)  class_acc: 0.8281 (0.8337)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0009  max mem: 8477\n","Epoch: [7]  [550/781]  eta: 0:03:44  lr: 0.000051  min_lr: 0.000051  loss: 0.8447 (0.8755)  class_acc: 0.8438 (0.8340)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0008  max mem: 8477\n","Epoch: [7]  [560/781]  eta: 0:03:34  lr: 0.000050  min_lr: 0.000050  loss: 0.8442 (0.8753)  class_acc: 0.8750 (0.8342)  weight_decay: 0.0500 (0.0500)  time: 0.9706  data: 0.0009  max mem: 8477\n","Epoch: [7]  [570/781]  eta: 0:03:25  lr: 0.000050  min_lr: 0.000050  loss: 0.8699 (0.8757)  class_acc: 0.8438 (0.8341)  weight_decay: 0.0500 (0.0500)  time: 0.9717  data: 0.0011  max mem: 8477\n","Epoch: [7]  [580/781]  eta: 0:03:15  lr: 0.000049  min_lr: 0.000049  loss: 0.8603 (0.8754)  class_acc: 0.8438 (0.8341)  weight_decay: 0.0500 (0.0500)  time: 0.9716  data: 0.0011  max mem: 8477\n","Epoch: [7]  [590/781]  eta: 0:03:05  lr: 0.000049  min_lr: 0.000049  loss: 0.8440 (0.8746)  class_acc: 0.8438 (0.8344)  weight_decay: 0.0500 (0.0500)  time: 0.9740  data: 0.0010  max mem: 8477\n","Epoch: [7]  [600/781]  eta: 0:02:55  lr: 0.000048  min_lr: 0.000048  loss: 0.8599 (0.8745)  class_acc: 0.8438 (0.8344)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0009  max mem: 8477\n","Epoch: [7]  [610/781]  eta: 0:02:46  lr: 0.000048  min_lr: 0.000048  loss: 0.8743 (0.8745)  class_acc: 0.8281 (0.8344)  weight_decay: 0.0500 (0.0500)  time: 0.9730  data: 0.0019  max mem: 8477\n","Epoch: [7]  [620/781]  eta: 0:02:36  lr: 0.000047  min_lr: 0.000047  loss: 0.8505 (0.8742)  class_acc: 0.8281 (0.8345)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0021  max mem: 8477\n","Epoch: [7]  [630/781]  eta: 0:02:26  lr: 0.000047  min_lr: 0.000047  loss: 0.8158 (0.8737)  class_acc: 0.8438 (0.8348)  weight_decay: 0.0500 (0.0500)  time: 0.9735  data: 0.0011  max mem: 8477\n","Epoch: [7]  [640/781]  eta: 0:02:17  lr: 0.000046  min_lr: 0.000046  loss: 0.8335 (0.8733)  class_acc: 0.8438 (0.8350)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0010  max mem: 8477\n","Epoch: [7]  [650/781]  eta: 0:02:07  lr: 0.000046  min_lr: 0.000046  loss: 0.8360 (0.8729)  class_acc: 0.8438 (0.8351)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0010  max mem: 8477\n","Epoch: [7]  [660/781]  eta: 0:01:57  lr: 0.000045  min_lr: 0.000045  loss: 0.8420 (0.8729)  class_acc: 0.8281 (0.8350)  weight_decay: 0.0500 (0.0500)  time: 0.9721  data: 0.0010  max mem: 8477\n","Epoch: [7]  [670/781]  eta: 0:01:47  lr: 0.000044  min_lr: 0.000044  loss: 0.8260 (0.8720)  class_acc: 0.8438 (0.8353)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0007  max mem: 8477\n","Epoch: [7]  [680/781]  eta: 0:01:38  lr: 0.000044  min_lr: 0.000044  loss: 0.8174 (0.8719)  class_acc: 0.8594 (0.8354)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0010  max mem: 8477\n","Epoch: [7]  [690/781]  eta: 0:01:28  lr: 0.000044  min_lr: 0.000044  loss: 0.8732 (0.8719)  class_acc: 0.8281 (0.8354)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0013  max mem: 8477\n","Epoch: [7]  [700/781]  eta: 0:01:18  lr: 0.000043  min_lr: 0.000043  loss: 0.8477 (0.8715)  class_acc: 0.8594 (0.8357)  weight_decay: 0.0500 (0.0500)  time: 0.9730  data: 0.0010  max mem: 8477\n","Epoch: [7]  [710/781]  eta: 0:01:09  lr: 0.000043  min_lr: 0.000043  loss: 0.8461 (0.8710)  class_acc: 0.8594 (0.8359)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0013  max mem: 8477\n","Epoch: [7]  [720/781]  eta: 0:00:59  lr: 0.000042  min_lr: 0.000042  loss: 0.8048 (0.8701)  class_acc: 0.8594 (0.8363)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0014  max mem: 8477\n","Epoch: [7]  [730/781]  eta: 0:00:49  lr: 0.000042  min_lr: 0.000042  loss: 0.8887 (0.8706)  class_acc: 0.7969 (0.8359)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0010  max mem: 8477\n","Epoch: [7]  [740/781]  eta: 0:00:39  lr: 0.000041  min_lr: 0.000041  loss: 0.9004 (0.8711)  class_acc: 0.7969 (0.8357)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0011  max mem: 8477\n","Epoch: [7]  [750/781]  eta: 0:00:30  lr: 0.000041  min_lr: 0.000041  loss: 0.8926 (0.8715)  class_acc: 0.8281 (0.8353)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0011  max mem: 8477\n","Epoch: [7]  [760/781]  eta: 0:00:20  lr: 0.000040  min_lr: 0.000040  loss: 0.8506 (0.8711)  class_acc: 0.8281 (0.8356)  weight_decay: 0.0500 (0.0500)  time: 0.9712  data: 0.0009  max mem: 8477\n","Epoch: [7]  [770/781]  eta: 0:00:10  lr: 0.000040  min_lr: 0.000040  loss: 0.8278 (0.8709)  class_acc: 0.8438 (0.8357)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0006  max mem: 8477\n","Epoch: [7]  [780/781]  eta: 0:00:00  lr: 0.000039  min_lr: 0.000039  loss: 0.8401 (0.8706)  class_acc: 0.8438 (0.8358)  weight_decay: 0.0500 (0.0500)  time: 0.9687  data: 0.0006  max mem: 8477\n","Epoch: [7] Total time: 0:12:39 (0.9725 s / it)\n","Averaged stats: lr: 0.000039  min_lr: 0.000039  loss: 0.8401 (0.8706)  class_acc: 0.8438 (0.8358)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:05:40  loss: 0.2168 (0.2168)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  time: 3.2389  data: 2.6936  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:09  loss: 0.1893 (0.1836)  acc1: 96.8750 (96.5909)  acc5: 100.0000 (99.9053)  time: 0.7264  data: 0.2464  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:51  loss: 0.1542 (0.1692)  acc1: 97.9167 (97.3214)  acc5: 100.0000 (99.9504)  time: 0.4782  data: 0.0040  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:42  loss: 0.1813 (0.1866)  acc1: 96.8750 (96.6062)  acc5: 100.0000 (99.8320)  time: 0.4815  data: 0.0040  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:35  loss: 0.3111 (0.2367)  acc1: 92.7083 (94.4614)  acc5: 100.0000 (99.7967)  time: 0.4839  data: 0.0015  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.3256 (0.2358)  acc1: 91.6667 (94.5874)  acc5: 100.0000 (99.8366)  time: 0.4861  data: 0.0014  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2690 (0.2554)  acc1: 92.7083 (93.7671)  acc5: 100.0000 (99.8463)  time: 0.4868  data: 0.0017  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.2690 (0.2448)  acc1: 92.7083 (94.2048)  acc5: 100.0000 (99.8533)  time: 0.4874  data: 0.0022  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.1585 (0.2377)  acc1: 97.9167 (94.5602)  acc5: 100.0000 (99.8457)  time: 0.4876  data: 0.0018  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.1695 (0.2299)  acc1: 96.8750 (94.8146)  acc5: 100.0000 (99.8626)  time: 0.4874  data: 0.0006  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1807 (0.2259)  acc1: 96.8750 (94.9154)  acc5: 100.0000 (99.8762)  time: 0.4873  data: 0.0002  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1723 (0.2240)  acc1: 96.8750 (94.9400)  acc5: 100.0000 (99.8800)  time: 0.4677  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5099 s / it)\n","* Acc@1 94.940 Acc@5 99.880 loss 0.224\n","Accuracy of the model on the 10000 test images: 94.9%\n","Max accuracy: 95.08%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [8]  [  0/781]  eta: 0:41:09  lr: 0.000039  min_lr: 0.000039  loss: 0.9233 (0.9233)  class_acc: 0.8125 (0.8125)  weight_decay: 0.0500 (0.0500)  time: 3.1621  data: 2.0834  max mem: 8477\n","Epoch: [8]  [ 10/781]  eta: 0:14:57  lr: 0.000039  min_lr: 0.000039  loss: 0.9233 (0.9158)  class_acc: 0.8125 (0.8139)  weight_decay: 0.0500 (0.0500)  time: 1.1643  data: 0.1910  max mem: 8477\n","Epoch: [8]  [ 20/781]  eta: 0:13:32  lr: 0.000038  min_lr: 0.000038  loss: 0.8741 (0.8779)  class_acc: 0.8438 (0.8371)  weight_decay: 0.0500 (0.0500)  time: 0.9634  data: 0.0013  max mem: 8477\n","Epoch: [8]  [ 30/781]  eta: 0:12:56  lr: 0.000038  min_lr: 0.000038  loss: 0.8154 (0.8502)  class_acc: 0.8594 (0.8473)  weight_decay: 0.0500 (0.0500)  time: 0.9625  data: 0.0009  max mem: 8477\n","Epoch: [8]  [ 40/781]  eta: 0:12:33  lr: 0.000037  min_lr: 0.000037  loss: 0.8519 (0.8595)  class_acc: 0.8438 (0.8438)  weight_decay: 0.0500 (0.0500)  time: 0.9626  data: 0.0011  max mem: 8477\n","Epoch: [8]  [ 50/781]  eta: 0:12:15  lr: 0.000037  min_lr: 0.000037  loss: 0.8655 (0.8544)  class_acc: 0.8438 (0.8474)  weight_decay: 0.0500 (0.0500)  time: 0.9619  data: 0.0013  max mem: 8477\n","Epoch: [8]  [ 60/781]  eta: 0:12:00  lr: 0.000036  min_lr: 0.000036  loss: 0.8652 (0.8551)  class_acc: 0.8594 (0.8473)  weight_decay: 0.0500 (0.0500)  time: 0.9626  data: 0.0014  max mem: 8477\n","Epoch: [8]  [ 70/781]  eta: 0:11:46  lr: 0.000036  min_lr: 0.000036  loss: 0.8236 (0.8472)  class_acc: 0.8594 (0.8499)  weight_decay: 0.0500 (0.0500)  time: 0.9637  data: 0.0011  max mem: 8477\n","Epoch: [8]  [ 80/781]  eta: 0:11:34  lr: 0.000035  min_lr: 0.000035  loss: 0.8236 (0.8509)  class_acc: 0.8594 (0.8486)  weight_decay: 0.0500 (0.0500)  time: 0.9643  data: 0.0008  max mem: 8477\n","Epoch: [8]  [ 90/781]  eta: 0:11:22  lr: 0.000035  min_lr: 0.000035  loss: 0.8179 (0.8468)  class_acc: 0.8594 (0.8504)  weight_decay: 0.0500 (0.0500)  time: 0.9667  data: 0.0011  max mem: 8477\n","Epoch: [8]  [100/781]  eta: 0:11:11  lr: 0.000035  min_lr: 0.000035  loss: 0.7929 (0.8412)  class_acc: 0.8594 (0.8533)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0009  max mem: 8477\n","Epoch: [8]  [110/781]  eta: 0:11:00  lr: 0.000034  min_lr: 0.000034  loss: 0.8005 (0.8374)  class_acc: 0.8594 (0.8539)  weight_decay: 0.0500 (0.0500)  time: 0.9681  data: 0.0005  max mem: 8477\n","Epoch: [8]  [120/781]  eta: 0:10:49  lr: 0.000034  min_lr: 0.000034  loss: 0.8068 (0.8379)  class_acc: 0.8594 (0.8524)  weight_decay: 0.0500 (0.0500)  time: 0.9653  data: 0.0006  max mem: 8477\n","Epoch: [8]  [130/781]  eta: 0:10:38  lr: 0.000033  min_lr: 0.000033  loss: 0.8360 (0.8380)  class_acc: 0.8438 (0.8522)  weight_decay: 0.0500 (0.0500)  time: 0.9656  data: 0.0009  max mem: 8477\n","Epoch: [8]  [140/781]  eta: 0:10:28  lr: 0.000033  min_lr: 0.000033  loss: 0.8502 (0.8428)  class_acc: 0.8281 (0.8488)  weight_decay: 0.0500 (0.0500)  time: 0.9652  data: 0.0010  max mem: 8477\n","Epoch: [8]  [150/781]  eta: 0:10:18  lr: 0.000032  min_lr: 0.000032  loss: 0.8502 (0.8429)  class_acc: 0.8438 (0.8498)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0012  max mem: 8477\n","Epoch: [8]  [160/781]  eta: 0:10:07  lr: 0.000032  min_lr: 0.000032  loss: 0.8507 (0.8444)  class_acc: 0.8438 (0.8490)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0013  max mem: 8477\n","Epoch: [8]  [170/781]  eta: 0:09:57  lr: 0.000031  min_lr: 0.000031  loss: 0.8507 (0.8449)  class_acc: 0.8438 (0.8478)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0010  max mem: 8477\n","Epoch: [8]  [180/781]  eta: 0:09:47  lr: 0.000031  min_lr: 0.000031  loss: 0.8487 (0.8461)  class_acc: 0.8281 (0.8474)  weight_decay: 0.0500 (0.0500)  time: 0.9717  data: 0.0011  max mem: 8477\n","Epoch: [8]  [190/781]  eta: 0:09:37  lr: 0.000031  min_lr: 0.000031  loss: 0.8575 (0.8462)  class_acc: 0.8281 (0.8471)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0010  max mem: 8477\n","Epoch: [8]  [200/781]  eta: 0:09:27  lr: 0.000030  min_lr: 0.000030  loss: 0.8491 (0.8473)  class_acc: 0.8438 (0.8462)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0008  max mem: 8477\n","Epoch: [8]  [210/781]  eta: 0:09:17  lr: 0.000030  min_lr: 0.000030  loss: 0.8429 (0.8478)  class_acc: 0.8438 (0.8457)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0009  max mem: 8477\n","Epoch: [8]  [220/781]  eta: 0:09:07  lr: 0.000029  min_lr: 0.000029  loss: 0.8481 (0.8490)  class_acc: 0.8438 (0.8454)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0012  max mem: 8477\n","Epoch: [8]  [230/781]  eta: 0:08:57  lr: 0.000029  min_lr: 0.000029  loss: 0.8665 (0.8505)  class_acc: 0.8281 (0.8442)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0015  max mem: 8477\n","Epoch: [8]  [240/781]  eta: 0:08:47  lr: 0.000029  min_lr: 0.000029  loss: 0.8571 (0.8514)  class_acc: 0.8281 (0.8442)  weight_decay: 0.0500 (0.0500)  time: 0.9710  data: 0.0018  max mem: 8477\n","Epoch: [8]  [250/781]  eta: 0:08:38  lr: 0.000028  min_lr: 0.000028  loss: 0.8382 (0.8508)  class_acc: 0.8438 (0.8444)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0015  max mem: 8477\n","Epoch: [8]  [260/781]  eta: 0:08:28  lr: 0.000028  min_lr: 0.000028  loss: 0.8496 (0.8510)  class_acc: 0.8438 (0.8445)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0011  max mem: 8477\n","Epoch: [8]  [270/781]  eta: 0:08:18  lr: 0.000027  min_lr: 0.000027  loss: 0.8676 (0.8521)  class_acc: 0.8438 (0.8442)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0010  max mem: 8477\n","Epoch: [8]  [280/781]  eta: 0:08:08  lr: 0.000027  min_lr: 0.000027  loss: 0.8779 (0.8527)  class_acc: 0.8438 (0.8441)  weight_decay: 0.0500 (0.0500)  time: 0.9666  data: 0.0007  max mem: 8477\n","Epoch: [8]  [290/781]  eta: 0:07:58  lr: 0.000027  min_lr: 0.000027  loss: 0.8415 (0.8517)  class_acc: 0.8438 (0.8444)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0008  max mem: 8477\n","Epoch: [8]  [300/781]  eta: 0:07:48  lr: 0.000026  min_lr: 0.000026  loss: 0.8238 (0.8525)  class_acc: 0.8438 (0.8440)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0013  max mem: 8477\n","Epoch: [8]  [310/781]  eta: 0:07:38  lr: 0.000026  min_lr: 0.000026  loss: 0.8482 (0.8525)  class_acc: 0.8438 (0.8440)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0014  max mem: 8477\n","Epoch: [8]  [320/781]  eta: 0:07:29  lr: 0.000025  min_lr: 0.000025  loss: 0.8062 (0.8513)  class_acc: 0.8594 (0.8448)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0011  max mem: 8477\n","Epoch: [8]  [330/781]  eta: 0:07:19  lr: 0.000025  min_lr: 0.000025  loss: 0.7971 (0.8509)  class_acc: 0.8750 (0.8450)  weight_decay: 0.0500 (0.0500)  time: 0.9729  data: 0.0009  max mem: 8477\n","Epoch: [8]  [340/781]  eta: 0:07:09  lr: 0.000025  min_lr: 0.000025  loss: 0.8718 (0.8513)  class_acc: 0.8281 (0.8446)  weight_decay: 0.0500 (0.0500)  time: 0.9699  data: 0.0011  max mem: 8477\n","Epoch: [8]  [350/781]  eta: 0:06:59  lr: 0.000024  min_lr: 0.000024  loss: 0.8475 (0.8511)  class_acc: 0.8281 (0.8445)  weight_decay: 0.0500 (0.0500)  time: 0.9676  data: 0.0013  max mem: 8477\n","Epoch: [8]  [360/781]  eta: 0:06:49  lr: 0.000024  min_lr: 0.000024  loss: 0.8198 (0.8507)  class_acc: 0.8438 (0.8444)  weight_decay: 0.0500 (0.0500)  time: 0.9671  data: 0.0009  max mem: 8477\n","Epoch: [8]  [370/781]  eta: 0:06:40  lr: 0.000023  min_lr: 0.000023  loss: 0.8540 (0.8508)  class_acc: 0.8438 (0.8445)  weight_decay: 0.0500 (0.0500)  time: 0.9704  data: 0.0007  max mem: 8477\n","Epoch: [8]  [380/781]  eta: 0:06:30  lr: 0.000023  min_lr: 0.000023  loss: 0.8535 (0.8509)  class_acc: 0.8281 (0.8440)  weight_decay: 0.0500 (0.0500)  time: 0.9730  data: 0.0006  max mem: 8477\n","Epoch: [8]  [390/781]  eta: 0:06:20  lr: 0.000023  min_lr: 0.000023  loss: 0.8029 (0.8494)  class_acc: 0.8438 (0.8450)  weight_decay: 0.0500 (0.0500)  time: 0.9720  data: 0.0004  max mem: 8477\n","Epoch: [8]  [400/781]  eta: 0:06:10  lr: 0.000022  min_lr: 0.000022  loss: 0.7962 (0.8499)  class_acc: 0.8594 (0.8448)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0006  max mem: 8477\n","Epoch: [8]  [410/781]  eta: 0:06:01  lr: 0.000022  min_lr: 0.000022  loss: 0.8540 (0.8504)  class_acc: 0.8281 (0.8444)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0006  max mem: 8477\n","Epoch: [8]  [420/781]  eta: 0:05:51  lr: 0.000022  min_lr: 0.000022  loss: 0.8540 (0.8507)  class_acc: 0.8125 (0.8441)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0007  max mem: 8477\n","Epoch: [8]  [430/781]  eta: 0:05:41  lr: 0.000021  min_lr: 0.000021  loss: 0.8451 (0.8500)  class_acc: 0.8438 (0.8444)  weight_decay: 0.0500 (0.0500)  time: 0.9702  data: 0.0024  max mem: 8477\n","Epoch: [8]  [440/781]  eta: 0:05:31  lr: 0.000021  min_lr: 0.000021  loss: 0.8115 (0.8492)  class_acc: 0.8594 (0.8446)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0023  max mem: 8477\n","Epoch: [8]  [450/781]  eta: 0:05:22  lr: 0.000021  min_lr: 0.000021  loss: 0.8115 (0.8486)  class_acc: 0.8594 (0.8450)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0009  max mem: 8477\n","Epoch: [8]  [460/781]  eta: 0:05:12  lr: 0.000020  min_lr: 0.000020  loss: 0.8084 (0.8483)  class_acc: 0.8594 (0.8451)  weight_decay: 0.0500 (0.0500)  time: 0.9722  data: 0.0011  max mem: 8477\n","Epoch: [8]  [470/781]  eta: 0:05:02  lr: 0.000020  min_lr: 0.000020  loss: 0.8409 (0.8497)  class_acc: 0.8281 (0.8441)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0010  max mem: 8477\n","Epoch: [8]  [480/781]  eta: 0:04:52  lr: 0.000020  min_lr: 0.000020  loss: 0.8571 (0.8494)  class_acc: 0.8125 (0.8445)  weight_decay: 0.0500 (0.0500)  time: 0.9655  data: 0.0011  max mem: 8477\n","Epoch: [8]  [490/781]  eta: 0:04:43  lr: 0.000019  min_lr: 0.000019  loss: 0.8250 (0.8496)  class_acc: 0.8438 (0.8443)  weight_decay: 0.0500 (0.0500)  time: 0.9662  data: 0.0010  max mem: 8477\n","Epoch: [8]  [500/781]  eta: 0:04:33  lr: 0.000019  min_lr: 0.000019  loss: 0.8176 (0.8482)  class_acc: 0.8594 (0.8447)  weight_decay: 0.0500 (0.0500)  time: 0.9706  data: 0.0012  max mem: 8477\n","Epoch: [8]  [510/781]  eta: 0:04:23  lr: 0.000019  min_lr: 0.000019  loss: 0.7715 (0.8473)  class_acc: 0.8594 (0.8451)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0011  max mem: 8477\n","Epoch: [8]  [520/781]  eta: 0:04:13  lr: 0.000018  min_lr: 0.000018  loss: 0.8151 (0.8476)  class_acc: 0.8594 (0.8449)  weight_decay: 0.0500 (0.0500)  time: 0.9719  data: 0.0006  max mem: 8477\n","Epoch: [8]  [530/781]  eta: 0:04:04  lr: 0.000018  min_lr: 0.000018  loss: 0.8269 (0.8476)  class_acc: 0.8438 (0.8449)  weight_decay: 0.0500 (0.0500)  time: 0.9728  data: 0.0012  max mem: 8477\n","Epoch: [8]  [540/781]  eta: 0:03:54  lr: 0.000018  min_lr: 0.000018  loss: 0.8248 (0.8475)  class_acc: 0.8438 (0.8450)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0014  max mem: 8477\n","Epoch: [8]  [550/781]  eta: 0:03:44  lr: 0.000017  min_lr: 0.000017  loss: 0.8374 (0.8476)  class_acc: 0.8594 (0.8449)  weight_decay: 0.0500 (0.0500)  time: 0.9690  data: 0.0011  max mem: 8477\n","Epoch: [8]  [560/781]  eta: 0:03:34  lr: 0.000017  min_lr: 0.000017  loss: 0.8670 (0.8481)  class_acc: 0.8281 (0.8446)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0009  max mem: 8477\n","Epoch: [8]  [570/781]  eta: 0:03:25  lr: 0.000017  min_lr: 0.000017  loss: 0.8610 (0.8478)  class_acc: 0.8125 (0.8445)  weight_decay: 0.0500 (0.0500)  time: 0.9664  data: 0.0010  max mem: 8477\n","Epoch: [8]  [580/781]  eta: 0:03:15  lr: 0.000016  min_lr: 0.000016  loss: 0.8390 (0.8476)  class_acc: 0.8438 (0.8447)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0012  max mem: 8477\n","Epoch: [8]  [590/781]  eta: 0:03:05  lr: 0.000016  min_lr: 0.000016  loss: 0.8602 (0.8476)  class_acc: 0.8438 (0.8448)  weight_decay: 0.0500 (0.0500)  time: 0.9741  data: 0.0009  max mem: 8477\n","Epoch: [8]  [600/781]  eta: 0:02:55  lr: 0.000016  min_lr: 0.000016  loss: 0.8324 (0.8472)  class_acc: 0.8281 (0.8448)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0009  max mem: 8477\n","Epoch: [8]  [610/781]  eta: 0:02:46  lr: 0.000015  min_lr: 0.000015  loss: 0.8128 (0.8469)  class_acc: 0.8594 (0.8451)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0011  max mem: 8477\n","Epoch: [8]  [620/781]  eta: 0:02:36  lr: 0.000015  min_lr: 0.000015  loss: 0.8192 (0.8470)  class_acc: 0.8594 (0.8450)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0016  max mem: 8477\n","Epoch: [8]  [630/781]  eta: 0:02:26  lr: 0.000015  min_lr: 0.000015  loss: 0.8352 (0.8468)  class_acc: 0.8438 (0.8451)  weight_decay: 0.0500 (0.0500)  time: 0.9678  data: 0.0015  max mem: 8477\n","Epoch: [8]  [640/781]  eta: 0:02:17  lr: 0.000015  min_lr: 0.000015  loss: 0.8282 (0.8467)  class_acc: 0.8438 (0.8452)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0006  max mem: 8477\n","Epoch: [8]  [650/781]  eta: 0:02:07  lr: 0.000014  min_lr: 0.000014  loss: 0.8456 (0.8469)  class_acc: 0.8281 (0.8450)  weight_decay: 0.0500 (0.0500)  time: 0.9686  data: 0.0009  max mem: 8477\n","Epoch: [8]  [660/781]  eta: 0:01:57  lr: 0.000014  min_lr: 0.000014  loss: 0.8420 (0.8463)  class_acc: 0.8438 (0.8453)  weight_decay: 0.0500 (0.0500)  time: 0.9677  data: 0.0013  max mem: 8477\n","Epoch: [8]  [670/781]  eta: 0:01:47  lr: 0.000014  min_lr: 0.000014  loss: 0.8108 (0.8460)  class_acc: 0.8594 (0.8455)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0010  max mem: 8477\n","Epoch: [8]  [680/781]  eta: 0:01:38  lr: 0.000013  min_lr: 0.000013  loss: 0.8443 (0.8465)  class_acc: 0.8438 (0.8454)  weight_decay: 0.0500 (0.0500)  time: 0.9699  data: 0.0013  max mem: 8477\n","Epoch: [8]  [690/781]  eta: 0:01:28  lr: 0.000013  min_lr: 0.000013  loss: 0.8596 (0.8466)  class_acc: 0.8281 (0.8452)  weight_decay: 0.0500 (0.0500)  time: 0.9686  data: 0.0013  max mem: 8477\n","Epoch: [8]  [700/781]  eta: 0:01:18  lr: 0.000013  min_lr: 0.000013  loss: 0.8372 (0.8463)  class_acc: 0.8281 (0.8453)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0008  max mem: 8477\n","Epoch: [8]  [710/781]  eta: 0:01:08  lr: 0.000013  min_lr: 0.000013  loss: 0.8060 (0.8458)  class_acc: 0.8594 (0.8454)  weight_decay: 0.0500 (0.0500)  time: 0.9709  data: 0.0017  max mem: 8477\n","Epoch: [8]  [720/781]  eta: 0:00:59  lr: 0.000012  min_lr: 0.000012  loss: 0.8060 (0.8454)  class_acc: 0.8594 (0.8458)  weight_decay: 0.0500 (0.0500)  time: 0.9724  data: 0.0021  max mem: 8477\n","Epoch: [8]  [730/781]  eta: 0:00:49  lr: 0.000012  min_lr: 0.000012  loss: 0.8113 (0.8453)  class_acc: 0.8594 (0.8458)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0012  max mem: 8477\n","Epoch: [8]  [740/781]  eta: 0:00:39  lr: 0.000012  min_lr: 0.000012  loss: 0.8199 (0.8454)  class_acc: 0.8438 (0.8459)  weight_decay: 0.0500 (0.0500)  time: 0.9728  data: 0.0010  max mem: 8477\n","Epoch: [8]  [750/781]  eta: 0:00:30  lr: 0.000012  min_lr: 0.000012  loss: 0.8201 (0.8455)  class_acc: 0.8594 (0.8459)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0014  max mem: 8477\n","Epoch: [8]  [760/781]  eta: 0:00:20  lr: 0.000011  min_lr: 0.000011  loss: 0.8436 (0.8456)  class_acc: 0.8594 (0.8460)  weight_decay: 0.0500 (0.0500)  time: 0.9675  data: 0.0014  max mem: 8477\n","Epoch: [8]  [770/781]  eta: 0:00:10  lr: 0.000011  min_lr: 0.000011  loss: 0.8495 (0.8457)  class_acc: 0.8281 (0.8457)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0010  max mem: 8477\n","Epoch: [8]  [780/781]  eta: 0:00:00  lr: 0.000011  min_lr: 0.000011  loss: 0.8495 (0.8457)  class_acc: 0.8438 (0.8459)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0005  max mem: 8477\n","Epoch: [8] Total time: 0:12:39 (0.9720 s / it)\n","Averaged stats: lr: 0.000011  min_lr: 0.000011  loss: 0.8495 (0.8457)  class_acc: 0.8438 (0.8459)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:05:10  loss: 0.2152 (0.2152)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  time: 2.9552  data: 2.4133  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:06  loss: 0.1899 (0.1910)  acc1: 95.8333 (96.3068)  acc5: 100.0000 (99.9053)  time: 0.7050  data: 0.2215  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:50  loss: 0.1624 (0.1741)  acc1: 97.9167 (97.1726)  acc5: 100.0000 (99.9504)  time: 0.4799  data: 0.0026  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:42  loss: 0.1855 (0.1927)  acc1: 96.8750 (96.4046)  acc5: 100.0000 (99.8992)  time: 0.4815  data: 0.0019  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:35  loss: 0.3119 (0.2411)  acc1: 92.7083 (94.6138)  acc5: 100.0000 (99.8984)  time: 0.4872  data: 0.0031  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.3119 (0.2389)  acc1: 91.6667 (94.7304)  acc5: 100.0000 (99.9183)  time: 0.4890  data: 0.0039  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2313 (0.2446)  acc1: 93.7500 (94.3135)  acc5: 100.0000 (99.9317)  time: 0.4871  data: 0.0020  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.2036 (0.2335)  acc1: 94.7917 (94.8063)  acc5: 100.0000 (99.9120)  time: 0.4874  data: 0.0009  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.1571 (0.2276)  acc1: 97.9167 (95.0617)  acc5: 100.0000 (99.8971)  time: 0.4875  data: 0.0007  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.1619 (0.2207)  acc1: 96.8750 (95.2839)  acc5: 100.0000 (99.9084)  time: 0.4875  data: 0.0013  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1714 (0.2174)  acc1: 96.8750 (95.3899)  acc5: 100.0000 (99.9175)  time: 0.4880  data: 0.0009  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1693 (0.2156)  acc1: 96.8750 (95.4200)  acc5: 100.0000 (99.9200)  time: 0.4685  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5081 s / it)\n","* Acc@1 95.420 Acc@5 99.920 loss 0.216\n","Accuracy of the model on the 10000 test images: 95.4%\n","Max accuracy: 95.42%\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","Epoch: [9]  [  0/781]  eta: 0:38:05  lr: 0.000011  min_lr: 0.000011  loss: 0.8427 (0.8427)  class_acc: 0.8750 (0.8750)  weight_decay: 0.0500 (0.0500)  time: 2.9260  data: 1.8524  max mem: 8477\n","Epoch: [9]  [ 10/781]  eta: 0:14:42  lr: 0.000011  min_lr: 0.000011  loss: 0.8427 (0.8626)  class_acc: 0.8750 (0.8494)  weight_decay: 0.0500 (0.0500)  time: 1.1441  data: 0.1690  max mem: 8477\n","Epoch: [9]  [ 20/781]  eta: 0:13:28  lr: 0.000010  min_lr: 0.000010  loss: 0.8348 (0.8422)  class_acc: 0.8594 (0.8519)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0011  max mem: 8477\n","Epoch: [9]  [ 30/781]  eta: 0:12:56  lr: 0.000010  min_lr: 0.000010  loss: 0.8043 (0.8287)  class_acc: 0.8750 (0.8584)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0011  max mem: 8477\n","Epoch: [9]  [ 40/781]  eta: 0:12:35  lr: 0.000010  min_lr: 0.000010  loss: 0.8247 (0.8357)  class_acc: 0.8594 (0.8540)  weight_decay: 0.0500 (0.0500)  time: 0.9750  data: 0.0007  max mem: 8477\n","Epoch: [9]  [ 50/781]  eta: 0:12:18  lr: 0.000010  min_lr: 0.000010  loss: 0.8262 (0.8351)  class_acc: 0.8594 (0.8539)  weight_decay: 0.0500 (0.0500)  time: 0.9745  data: 0.0008  max mem: 8477\n","Epoch: [9]  [ 60/781]  eta: 0:12:04  lr: 0.000009  min_lr: 0.000009  loss: 0.8148 (0.8358)  class_acc: 0.8594 (0.8530)  weight_decay: 0.0500 (0.0500)  time: 0.9728  data: 0.0015  max mem: 8477\n","Epoch: [9]  [ 70/781]  eta: 0:11:51  lr: 0.000009  min_lr: 0.000009  loss: 0.8232 (0.8331)  class_acc: 0.8594 (0.8548)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0015  max mem: 8477\n","Epoch: [9]  [ 80/781]  eta: 0:11:38  lr: 0.000009  min_lr: 0.000009  loss: 0.8239 (0.8347)  class_acc: 0.8438 (0.8526)  weight_decay: 0.0500 (0.0500)  time: 0.9714  data: 0.0010  max mem: 8477\n","Epoch: [9]  [ 90/781]  eta: 0:11:26  lr: 0.000009  min_lr: 0.000009  loss: 0.8058 (0.8353)  class_acc: 0.8438 (0.8525)  weight_decay: 0.0500 (0.0500)  time: 0.9672  data: 0.0010  max mem: 8477\n","Epoch: [9]  [100/781]  eta: 0:11:14  lr: 0.000008  min_lr: 0.000008  loss: 0.8087 (0.8353)  class_acc: 0.8594 (0.8526)  weight_decay: 0.0500 (0.0500)  time: 0.9651  data: 0.0010  max mem: 8477\n","Epoch: [9]  [110/781]  eta: 0:11:02  lr: 0.000008  min_lr: 0.000008  loss: 0.8256 (0.8343)  class_acc: 0.8438 (0.8522)  weight_decay: 0.0500 (0.0500)  time: 0.9631  data: 0.0013  max mem: 8477\n","Epoch: [9]  [120/781]  eta: 0:10:51  lr: 0.000008  min_lr: 0.000008  loss: 0.8322 (0.8374)  class_acc: 0.8438 (0.8499)  weight_decay: 0.0500 (0.0500)  time: 0.9627  data: 0.0014  max mem: 8477\n","Epoch: [9]  [130/781]  eta: 0:10:40  lr: 0.000008  min_lr: 0.000008  loss: 0.8322 (0.8364)  class_acc: 0.8438 (0.8503)  weight_decay: 0.0500 (0.0500)  time: 0.9635  data: 0.0013  max mem: 8477\n","Epoch: [9]  [140/781]  eta: 0:10:29  lr: 0.000008  min_lr: 0.000008  loss: 0.8356 (0.8397)  class_acc: 0.8594 (0.8495)  weight_decay: 0.0500 (0.0500)  time: 0.9655  data: 0.0008  max mem: 8477\n","Epoch: [9]  [150/781]  eta: 0:10:19  lr: 0.000007  min_lr: 0.000007  loss: 0.8613 (0.8405)  class_acc: 0.8594 (0.8494)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0019  max mem: 8477\n","Epoch: [9]  [160/781]  eta: 0:10:09  lr: 0.000007  min_lr: 0.000007  loss: 0.8264 (0.8397)  class_acc: 0.8438 (0.8499)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0023  max mem: 8477\n","Epoch: [9]  [170/781]  eta: 0:09:58  lr: 0.000007  min_lr: 0.000007  loss: 0.8503 (0.8428)  class_acc: 0.8438 (0.8482)  weight_decay: 0.0500 (0.0500)  time: 0.9688  data: 0.0009  max mem: 8477\n","Epoch: [9]  [180/781]  eta: 0:09:48  lr: 0.000007  min_lr: 0.000007  loss: 0.8531 (0.8426)  class_acc: 0.8281 (0.8482)  weight_decay: 0.0500 (0.0500)  time: 0.9692  data: 0.0005  max mem: 8477\n","Epoch: [9]  [190/781]  eta: 0:09:38  lr: 0.000007  min_lr: 0.000007  loss: 0.8372 (0.8446)  class_acc: 0.8438 (0.8473)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0005  max mem: 8477\n","Epoch: [9]  [200/781]  eta: 0:09:28  lr: 0.000006  min_lr: 0.000006  loss: 0.8318 (0.8416)  class_acc: 0.8438 (0.8487)  weight_decay: 0.0500 (0.0500)  time: 0.9719  data: 0.0008  max mem: 8477\n","Epoch: [9]  [210/781]  eta: 0:09:18  lr: 0.000006  min_lr: 0.000006  loss: 0.7732 (0.8394)  class_acc: 0.8750 (0.8497)  weight_decay: 0.0500 (0.0500)  time: 0.9708  data: 0.0009  max mem: 8477\n","Epoch: [9]  [220/781]  eta: 0:09:08  lr: 0.000006  min_lr: 0.000006  loss: 0.8029 (0.8380)  class_acc: 0.8750 (0.8503)  weight_decay: 0.0500 (0.0500)  time: 0.9732  data: 0.0008  max mem: 8477\n","Epoch: [9]  [230/781]  eta: 0:08:58  lr: 0.000006  min_lr: 0.000006  loss: 0.8140 (0.8378)  class_acc: 0.8594 (0.8504)  weight_decay: 0.0500 (0.0500)  time: 0.9744  data: 0.0010  max mem: 8477\n","Epoch: [9]  [240/781]  eta: 0:08:48  lr: 0.000006  min_lr: 0.000006  loss: 0.8140 (0.8373)  class_acc: 0.8594 (0.8506)  weight_decay: 0.0500 (0.0500)  time: 0.9731  data: 0.0013  max mem: 8477\n","Epoch: [9]  [250/781]  eta: 0:08:39  lr: 0.000006  min_lr: 0.000006  loss: 0.8464 (0.8385)  class_acc: 0.8281 (0.8497)  weight_decay: 0.0500 (0.0500)  time: 0.9734  data: 0.0012  max mem: 8477\n","Epoch: [9]  [260/781]  eta: 0:08:29  lr: 0.000005  min_lr: 0.000005  loss: 0.8831 (0.8395)  class_acc: 0.8281 (0.8494)  weight_decay: 0.0500 (0.0500)  time: 0.9715  data: 0.0010  max mem: 8477\n","Epoch: [9]  [270/781]  eta: 0:08:19  lr: 0.000005  min_lr: 0.000005  loss: 0.8492 (0.8404)  class_acc: 0.8281 (0.8487)  weight_decay: 0.0500 (0.0500)  time: 0.9683  data: 0.0013  max mem: 8477\n","Epoch: [9]  [280/781]  eta: 0:08:09  lr: 0.000005  min_lr: 0.000005  loss: 0.8492 (0.8426)  class_acc: 0.8281 (0.8478)  weight_decay: 0.0500 (0.0500)  time: 0.9676  data: 0.0012  max mem: 8477\n","Epoch: [9]  [290/781]  eta: 0:07:59  lr: 0.000005  min_lr: 0.000005  loss: 0.8265 (0.8419)  class_acc: 0.8438 (0.8479)  weight_decay: 0.0500 (0.0500)  time: 0.9686  data: 0.0009  max mem: 8477\n","Epoch: [9]  [300/781]  eta: 0:07:49  lr: 0.000005  min_lr: 0.000005  loss: 0.8133 (0.8421)  class_acc: 0.8438 (0.8478)  weight_decay: 0.0500 (0.0500)  time: 0.9723  data: 0.0010  max mem: 8477\n","Epoch: [9]  [310/781]  eta: 0:07:39  lr: 0.000005  min_lr: 0.000005  loss: 0.8269 (0.8421)  class_acc: 0.8438 (0.8478)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0009  max mem: 8477\n","Epoch: [9]  [320/781]  eta: 0:07:30  lr: 0.000004  min_lr: 0.000004  loss: 0.8269 (0.8421)  class_acc: 0.8438 (0.8476)  weight_decay: 0.0500 (0.0500)  time: 0.9742  data: 0.0010  max mem: 8477\n","Epoch: [9]  [330/781]  eta: 0:07:20  lr: 0.000004  min_lr: 0.000004  loss: 0.8138 (0.8411)  class_acc: 0.8594 (0.8479)  weight_decay: 0.0500 (0.0500)  time: 0.9713  data: 0.0016  max mem: 8477\n","Epoch: [9]  [340/781]  eta: 0:07:10  lr: 0.000004  min_lr: 0.000004  loss: 0.7882 (0.8398)  class_acc: 0.8594 (0.8484)  weight_decay: 0.0500 (0.0500)  time: 0.9674  data: 0.0015  max mem: 8477\n","Epoch: [9]  [350/781]  eta: 0:07:00  lr: 0.000004  min_lr: 0.000004  loss: 0.8203 (0.8401)  class_acc: 0.8594 (0.8484)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0011  max mem: 8477\n","Epoch: [9]  [360/781]  eta: 0:06:50  lr: 0.000004  min_lr: 0.000004  loss: 0.8260 (0.8400)  class_acc: 0.8594 (0.8487)  weight_decay: 0.0500 (0.0500)  time: 0.9693  data: 0.0010  max mem: 8477\n","Epoch: [9]  [370/781]  eta: 0:06:40  lr: 0.000004  min_lr: 0.000004  loss: 0.8172 (0.8402)  class_acc: 0.8438 (0.8485)  weight_decay: 0.0500 (0.0500)  time: 0.9703  data: 0.0009  max mem: 8477\n","Epoch: [9]  [380/781]  eta: 0:06:30  lr: 0.000004  min_lr: 0.000004  loss: 0.8094 (0.8389)  class_acc: 0.8750 (0.8492)  weight_decay: 0.0500 (0.0500)  time: 0.9697  data: 0.0008  max mem: 8477\n","Epoch: [9]  [390/781]  eta: 0:06:21  lr: 0.000003  min_lr: 0.000003  loss: 0.8123 (0.8391)  class_acc: 0.8594 (0.8490)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0009  max mem: 8477\n","Epoch: [9]  [400/781]  eta: 0:06:11  lr: 0.000003  min_lr: 0.000003  loss: 0.8285 (0.8380)  class_acc: 0.8594 (0.8496)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0009  max mem: 8477\n","Epoch: [9]  [410/781]  eta: 0:06:01  lr: 0.000003  min_lr: 0.000003  loss: 0.8091 (0.8381)  class_acc: 0.8594 (0.8497)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0008  max mem: 8477\n","Epoch: [9]  [420/781]  eta: 0:05:51  lr: 0.000003  min_lr: 0.000003  loss: 0.8119 (0.8380)  class_acc: 0.8594 (0.8498)  weight_decay: 0.0500 (0.0500)  time: 0.9659  data: 0.0011  max mem: 8477\n","Epoch: [9]  [430/781]  eta: 0:05:41  lr: 0.000003  min_lr: 0.000003  loss: 0.8115 (0.8379)  class_acc: 0.8438 (0.8496)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0009  max mem: 8477\n","Epoch: [9]  [440/781]  eta: 0:05:32  lr: 0.000003  min_lr: 0.000003  loss: 0.8115 (0.8372)  class_acc: 0.8438 (0.8500)  weight_decay: 0.0500 (0.0500)  time: 0.9688  data: 0.0014  max mem: 8477\n","Epoch: [9]  [450/781]  eta: 0:05:22  lr: 0.000003  min_lr: 0.000003  loss: 0.8069 (0.8364)  class_acc: 0.8594 (0.8506)  weight_decay: 0.0500 (0.0500)  time: 0.9682  data: 0.0018  max mem: 8477\n","Epoch: [9]  [460/781]  eta: 0:05:12  lr: 0.000003  min_lr: 0.000003  loss: 0.8050 (0.8356)  class_acc: 0.8750 (0.8514)  weight_decay: 0.0500 (0.0500)  time: 0.9711  data: 0.0010  max mem: 8477\n","Epoch: [9]  [470/781]  eta: 0:05:02  lr: 0.000003  min_lr: 0.000003  loss: 0.7755 (0.8346)  class_acc: 0.8906 (0.8518)  weight_decay: 0.0500 (0.0500)  time: 0.9725  data: 0.0008  max mem: 8477\n","Epoch: [9]  [480/781]  eta: 0:04:53  lr: 0.000002  min_lr: 0.000002  loss: 0.8430 (0.8352)  class_acc: 0.8438 (0.8515)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0010  max mem: 8477\n","Epoch: [9]  [490/781]  eta: 0:04:43  lr: 0.000002  min_lr: 0.000002  loss: 0.8545 (0.8354)  class_acc: 0.8438 (0.8515)  weight_decay: 0.0500 (0.0500)  time: 0.9665  data: 0.0009  max mem: 8477\n","Epoch: [9]  [500/781]  eta: 0:04:33  lr: 0.000002  min_lr: 0.000002  loss: 0.8322 (0.8349)  class_acc: 0.8594 (0.8517)  weight_decay: 0.0500 (0.0500)  time: 0.9675  data: 0.0006  max mem: 8477\n","Epoch: [9]  [510/781]  eta: 0:04:23  lr: 0.000002  min_lr: 0.000002  loss: 0.8114 (0.8351)  class_acc: 0.8438 (0.8516)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0015  max mem: 8477\n","Epoch: [9]  [520/781]  eta: 0:04:14  lr: 0.000002  min_lr: 0.000002  loss: 0.8360 (0.8354)  class_acc: 0.8438 (0.8515)  weight_decay: 0.0500 (0.0500)  time: 0.9694  data: 0.0018  max mem: 8477\n","Epoch: [9]  [530/781]  eta: 0:04:04  lr: 0.000002  min_lr: 0.000002  loss: 0.8360 (0.8356)  class_acc: 0.8438 (0.8515)  weight_decay: 0.0500 (0.0500)  time: 0.9704  data: 0.0016  max mem: 8477\n","Epoch: [9]  [540/781]  eta: 0:03:54  lr: 0.000002  min_lr: 0.000002  loss: 0.8116 (0.8358)  class_acc: 0.8438 (0.8514)  weight_decay: 0.0500 (0.0500)  time: 0.9700  data: 0.0016  max mem: 8477\n","Epoch: [9]  [550/781]  eta: 0:03:44  lr: 0.000002  min_lr: 0.000002  loss: 0.8122 (0.8362)  class_acc: 0.8438 (0.8513)  weight_decay: 0.0500 (0.0500)  time: 0.9671  data: 0.0015  max mem: 8477\n","Epoch: [9]  [560/781]  eta: 0:03:35  lr: 0.000002  min_lr: 0.000002  loss: 0.8173 (0.8358)  class_acc: 0.8438 (0.8515)  weight_decay: 0.0500 (0.0500)  time: 0.9679  data: 0.0015  max mem: 8477\n","Epoch: [9]  [570/781]  eta: 0:03:25  lr: 0.000002  min_lr: 0.000002  loss: 0.8260 (0.8360)  class_acc: 0.8438 (0.8513)  weight_decay: 0.0500 (0.0500)  time: 0.9705  data: 0.0008  max mem: 8477\n","Epoch: [9]  [580/781]  eta: 0:03:15  lr: 0.000002  min_lr: 0.000002  loss: 0.8260 (0.8353)  class_acc: 0.8438 (0.8516)  weight_decay: 0.0500 (0.0500)  time: 0.9685  data: 0.0009  max mem: 8477\n","Epoch: [9]  [590/781]  eta: 0:03:05  lr: 0.000002  min_lr: 0.000002  loss: 0.7898 (0.8351)  class_acc: 0.8750 (0.8517)  weight_decay: 0.0500 (0.0500)  time: 0.9670  data: 0.0011  max mem: 8477\n","Epoch: [9]  [600/781]  eta: 0:02:56  lr: 0.000002  min_lr: 0.000002  loss: 0.8114 (0.8350)  class_acc: 0.8594 (0.8517)  weight_decay: 0.0500 (0.0500)  time: 0.9678  data: 0.0016  max mem: 8477\n","Epoch: [9]  [610/781]  eta: 0:02:46  lr: 0.000001  min_lr: 0.000001  loss: 0.8162 (0.8349)  class_acc: 0.8438 (0.8518)  weight_decay: 0.0500 (0.0500)  time: 0.9673  data: 0.0013  max mem: 8477\n","Epoch: [9]  [620/781]  eta: 0:02:36  lr: 0.000001  min_lr: 0.000001  loss: 0.7991 (0.8344)  class_acc: 0.8750 (0.8523)  weight_decay: 0.0500 (0.0500)  time: 0.9665  data: 0.0011  max mem: 8477\n","Epoch: [9]  [630/781]  eta: 0:02:26  lr: 0.000001  min_lr: 0.000001  loss: 0.8330 (0.8351)  class_acc: 0.8438 (0.8519)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0013  max mem: 8477\n","Epoch: [9]  [640/781]  eta: 0:02:17  lr: 0.000001  min_lr: 0.000001  loss: 0.8697 (0.8353)  class_acc: 0.8281 (0.8517)  weight_decay: 0.0500 (0.0500)  time: 0.9674  data: 0.0007  max mem: 8477\n","Epoch: [9]  [650/781]  eta: 0:02:07  lr: 0.000001  min_lr: 0.000001  loss: 0.8266 (0.8346)  class_acc: 0.8438 (0.8520)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0007  max mem: 8477\n","Epoch: [9]  [660/781]  eta: 0:01:57  lr: 0.000001  min_lr: 0.000001  loss: 0.7893 (0.8350)  class_acc: 0.8438 (0.8519)  weight_decay: 0.0500 (0.0500)  time: 0.9689  data: 0.0014  max mem: 8477\n","Epoch: [9]  [670/781]  eta: 0:01:47  lr: 0.000001  min_lr: 0.000001  loss: 0.7905 (0.8345)  class_acc: 0.8594 (0.8522)  weight_decay: 0.0500 (0.0500)  time: 0.9678  data: 0.0017  max mem: 8477\n","Epoch: [9]  [680/781]  eta: 0:01:38  lr: 0.000001  min_lr: 0.000001  loss: 0.8182 (0.8349)  class_acc: 0.8594 (0.8520)  weight_decay: 0.0500 (0.0500)  time: 0.9669  data: 0.0014  max mem: 8477\n","Epoch: [9]  [690/781]  eta: 0:01:28  lr: 0.000001  min_lr: 0.000001  loss: 0.8341 (0.8349)  class_acc: 0.8438 (0.8520)  weight_decay: 0.0500 (0.0500)  time: 0.9668  data: 0.0020  max mem: 8477\n","Epoch: [9]  [700/781]  eta: 0:01:18  lr: 0.000001  min_lr: 0.000001  loss: 0.8217 (0.8344)  class_acc: 0.8750 (0.8522)  weight_decay: 0.0500 (0.0500)  time: 0.9662  data: 0.0020  max mem: 8477\n","Epoch: [9]  [710/781]  eta: 0:01:09  lr: 0.000001  min_lr: 0.000001  loss: 0.8201 (0.8343)  class_acc: 0.8750 (0.8523)  weight_decay: 0.0500 (0.0500)  time: 0.9687  data: 0.0013  max mem: 8477\n","Epoch: [9]  [720/781]  eta: 0:00:59  lr: 0.000001  min_lr: 0.000001  loss: 0.8171 (0.8339)  class_acc: 0.8594 (0.8525)  weight_decay: 0.0500 (0.0500)  time: 0.9695  data: 0.0009  max mem: 8477\n","Epoch: [9]  [730/781]  eta: 0:00:49  lr: 0.000001  min_lr: 0.000001  loss: 0.8151 (0.8343)  class_acc: 0.8438 (0.8524)  weight_decay: 0.0500 (0.0500)  time: 0.9681  data: 0.0007  max mem: 8477\n","Epoch: [9]  [740/781]  eta: 0:00:39  lr: 0.000001  min_lr: 0.000001  loss: 0.8550 (0.8347)  class_acc: 0.8438 (0.8521)  weight_decay: 0.0500 (0.0500)  time: 0.9691  data: 0.0010  max mem: 8477\n","Epoch: [9]  [750/781]  eta: 0:00:30  lr: 0.000001  min_lr: 0.000001  loss: 0.8305 (0.8342)  class_acc: 0.8594 (0.8526)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0012  max mem: 8477\n","Epoch: [9]  [760/781]  eta: 0:00:20  lr: 0.000001  min_lr: 0.000001  loss: 0.8142 (0.8339)  class_acc: 0.8750 (0.8527)  weight_decay: 0.0500 (0.0500)  time: 0.9680  data: 0.0011  max mem: 8477\n","Epoch: [9]  [770/781]  eta: 0:00:10  lr: 0.000001  min_lr: 0.000001  loss: 0.8264 (0.8337)  class_acc: 0.8438 (0.8527)  weight_decay: 0.0500 (0.0500)  time: 0.9664  data: 0.0008  max mem: 8477\n","Epoch: [9]  [780/781]  eta: 0:00:00  lr: 0.000001  min_lr: 0.000001  loss: 0.8356 (0.8334)  class_acc: 0.8438 (0.8529)  weight_decay: 0.0500 (0.0500)  time: 0.9701  data: 0.0008  max mem: 8477\n","Epoch: [9] Total time: 0:12:39 (0.9721 s / it)\n","Averaged stats: lr: 0.000001  min_lr: 0.000001  loss: 0.8356 (0.8334)  class_acc: 0.8438 (0.8529)  weight_decay: 0.0500 (0.0500)\n","Test:  [  0/105]  eta: 0:04:36  loss: 0.2023 (0.2023)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  time: 2.6330  data: 2.1030  max mem: 8477\n","Test:  [ 10/105]  eta: 0:01:04  loss: 0.1752 (0.1821)  acc1: 95.8333 (96.4962)  acc5: 100.0000 (99.9053)  time: 0.6791  data: 0.1997  max mem: 8477\n","Test:  [ 20/105]  eta: 0:00:49  loss: 0.1693 (0.1720)  acc1: 96.8750 (97.0734)  acc5: 100.0000 (99.9504)  time: 0.4831  data: 0.0052  max mem: 8477\n","Test:  [ 30/105]  eta: 0:00:41  loss: 0.1791 (0.1894)  acc1: 96.8750 (96.5390)  acc5: 100.0000 (99.8992)  time: 0.4849  data: 0.0018  max mem: 8477\n","Test:  [ 40/105]  eta: 0:00:34  loss: 0.3060 (0.2379)  acc1: 91.6667 (94.5884)  acc5: 100.0000 (99.8984)  time: 0.4868  data: 0.0017  max mem: 8477\n","Test:  [ 50/105]  eta: 0:00:29  loss: 0.3000 (0.2350)  acc1: 90.6250 (94.7304)  acc5: 100.0000 (99.9183)  time: 0.4867  data: 0.0010  max mem: 8477\n","Test:  [ 60/105]  eta: 0:00:23  loss: 0.2354 (0.2433)  acc1: 93.7500 (94.3306)  acc5: 100.0000 (99.9317)  time: 0.4872  data: 0.0009  max mem: 8477\n","Test:  [ 70/105]  eta: 0:00:18  loss: 0.2178 (0.2325)  acc1: 94.7917 (94.7770)  acc5: 100.0000 (99.9266)  time: 0.4873  data: 0.0004  max mem: 8477\n","Test:  [ 80/105]  eta: 0:00:12  loss: 0.1588 (0.2264)  acc1: 97.9167 (95.0360)  acc5: 100.0000 (99.9100)  time: 0.4876  data: 0.0006  max mem: 8477\n","Test:  [ 90/105]  eta: 0:00:07  loss: 0.1661 (0.2198)  acc1: 96.8750 (95.2381)  acc5: 100.0000 (99.9199)  time: 0.4875  data: 0.0010  max mem: 8477\n","Test:  [100/105]  eta: 0:00:02  loss: 0.1735 (0.2163)  acc1: 96.8750 (95.3795)  acc5: 100.0000 (99.9278)  time: 0.4875  data: 0.0006  max mem: 8477\n","Test:  [104/105]  eta: 0:00:00  loss: 0.1697 (0.2144)  acc1: 96.8750 (95.4100)  acc5: 100.0000 (99.9300)  time: 0.4682  data: 0.0002  max mem: 8477\n","Test: Total time: 0:00:53 (0.5057 s / it)\n","* Acc@1 95.410 Acc@5 99.930 loss 0.214\n","Accuracy of the model on the 10000 test images: 95.4%\n","Max accuracy: 95.42%\n","\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./model_ckpt)... Done. 7.2s\n","Training time 2:15:46\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 ▁▃▅▆▇▇█▇██\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 ▁▄▃▅▇▆▇▆██\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss █▆▄▃▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Global Train/train_class_acc ▁▃▄▅▆▆▇▇██\n","\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss █▆▅▄▃▃▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr ██▇▆▅▄▃▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr ██▇▆▅▄▃▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay ▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:   Rank-0 Batch Wise/train_class_acc ▁▃▃▅▁▇▃▄▄▄▆▅▄▅▆▇▅▅▅▆▆▇▅▇▅▅▇▇▆▇▅▅▆▅█▇▅█▆█\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss █▆▆▄▆▃▅▅▅▅▄▄▄▄▄▃▃▃▄▃▃▂▄▂▃▃▂▂▃▃▄▃▃▃▂▂▄▁▃▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr ███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr ███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch ▁▂▃▃▄▅▆▆▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc1 95.41\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_acc5 99.93\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Test/test_loss 0.21437\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Global Train/train_class_acc 0.85287\n","\u001b[34m\u001b[1mwandb\u001b[0m:             Global Train/train_loss 0.83341\n","\u001b[34m\u001b[1mwandb\u001b[0m:               Global Train/train_lr 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:           Global Train/train_min_lr 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:     Global Train/train_weight_decay 0.05\n","\u001b[34m\u001b[1mwandb\u001b[0m: Rank-0 Batch Wise/global_train_step 7809\n","\u001b[34m\u001b[1mwandb\u001b[0m:   Rank-0 Batch Wise/train_class_acc 0.84375\n","\u001b[34m\u001b[1mwandb\u001b[0m:        Rank-0 Batch Wise/train_loss 0.83584\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_max_lr 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:      Rank-0 Batch Wise/train_min_lr 0.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:                               epoch 9\n","\u001b[34m\u001b[1mwandb\u001b[0m:                        n_parameters 27827818\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mskilled-resonance-2\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/mist/convnext/runs/1t3nj2l9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 5 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220719_201816-1t3nj2l9/logs\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# 🏐 Conclusion\n","\n","* **The above setting gives a top-1 accuracy of ~95%.**\n","* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset. \n","* The finetune model achieves competitive results. \n","\n","* By passing two arguments you get the following:\n","\n","  * Repository of all your experiments (train and test metrics) as a [W&B Project](https://docs.wandb.ai/ref/app/pages/project-page). You can easily compare experiments to find the best performing model.\n","  * Hyperparameters (Configs) used to train individual models. \n","  * System (CPU/GPU/Disk) metrics.\n","  * Model checkpoints saved as W&B Artifacts. They are versioned and easy to share. \n","\n","  Check out the associated [W&B run page](https://wandb.ai/ayut/convnext/runs/16vi9e31). $→$"],"metadata":{"id":"350MmZgtBVWy"}}]}