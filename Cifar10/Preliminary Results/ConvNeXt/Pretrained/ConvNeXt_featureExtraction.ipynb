{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ConvNeXt_featureExtraction.ipynb","provenance":[{"file_id":"1V_SsZRzpwrhUTAhn7tXuKwhbnKoR15aE","timestamp":1648933339354},{"file_id":"1JMydR7Cs3IZaG3rkmVtBRiB7c3w9djZy","timestamp":1648931443727}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-VAVxPNTxdHo"},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from numpy.lib.function_base import append\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])"],"metadata":{"id":"eQj2eJVxxsXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=2)\n","\n","test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False, num_workers=2)\n","\n","classes = ('Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5hc1y07qxu6_","executionInfo":{"status":"ok","timestamp":1656468038170,"user_tz":240,"elapsed":1680,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"502d60fc-3b36-4b86-9c5e-81c7e257a49e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["dataiter = iter(trainloader)\n","images, labels = dataiter.next()"],"metadata":{"id":"mtucpPyC1wpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1mgr2CiNsvq4","executionInfo":{"status":"ok","timestamp":1656468041150,"user_tz":240,"elapsed":2797,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"5063fd5a-cf54-4c23-d620-01d232bb583b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"]}]},{"cell_type":"code","source":["from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification\n","import torch\n","\n","feature_extractor = ConvNextFeatureExtractor.from_pretrained(\"facebook/convnext-tiny-224\")\n","model = ConvNextForImageClassification.from_pretrained(\"facebook/convnext-tiny-224\")\n","# model = ConvNextFeatureExtractor.from_pretrained(\"facebook/convnext-tiny-224\")\n","\n","\n","#Now using the AlexNet\n","# model = torch.hub.load('pytorch/vision', 'ConvNeXt', pretrained=True)\n","# model.eval()"],"metadata":{"id":"RHgApe8tx1-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inputs = feature_extractor(image, return_tensors=\"pt\")\n","\n","# with torch.no_grad():\n","#     logits = model(**inputs).logits\n","\n","# # model predicts one of the 1000 ImageNet classes\n","# predicted_label = logits.argmax(-1).item()\n","# print(model.config.id2label[predicted_label]),"],"metadata":{"id":"foLITRQ8tEIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for param in model.parameters():\n","    param.requires_grad = False\n"],"metadata":{"id":"1HRsUAfQzzSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Removing layers after fc7\n","# import torch.nn as nn\n","# # https://stackoverflow.com/questions/51501828/how-to-extract-fc7-features-from-alexnet-in-pytorch-as-numpy-array\n","# new_classifier = nn.Sequential(*list(model.classifier.children())[:-2])\n","# model.classifier = new_classifier"],"metadata":{"id":"Dzf_dyXWzev7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKhqUzVgz4fj","executionInfo":{"status":"ok","timestamp":1656468041844,"user_tz":240,"elapsed":67,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"62b8f78a-6e09-449e-a535-2bc11c952d98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNextForImageClassification(\n","  (convnext): ConvNextModel(\n","    (embeddings): ConvNextEmbeddings(\n","      (patch_embeddings): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (layernorm): ConvNextLayerNorm()\n","    )\n","    (encoder): ConvNextEncoder(\n","      (stages): ModuleList(\n","        (0): ConvNextStage(\n","          (downsampling_layer): Identity()\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (1): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (2): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (3): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (4): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (5): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (6): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (7): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (8): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (3): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Linear(in_features=768, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["model.named_modules()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09pQ_lATxPsJ","executionInfo":{"status":"ok","timestamp":1656468041845,"user_tz":240,"elapsed":50,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"ae596bc0-31ee-421b-a53e-12471d2ef0a8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.named_modules at 0x7f3a6c7b6cd0>"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["# Removing last layer of convnext\n","import torch.nn as nn\n","new_classifier = nn.Sequential(*list(model.classifier.children())[:-1])\n","model.classifier = new_classifier"],"metadata":{"id":"U7HB-BfNt2kZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AhnkllGlt_gc","executionInfo":{"status":"ok","timestamp":1656468041993,"user_tz":240,"elapsed":38,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"3ee10f7c-6842-4709-c451-ba42521da1a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNextForImageClassification(\n","  (convnext): ConvNextModel(\n","    (embeddings): ConvNextEmbeddings(\n","      (patch_embeddings): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (layernorm): ConvNextLayerNorm()\n","    )\n","    (encoder): ConvNextEncoder(\n","      (stages): ModuleList(\n","        (0): ConvNextStage(\n","          (downsampling_layer): Identity()\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (1): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (2): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (3): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (4): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (5): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (6): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (7): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (8): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (3): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Sequential()\n",")"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["# move the input and model to GPU for speed if available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JvuFaTb1IWj","executionInfo":{"status":"ok","timestamp":1656468041994,"user_tz":240,"elapsed":32,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"df87bd3d-f32d-4383-d6f0-1f8beb6c60da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}]},{"cell_type":"code","source":["model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_GlYtuUz2DXJ","executionInfo":{"status":"ok","timestamp":1656468041994,"user_tz":240,"elapsed":12,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"68c15520-6099-48bb-aed8-535750e1af28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNextForImageClassification(\n","  (convnext): ConvNextModel(\n","    (embeddings): ConvNextEmbeddings(\n","      (patch_embeddings): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n","      (layernorm): ConvNextLayerNorm()\n","    )\n","    (encoder): ConvNextEncoder(\n","      (stages): ModuleList(\n","        (0): ConvNextStage(\n","          (downsampling_layer): Identity()\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=96, out_features=384, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=384, out_features=96, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (1): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=192, out_features=768, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=768, out_features=192, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (2): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (3): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (4): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (5): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (6): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (7): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (8): ConvNextLayer(\n","              (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","        (3): ConvNextStage(\n","          (downsampling_layer): Sequential(\n","            (0): ConvNextLayerNorm()\n","            (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n","          )\n","          (layers): Sequential(\n","            (0): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (1): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","            (2): ConvNextLayer(\n","              (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n","              (layernorm): ConvNextLayerNorm()\n","              (pwconv1): Linear(in_features=768, out_features=3072, bias=True)\n","              (act): GELUActivation()\n","              (pwconv2): Linear(in_features=3072, out_features=768, bias=True)\n","              (drop_path): Identity()\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","  )\n","  (classifier): Sequential()\n",")"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# Getting xtest, ytest from the model\n","xtest = []\n","ytest = []\n","\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        ytest.append(labels)\n","        xtest.append(model(images))\n"],"metadata":{"id":"dtsdyA667SIJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Getting xtrain, ytrain from the model\n","xtrain = []\n","ytrain = []\n","\n","with torch.no_grad():\n","    for data in trainloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        ytrain.append(labels)\n","        xtrain.append(model(images))"],"metadata":{"id":"4Juq_ybNShBr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving xtest, ytest to use in another file\n","torch.save(xtest, 'xtestconvnext.pt')\n","torch.save(ytest, 'ytestconvnext.pt')"],"metadata":{"id":"FA-ZPINe7Z-g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving xtrain, ytrain to use in another file\n","torch.save(xtrain, 'xtrainconvnext.pt')\n","torch.save(ytrain, 'ytrainconvnext.pt')"],"metadata":{"id":"B4qRGaPqT3zO"},"execution_count":null,"outputs":[]}]}