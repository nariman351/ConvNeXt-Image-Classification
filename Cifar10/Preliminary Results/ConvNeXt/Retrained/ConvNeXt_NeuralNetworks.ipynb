{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ConvNeXt_NeuralNetworks.ipynb","provenance":[{"file_id":"104-STW_ZEhJISxJ0LbfeHanWoJ-oIKvl","timestamp":1648944867202}],"collapsed_sections":[],"mount_file_id":"104-STW_ZEhJISxJ0LbfeHanWoJ-oIKvl","authorship_tag":"ABX9TyOM2jws1Y1vTuXEelDMMSoh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch"],"metadata":{"id":"3b3tHIGUZsQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqGXIlYJlzBM","executionInfo":{"status":"ok","timestamp":1658370619199,"user_tz":240,"elapsed":10341,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"22dcef74-2c7c-4df3-9d5d-11fcaf3434da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 4.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 45.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCHMpq1dcbWX","executionInfo":{"status":"ok","timestamp":1658370512914,"user_tz":240,"elapsed":17713,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"f00e43d5-1d35-428e-879f-aaea5d125192"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["xtrain = torch.load('./drive/MyDrive/MLProject/xtrainconvnext.pt',map_location=torch.device('cpu'))\n","ytrain = torch.load('./drive/MyDrive/MLProject/ytrainconvnext.pt',map_location=torch.device('cpu'))\n","xtest = torch.load('./drive/MyDrive/MLProject/xtestconvnext.pt',map_location=torch.device('cpu'))\n","ytest = torch.load('./drive/MyDrive/MLProject/ytestconvnext.pt',map_location=torch.device('cpu'))"],"metadata":{"id":"Y62YYh_pbXNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(xtrain)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJ2OpSxR_8at","executionInfo":{"status":"ok","timestamp":1658370631503,"user_tz":240,"elapsed":12,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"ef49c7e4-21f0-4862-8c06-9cc208ff11b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["12500"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["xtrain[0].logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DD6sX-Xk8Qsq","executionInfo":{"status":"ok","timestamp":1658370631737,"user_tz":240,"elapsed":240,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"32ff04c1-0291-4bbd-d767-1c5c13babc03"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0970, -0.2797, -0.2374,  ...,  0.2035, -0.1968, -0.2819],\n","        [-0.0668,  0.4410, -0.7452,  ...,  0.0150, -0.2125,  0.2795],\n","        [ 0.2108, -0.0450, -0.7191,  ..., -0.2082, -0.2974,  0.1566],\n","        [-0.4496, -0.4706, -0.8118,  ..., -0.5422,  0.5650,  0.3224]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["xtest[0].logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTocnQPtCqp5","executionInfo":{"status":"ok","timestamp":1658370631737,"user_tz":240,"elapsed":28,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"afa5da89-5a37-412b-d8cb-f6b7f0f930b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.9773e-01, -7.0178e-02, -3.7201e-01,  1.7608e-01,  1.9039e-01,\n","         -2.0810e-01, -7.4339e-02, -2.5052e-01,  1.5424e-01, -5.7588e-02,\n","          5.0018e-01, -1.6397e-02, -4.3196e-01, -5.2352e-02, -6.6966e-01,\n","          8.0492e-02, -1.0220e-01, -8.6355e-02, -7.3400e-01,  2.5742e-01,\n","          1.0769e-01, -5.2853e-01,  1.1252e-01, -1.2042e-01,  3.3263e-02,\n","          1.4191e-01,  1.5133e-01,  5.8903e-01, -1.4762e-01, -4.2799e-02,\n","         -9.6434e-02,  9.9700e-02,  2.9185e-01, -6.5392e-02, -1.5473e-01,\n","          8.7884e-02,  1.1074e-01, -2.7604e-01,  3.5598e-01, -1.7493e-01,\n","         -2.8661e-01,  6.7609e-02, -8.9845e-01,  7.2487e-01,  1.2117e-01,\n","          4.5008e-01, -7.8046e-02, -7.1369e-02,  4.3883e-01, -1.4440e-01,\n","         -1.7897e-01, -2.9359e-01, -1.8736e-01,  1.6721e+00, -1.1190e-01,\n","          2.4245e-01, -5.2655e-01, -6.1564e-01,  1.6131e-01, -1.4596e-01,\n","         -1.4417e-02, -2.5069e-01, -1.4239e-01,  2.2931e-01, -4.9707e-03,\n","          1.2725e-01, -3.2255e-01,  2.4392e-01, -1.0082e-01, -1.6765e-01,\n","          2.7449e-01,  5.9751e-01, -1.3365e+00, -1.7292e-01, -2.7715e-01,\n","         -3.5568e-01, -3.2930e-02, -5.7416e-01, -2.0203e-01, -3.4233e-01,\n","          5.3216e-02, -1.1188e-01,  1.2553e-01, -4.3528e-01, -4.7467e-02,\n","          6.6155e-02, -3.5962e-01,  1.5655e-02,  7.0217e-01,  8.0043e-01,\n","         -2.3695e-01, -1.6384e-01,  1.4903e-01, -6.7670e-02,  3.2671e-01,\n","          9.8994e-02, -3.9817e-01,  9.3999e-02,  1.7990e-01, -6.0712e-01,\n","          3.9267e-01,  3.1742e-01,  2.7642e-01,  6.1227e-02,  2.9135e-01,\n","          2.4277e-01, -8.1562e-03, -2.7205e-01, -2.6559e-03, -7.2576e-01,\n","          1.8049e-01,  2.3624e-01,  1.8776e-01,  9.1262e-01,  1.3161e+00,\n","         -3.6181e-01, -7.5921e-02, -2.9894e-01, -6.3042e-02, -1.0822e-01,\n","         -6.6313e-01,  3.5811e-01, -4.6013e-01, -1.2476e-01, -7.2171e-01,\n","          1.0275e-01, -8.9087e-02, -7.1718e-02,  3.3449e-01,  1.6148e-01,\n","          6.5278e-01, -6.2403e-01,  1.0563e-01, -2.5085e-01,  3.4569e-01,\n","          5.3402e-01,  1.6143e-01,  3.3065e-01,  3.7653e-01, -1.7132e-02,\n","          1.8424e-01,  3.0223e-01,  2.2023e-02, -4.9179e-01,  3.4468e-01,\n","          1.0764e-01, -1.3719e-02, -2.6752e-01, -2.0502e-02, -7.3984e-02,\n","          3.8918e-02, -3.3204e-01, -2.9654e-01, -1.4774e-01, -1.3750e+00,\n","         -4.3652e-01, -1.0034e+00, -2.5924e-01, -9.8385e-02, -1.9566e-01,\n","         -1.0278e-01,  2.6678e-01,  4.4713e-01, -2.4953e-02, -2.8399e-01,\n","          1.1367e+00,  2.2539e-01,  1.8496e-01, -4.6523e-01, -6.9882e-02,\n","         -4.5585e-01,  1.8640e-01,  1.9051e-01, -4.6803e-01,  2.0847e-01,\n","         -3.0823e-02,  1.8890e-01, -1.9386e-01,  9.0895e-02,  7.1601e-01,\n","         -9.8290e-02,  5.2255e-02,  4.6766e-01,  4.6364e-01, -1.6548e-01,\n","          9.5010e-02, -3.1036e-01, -5.8119e-01, -3.9578e-02, -1.0519e-01,\n","          4.7856e-02,  2.7211e-01, -4.4008e-02, -1.7502e-01,  6.8807e-02,\n","          7.5027e-01,  7.6964e-02, -9.9546e-02,  1.3015e-01, -3.7709e-01,\n","         -4.5755e-01,  3.6171e-01, -2.2187e-01,  5.0920e-01, -2.6160e-01,\n","         -3.0147e-02,  2.0492e-01, -3.6661e-02,  2.7235e-01, -2.3945e-01,\n","         -2.8081e-01, -5.4856e-01, -2.3055e-01,  4.0830e-02,  7.6959e-01,\n","          4.7927e-01,  1.3251e-01, -7.7083e-01,  3.9333e-01, -5.1126e-02,\n","         -3.7200e-01,  5.0802e-01, -9.3992e-01, -2.7784e-01,  2.7794e-02,\n","         -8.5715e-01, -8.5993e-02, -8.5733e-01,  3.9590e-01, -2.0108e-01,\n","         -1.9297e-01,  4.7753e-01, -7.6609e-01, -3.5530e-01, -2.7744e-01,\n","         -1.7347e-01, -1.4287e-01,  1.6264e-01, -2.6929e-01, -2.4499e-01,\n","         -1.0674e+00,  2.9495e-01, -3.2581e-01,  2.2338e-01,  7.0880e-01,\n","         -5.3873e-01, -2.2422e-01,  1.9782e-01,  1.0647e+00, -3.1676e-01,\n","         -1.9748e-01,  3.7813e-01, -3.8151e-02, -5.5820e-02, -2.6489e-01,\n","          3.1103e-01, -4.1259e-01,  4.4204e-01,  9.2048e-02, -7.4612e-01,\n","          2.6352e-01, -1.9103e-01, -6.1117e-01,  5.0381e-01,  4.1785e-01,\n","         -2.6291e-02,  3.7178e-01, -1.7499e-01,  4.2160e-01,  1.2544e-01,\n","         -1.0147e-01, -1.6344e-01, -1.8037e+00, -4.3014e-01,  3.2038e-01,\n","          1.8973e-01, -1.7006e-01, -9.6967e-02, -7.3342e-02,  4.7301e-01,\n","         -8.5582e-02, -1.9216e-01,  7.0546e-01,  3.8212e-02, -5.3427e-01,\n","          3.5136e-01,  5.4416e-01,  1.5940e-03, -9.0452e-02,  3.6804e-01,\n","          9.5156e-02, -6.8926e-02, -1.7753e-01,  4.3901e-01,  1.5767e-01,\n","         -3.2049e-01, -3.8458e-02, -1.2362e+00, -3.9242e-02, -7.5698e-02,\n","         -8.5657e-02, -1.1320e-01, -3.5277e-03,  1.6081e-01,  1.7748e-01,\n","         -1.8031e-01, -2.6442e-01,  5.9905e-01,  6.6185e-02,  2.5939e-01,\n","          3.1091e-01,  6.4255e-01,  3.5033e-02, -4.2653e-01,  1.9938e-01,\n","         -2.5479e-01,  4.5958e-01, -1.4555e+00,  8.3493e-02, -4.7600e-01,\n","          2.4643e-01, -2.4365e-01,  1.1145e+00,  3.0666e-01, -1.8591e-01,\n","         -6.8609e-02,  1.7882e-01,  8.3441e-03,  4.1965e-01, -5.1550e-01,\n","         -2.9238e-01, -1.6976e-01,  4.9728e-02,  4.2594e-01, -3.2480e-01,\n","          6.7623e-01, -2.7111e-01,  1.3328e-01,  5.3181e-01,  5.1389e-02,\n","          5.2571e-01, -3.1883e-01,  3.8157e-01,  1.4266e-01, -1.6526e-01,\n","         -4.0801e-02,  1.1335e-01, -1.3458e-01,  1.2067e-01,  2.4714e-01,\n","         -7.0963e-01, -2.4864e-01, -3.8503e-01, -2.7667e-01, -1.2858e-01,\n","         -5.1905e-02, -5.6412e-01,  2.6000e-03, -3.0639e-01,  6.5179e-01,\n","         -2.3905e-01, -1.6255e-01,  8.3386e-01, -3.7776e-02,  3.6688e-01,\n","         -1.1468e-01, -2.0712e-01,  8.8846e-02,  1.1746e-01,  2.5466e-01,\n","          3.5680e-01,  1.5411e-02, -2.3432e-01,  6.2112e-01, -3.1319e-01,\n","          2.2451e-01,  5.2223e-02,  7.5820e-02, -6.6624e-01, -2.1126e-01,\n","         -1.0500e+00, -1.0529e-01,  1.9763e-01, -6.9311e-02,  5.5622e-02,\n","         -6.0150e-02, -1.7019e-01, -5.5561e-01, -4.3178e-01,  2.7558e-01,\n","          4.4767e-01,  2.0163e-01,  7.4219e-01, -6.6652e-01,  1.0025e-01,\n","          2.7251e-01,  8.9500e-01,  3.4013e-03, -3.7049e-01,  1.2249e-01,\n","         -6.4617e-01, -4.9287e-01,  1.8257e-01, -3.9539e-01,  1.3000e-01,\n","          5.7439e-02,  6.8272e-01,  3.1802e-01, -2.6278e-02, -7.7135e-03,\n","         -4.1360e-03, -5.4021e-01,  4.2841e-01,  4.1586e-01,  2.1001e-01,\n","         -4.5890e-02,  1.8135e-02,  3.6630e-03,  3.0160e-01, -1.8326e+00,\n","         -1.3835e-01,  2.8902e-01,  6.6394e-02, -3.5952e-01, -3.6441e-02,\n","          3.3150e-02, -2.2120e-03, -3.4964e-01, -7.3946e-02, -9.8704e-01,\n","          3.8202e-01,  1.6610e-01, -7.7423e-01,  4.5986e-01, -1.8437e-01,\n","         -3.1497e-01,  2.6180e-01,  7.2599e-01, -3.6138e-02,  2.0670e-01,\n","         -3.6804e-01,  6.0638e-01,  2.0504e-01, -4.8274e-01,  5.4731e-01,\n","         -3.7399e-01,  3.5786e-01,  5.2560e-02, -2.6012e-01, -9.5004e-03,\n","         -1.4417e-01,  1.8287e-01,  5.1896e-03,  1.0486e-01,  3.6525e-01,\n","         -3.2403e-01, -1.5689e-01, -4.5964e-01, -1.9854e-01,  5.0062e-01,\n","          4.7515e-01,  3.6567e-02, -1.4087e-01,  6.1063e-01,  8.8523e-02,\n","         -2.2227e-01,  7.0021e-01,  2.1693e-01, -1.2017e-01, -5.0806e-01,\n","          3.8269e-01, -1.9860e-01, -3.0804e-02, -3.8313e-01, -1.9699e-02,\n","          2.3633e-01,  2.0780e-01,  3.5045e-01, -5.4653e-02,  3.4343e-01,\n","          1.8888e-02, -4.2616e-02, -1.8654e-01,  4.6126e-01,  5.1846e-01,\n","         -4.4463e-01,  4.4318e-01,  4.9375e-01,  1.0236e-01,  3.4079e-01,\n","         -4.7017e-01, -2.1957e-01, -3.5675e-02,  1.8855e-02, -8.2667e-02,\n","          1.7817e-01, -1.3000e-02,  2.1816e-01,  1.5783e+00, -4.8473e-01,\n","         -4.0489e-01, -1.6256e-01, -1.9036e-01,  1.4051e-01,  2.5568e-01,\n","          1.3348e-01, -4.5873e-02,  1.5153e-01,  2.1617e-01, -7.9847e-01,\n","          1.0681e+00, -3.0939e-01,  3.1204e-01, -1.0648e+00,  3.5666e-01,\n","         -2.7606e-01,  4.0338e-01, -5.0673e-02,  5.9736e-01,  6.6412e-02,\n","         -8.4315e-02, -2.2799e-01, -4.0590e-02,  2.7498e-01, -8.1412e-03,\n","         -4.7173e-01, -1.3033e-01,  2.4838e-01,  3.5531e-01,  9.9272e-03,\n","          6.5678e-01, -1.5948e+00, -8.3327e-01,  3.1825e-01, -2.3586e-01,\n","          6.0132e-01,  2.5053e-01, -6.5175e-01, -2.4261e-02, -5.9755e-01,\n","          5.6022e-01,  1.0350e-01, -1.0733e+00,  2.6569e-01, -2.9012e-01,\n","          3.4314e-01,  6.5739e-01,  3.2092e-01, -1.2516e-01, -5.3981e-01,\n","         -1.0504e+00, -1.5702e-01, -1.9377e-01,  2.2894e-01,  4.4986e-01,\n","          7.6546e-04, -4.4684e-01, -1.0983e-01,  1.3405e-01, -2.0101e-01,\n","          9.3435e-02, -2.4323e-01,  2.6415e-01,  3.7338e-01, -1.2198e-01,\n","         -4.1883e-02, -3.3945e-01,  3.8653e-01, -4.0257e-01,  9.1378e-02,\n","         -4.2330e-01, -6.1193e-01, -2.2416e-02,  4.7428e-01, -2.0330e-01,\n","          5.0481e-01, -3.0835e-01, -1.6962e-01,  3.0747e-01,  2.0609e-01,\n","          1.1750e-01, -4.2151e-01, -2.5359e-01, -6.1662e-01, -2.8476e-01,\n","          2.0725e-01, -3.5449e-02,  1.6745e-01,  6.4846e-02,  4.3761e-01,\n","         -4.0665e-01, -2.6227e-01, -3.4581e-01,  1.4530e-01,  1.5367e-01,\n","         -2.1505e-01,  3.4016e-01,  2.6658e-01,  2.9753e-01,  1.0892e-01,\n","          5.7724e-02, -1.7944e-01,  1.3150e-01,  1.0129e+00, -5.0911e-01,\n","         -5.6495e-02,  6.5476e-01, -1.1981e+00, -5.3383e-02,  3.9328e-01,\n","         -1.0356e-03, -5.2124e-01, -9.3324e-02,  1.2623e-01,  2.1235e-01,\n","          8.2559e-02, -4.7516e-01, -1.1700e+00, -1.5167e-01,  1.5149e-01,\n","          1.8272e-01, -1.8678e-01, -1.5560e-01, -1.5634e-01, -7.8570e-02,\n","          4.7177e-01, -3.3217e-01,  2.9849e-01,  6.6845e-01, -2.4883e-01,\n","          5.3828e-01,  3.0005e-01, -4.0500e-01, -4.6061e-01,  9.3985e-02,\n","         -9.6742e-03, -3.7849e-01, -8.4069e-03, -7.1445e-02, -1.3541e-01,\n","         -2.2839e-01,  2.0589e-01,  3.5276e-01, -3.0832e-01,  2.5257e-01,\n","         -4.5508e-01,  3.0617e-01, -1.6193e-01, -1.2944e-01,  2.0800e-01,\n","         -1.3374e-01,  2.5692e-01, -4.7071e-01, -7.0522e-01,  4.2094e-01,\n","         -5.7665e-02, -4.2658e-01, -1.3619e-01,  2.6366e-01,  2.0212e-01,\n","         -5.3649e-01,  3.6636e-02,  5.5933e-01, -4.5978e-01,  1.7992e-01,\n","         -5.5896e-01,  9.9014e-02,  1.4358e-01, -5.0190e-02,  8.5451e-01,\n","          4.7840e-01,  1.1520e-01,  5.2524e-02, -2.8617e-02,  3.4362e-01,\n","          2.1182e-01, -4.0350e-02,  3.3451e-01,  1.9083e-01, -1.2574e-01,\n","          2.8761e-01, -2.4773e-01,  3.4969e-01, -5.7573e-01,  1.3284e-01,\n","         -1.2405e-01, -6.0348e-01,  1.6238e-01,  1.8235e-01, -1.4297e-01,\n","          1.3787e-01, -3.4885e-01, -4.2987e-01, -3.2762e-01,  1.9530e-01,\n","         -5.3268e-01,  2.0268e-02,  1.6209e-01, -3.5127e-01,  1.7327e-01,\n","          1.9800e-01,  1.1513e-02, -5.4218e-01, -4.7315e-02, -4.5724e-01,\n","          6.8394e-01,  1.2327e-01,  1.3611e-01,  4.9699e-01,  3.3498e-01,\n","         -4.3232e-01,  5.8875e-01, -1.8344e-02,  3.5943e-01, -2.2187e-01,\n","          1.7019e-01, -2.4457e-01,  5.5144e-02, -6.0631e-02, -1.9176e-01,\n","          3.5182e-01,  1.9482e-01,  7.7375e-01, -2.6915e-01,  6.2812e-02,\n","         -1.4429e-01, -2.9262e-01, -3.5870e-01,  5.0353e-01, -1.6119e-02,\n","         -3.6958e-01, -4.9267e-03,  4.7368e-01, -7.1601e-03,  3.9986e-01,\n","          1.4656e-01,  7.7602e-02,  6.8204e-02,  4.4706e-01, -2.7793e-01,\n","         -8.6273e-01, -3.7291e-01, -1.9474e-01, -3.6082e-01, -1.0408e-01,\n","          2.4594e-02,  4.2056e-01, -3.4261e-01,  1.3427e+00,  8.4665e-02,\n","         -7.4228e-02,  5.6402e-01,  7.8236e-02, -1.1295e-01,  4.3706e-01,\n","         -2.7417e-01,  2.9678e-02,  3.2597e-01,  4.2248e-01,  6.8510e-01,\n","          5.5681e-02,  7.4675e-01, -5.9492e-02, -9.2801e-03,  2.4762e-01,\n","          3.1267e-01, -7.0057e-02,  6.4637e-02]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ytrain[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJWI8V6TCXFW","executionInfo":{"status":"ok","timestamp":1658370631738,"user_tz":240,"elapsed":22,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"db8570b8-1ded-499d-8503-64b92e6ed56b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([9, 3, 8, 2])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["ytest[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmTJfWRtCd15","executionInfo":{"status":"ok","timestamp":1658370631738,"user_tz":240,"elapsed":12,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"4dd368a8-4b1e-46a0-dd8a-03f0021c7693"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["xtrain1 = []\n","for num, item in enumerate(xtrain):\n","  xtrain1.append(xtrain[num].logits)\n","xtest1 = []\n","for num, item in enumerate(xtest):\n","  xtest1.append(xtest[num].logits)"],"metadata":{"id":"VJe-ZvCn80Rs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtrain = xtrain1\n","xtest = xtest1"],"metadata":{"id":"5ItnMPwZCin3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtrain = torch.stack(xtrain)\n","xtrain.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Bw_3V4gdAIo","executionInfo":{"status":"ok","timestamp":1658370631981,"user_tz":240,"elapsed":248,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"b86f6d87-866d-425a-c128-6ad3d3b2a53e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12500, 4, 768])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["ytrain = torch.stack(ytrain)\n","ytrain.size()"],"metadata":{"id":"vK1MVOmZdF_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370631981,"user_tz":240,"elapsed":13,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"e10a7af2-751c-4b4d-fafe-41c6ee5d9120"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12500, 4])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["xtest = torch.stack(xtest)\n","xtest.size()"],"metadata":{"id":"MkkdF2QkdGxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370631982,"user_tz":240,"elapsed":11,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"2f40a20a-210a-4fe8-8fc9-c850d32fccf8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 1, 768])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["ytest = torch.stack(ytest)\n","ytest.size()"],"metadata":{"id":"qfHgc-gGdHKa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370631982,"user_tz":240,"elapsed":7,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"e8c37eb5-e8e8-453d-f10c-f03a98fd5b47"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10000, 1])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["xtrain = xtrain.cpu()\n","xtrain = xtrain.numpy()\n","xtrain = xtrain.T.reshape(768,50000)"],"metadata":{"id":"UtqMq8UodVj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtrain.shape"],"metadata":{"id":"Pnr_TYR2lKjv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370632629,"user_tz":240,"elapsed":14,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"c35bef0a-ea2a-4a7e-9145-4c1681ec274f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 50000)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["ytrain = ytrain.cpu()\n","ytrain = ytrain.numpy()\n","ytrain = ytrain.T.reshape(1,50000)"],"metadata":{"id":"JDYC4EOqngnx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ytrain.shape"],"metadata":{"id":"haQo71c8oINo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370632630,"user_tz":240,"elapsed":10,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"8cb08b97-d03e-4e4c-a143-19f2cb16c9b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 50000)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["xtest = xtest.cpu()\n","xtest = xtest.numpy()\n","xtest = xtest.T.reshape(768,10000)"],"metadata":{"id":"KGBzrqhXoPcE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtest.shape"],"metadata":{"id":"Gom-cFvHoZKc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370632837,"user_tz":240,"elapsed":21,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"7097055e-e8e9-4330-92c0-2c93aae0c448"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768, 10000)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["ytest = ytest.cpu()\n","ytest = ytest.numpy()\n","ytest = ytest.T.reshape(1,10000)"],"metadata":{"id":"7shh1eFpoeg_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ytest.shape"],"metadata":{"id":"yQb8ja4golDY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370632838,"user_tz":240,"elapsed":19,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"11effbf0-5e55-479c-985f-10d642013b9e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 10000)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["ytrain = ytrain.flatten()"],"metadata":{"id":"jjk0ZkbrqQX5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtrain = xtrain.T"],"metadata":{"id":"Gt8X6Vpfqfmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xtrain.shape"],"metadata":{"id":"pF_OPx9Nz0CN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370632839,"user_tz":240,"elapsed":14,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"a0d76286-a98d-41e5-c0db-2bf27e4750a6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000, 768)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["ytrain.shape"],"metadata":{"id":"jHa70Ze4z4Tm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658370632840,"user_tz":240,"elapsed":11,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"b9f298c6-ae5a-4737-8ed0-427e859be6d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(50000,)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["xtest = xtest.T"],"metadata":{"id":"kvpb3A9rz69A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ytest = ytest.flatten()"],"metadata":{"id":"2SC9LGs_0F6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install scikeras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkvATNs5jmmZ","executionInfo":{"status":"ok","timestamp":1658370636857,"user_tz":240,"elapsed":3869,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"3d28bd44-d6ff-4370-e928-a6032c7c1ceb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikeras\n","  Downloading scikeras-0.8.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.12.0)\n","Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=0.21->scikeras) (3.0.9)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.8.0\n"]}]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","# from keras.metrics import SparseCategoricalAccuracy \n","# from keras import utils\n","import tensorflow as tf"],"metadata":{"id":"0HBnSWxxj7a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://www.tensorflow.org/xla/tutorials/autoclustering_xla\n","# https://stackoverflow.com/questions/64689483/how-to-do-multiclass-classification-with-keras\n","ytrain = tf.keras.utils.to_categorical(ytrain, num_classes=10)"],"metadata":{"id":"JsQXXptc0W_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_inputs = xtrain.shape[1]\n","def model():\n","  model = Sequential()\n","  model.add(Dense(100, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n","  model.add(Dense(10, activation='softmax'))\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model\n"],"metadata":{"id":"77t5QKWsGAaC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["estimators = []\n","estimators.append(('mlp', KerasClassifier(model=model, epochs=20, batch_size=5, verbose=1)))\n","pipeline = Pipeline(estimators)\n","kfold = KFold(n_splits=2)\n","results = cross_val_score(pipeline, xtrain, ytrain, cv=kfold)"],"metadata":{"id":"Afbs2N2YGb2q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658371179654,"user_tz":240,"elapsed":542479,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"eaf76a40-e4bf-49df-9f9c-d2b900f3a3ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0282 - accuracy: 0.9923\n","Epoch 2/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0081 - accuracy: 0.9978\n","Epoch 3/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0067 - accuracy: 0.9980\n","Epoch 4/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0054 - accuracy: 0.9986\n","Epoch 5/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0030 - accuracy: 0.9992\n","Epoch 6/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0026 - accuracy: 0.9994\n","Epoch 7/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 7.7156e-04 - accuracy: 0.9996\n","Epoch 8/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n","Epoch 9/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0015 - accuracy: 0.9997\n","Epoch 10/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 8.6460e-04 - accuracy: 0.9996\n","Epoch 11/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 8.5314e-04 - accuracy: 0.9998\n","Epoch 12/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 3.2714e-04 - accuracy: 1.0000\n","Epoch 13/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0027 - accuracy: 0.9997\n","Epoch 14/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0020 - accuracy: 0.9998\n","Epoch 15/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 1.6635e-04 - accuracy: 0.9999\n","Epoch 16/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 6.5640e-07 - accuracy: 1.0000\n","Epoch 17/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 3.2860e-04 - accuracy: 0.9999\n","Epoch 18/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 6.9948e-05 - accuracy: 1.0000\n","Epoch 19/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 6.0384e-04 - accuracy: 0.9999\n","Epoch 20/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 5.8928e-04 - accuracy: 1.0000\n","5000/5000 [==============================] - 6s 1ms/step\n","Epoch 1/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0293 - accuracy: 0.9920\n","Epoch 2/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0071 - accuracy: 0.9980\n","Epoch 3/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0071 - accuracy: 0.9978\n","Epoch 4/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0031 - accuracy: 0.9992\n","Epoch 5/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0040 - accuracy: 0.9993\n","Epoch 6/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0033 - accuracy: 0.9992\n","Epoch 7/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 6.1778e-04 - accuracy: 0.9999\n","Epoch 8/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 5.9728e-05 - accuracy: 1.0000\n","Epoch 9/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0021 - accuracy: 0.9996\n","Epoch 10/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0017 - accuracy: 0.9997\n","Epoch 11/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 4.6140e-05 - accuracy: 1.0000\n","Epoch 12/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0015 - accuracy: 0.9996\n","Epoch 13/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 8.2470e-04 - accuracy: 0.9998\n","Epoch 14/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 15/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0012 - accuracy: 0.9998\n","Epoch 16/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 4.4522e-06 - accuracy: 1.0000\n","Epoch 17/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 6.9109e-07 - accuracy: 1.0000\n","Epoch 18/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n","Epoch 19/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0014 - accuracy: 0.9998\n","Epoch 20/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n","5000/5000 [==============================] - 6s 1ms/step\n"]}]},{"cell_type":"code","source":["from sklearn import metrics\n","from sklearn.model_selection import cross_val_predict\n","cross_val_predicted = cross_val_predict(pipeline, xtrain, ytrain, cv=2)\n","print(metrics.accuracy_score(ytrain, cross_val_predicted))\n","print(metrics.classification_report(ytrain, cross_val_predicted))"],"metadata":{"id":"690rsTUvszCp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658371725533,"user_tz":240,"elapsed":545882,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"96d839e1-12f3-4926-b1f4-0a66f3900d7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0295 - accuracy: 0.9926\n","Epoch 2/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0096 - accuracy: 0.9971\n","Epoch 3/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0075 - accuracy: 0.9982\n","Epoch 4/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0045 - accuracy: 0.9989\n","Epoch 5/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0028 - accuracy: 0.9995\n","Epoch 6/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0025 - accuracy: 0.9996\n","Epoch 7/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0022 - accuracy: 0.9994\n","Epoch 8/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0018 - accuracy: 0.9994\n","Epoch 9/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 7.0117e-04 - accuracy: 0.9998\n","Epoch 10/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0029 - accuracy: 0.9995\n","Epoch 11/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 8.5714e-05 - accuracy: 1.0000\n","Epoch 12/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 4.5368e-07 - accuracy: 1.0000\n","Epoch 13/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 5.7175e-04 - accuracy: 0.9998\n","Epoch 14/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0012 - accuracy: 0.9998\n","Epoch 15/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n","Epoch 16/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n","Epoch 17/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 3.5273e-04 - accuracy: 0.9999\n","Epoch 18/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0023 - accuracy: 0.9995\n","Epoch 19/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0010 - accuracy: 0.9998\n","Epoch 20/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 7.6686e-04 - accuracy: 1.0000\n","5000/5000 [==============================] - 6s 1ms/step\n","Epoch 1/20\n","5000/5000 [==============================] - 11s 2ms/step - loss: 0.0282 - accuracy: 0.9918\n","Epoch 2/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0073 - accuracy: 0.9978\n","Epoch 3/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0059 - accuracy: 0.9984\n","Epoch 4/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0061 - accuracy: 0.9984\n","Epoch 5/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0037 - accuracy: 0.9989\n","Epoch 6/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0036 - accuracy: 0.9993\n","Epoch 7/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 7.5227e-04 - accuracy: 0.9998\n","Epoch 8/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0028 - accuracy: 0.9993\n","Epoch 9/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 10/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 11/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 1.4160e-05 - accuracy: 1.0000\n","Epoch 12/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 3.7597e-04 - accuracy: 0.9999\n","Epoch 13/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 6.7887e-04 - accuracy: 0.9998\n","Epoch 14/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 2.9138e-04 - accuracy: 0.9999\n","Epoch 15/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 5.6590e-07 - accuracy: 1.0000\n","Epoch 16/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 4.0875e-04 - accuracy: 0.9999\n","Epoch 17/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 0.0016 - accuracy: 0.9999\n","Epoch 18/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 2.9869e-07 - accuracy: 1.0000\n","Epoch 19/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 4.2687e-08 - accuracy: 1.0000\n","Epoch 20/20\n","5000/5000 [==============================] - 10s 2ms/step - loss: 1.3685e-09 - accuracy: 1.0000\n","5000/5000 [==============================] - 6s 1ms/step\n","0.99658\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      5000\n","           1       1.00      1.00      1.00      5000\n","           2       1.00      1.00      1.00      5000\n","           3       0.99      0.99      0.99      5000\n","           4       1.00      1.00      1.00      5000\n","           5       0.99      1.00      1.00      5000\n","           6       1.00      1.00      1.00      5000\n","           7       1.00      1.00      1.00      5000\n","           8       1.00      1.00      1.00      5000\n","           9       1.00      1.00      1.00      5000\n","\n","   micro avg       1.00      1.00      1.00     50000\n","   macro avg       1.00      1.00      1.00     50000\n","weighted avg       1.00      1.00      1.00     50000\n"," samples avg       1.00      1.00      1.00     50000\n","\n"]}]},{"cell_type":"code","source":["print(\"Result: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqNMkw-OzOUs","executionInfo":{"status":"ok","timestamp":1658371179655,"user_tz":240,"elapsed":11,"user":{"displayName":"Nariman H","userId":"16525869975551128991"}},"outputId":"b24dce56-f021-425f-a508-9e645510a93c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result: 99.62% (0.07%)\n"]}]}]}